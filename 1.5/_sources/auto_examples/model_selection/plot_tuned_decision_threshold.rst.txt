
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/model_selection/plot_tuned_decision_threshold.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_model_selection_plot_tuned_decision_threshold.py>`
        to download the full example code. or to run this example in your browser via JupyterLite or Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_model_selection_plot_tuned_decision_threshold.py:


======================================================
Post-hoc tuning the cut-off point of decision function
======================================================

Once a binary classifier is trained, the :term:`predict` method outputs class label
predictions corresponding to a thresholding of either the :term:`decision_function` or
the :term:`predict_proba` output. The default threshold is defined as a posterior
probability estimate of 0.5 or a decision score of 0.0. However, this default strategy
may not be optimal for the task at hand.

This example shows how to use the
:class:`~sklearn.model_selection.TunedThresholdClassifierCV` to tune the decision
threshold, depending on a metric of interest.

.. GENERATED FROM PYTHON SOURCE LINES 18-24

The diabetes dataset
--------------------

To illustrate the tuning of the decision threshold, we will use the diabetes dataset.
This dataset is available on OpenML: https://www.openml.org/d/37. We use the
:func:`~sklearn.datasets.fetch_openml` function to fetch this dataset.

.. GENERATED FROM PYTHON SOURCE LINES 24-29

.. code-block:: Python

    from sklearn.datasets import fetch_openml

    diabetes = fetch_openml(data_id=37, as_frame=True, parser="pandas")
    data, target = diabetes.data, diabetes.target








.. GENERATED FROM PYTHON SOURCE LINES 30-31

We look at the target to understand the type of problem we are dealing with.

.. GENERATED FROM PYTHON SOURCE LINES 31-33

.. code-block:: Python

    target.value_counts()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    class
    tested_negative    500
    tested_positive    268
    Name: count, dtype: int64



.. GENERATED FROM PYTHON SOURCE LINES 34-38

We can see that we are dealing with a binary classification problem. Since the
labels are not encoded as 0 and 1, we make it explicit that we consider the class
labeled "tested_negative" as the negative class (which is also the most frequent)
and the class labeled "tested_positive" the positive as the positive class:

.. GENERATED FROM PYTHON SOURCE LINES 38-40

.. code-block:: Python

    neg_label, pos_label = target.value_counts().index








.. GENERATED FROM PYTHON SOURCE LINES 41-50

We can also observe that this binary problem is slightly imbalanced where we have
around twice more samples from the negative class than from the positive class. When
it comes to evaluation, we should consider this aspect to interpret the results.

Our vanilla classifier
----------------------

We define a basic predictive model composed of a scaler followed by a logistic
regression classifier.

.. GENERATED FROM PYTHON SOURCE LINES 50-57

.. code-block:: Python

    from sklearn.linear_model import LogisticRegression
    from sklearn.pipeline import make_pipeline
    from sklearn.preprocessing import StandardScaler

    model = make_pipeline(StandardScaler(), LogisticRegression())
    model






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <style>#sk-container-id-55 {
      /* Definition of color scheme common for light and dark mode */
      --sklearn-color-text: black;
      --sklearn-color-line: gray;
      /* Definition of color scheme for unfitted estimators */
      --sklearn-color-unfitted-level-0: #fff5e6;
      --sklearn-color-unfitted-level-1: #f6e4d2;
      --sklearn-color-unfitted-level-2: #ffe0b3;
      --sklearn-color-unfitted-level-3: chocolate;
      /* Definition of color scheme for fitted estimators */
      --sklearn-color-fitted-level-0: #f0f8ff;
      --sklearn-color-fitted-level-1: #d4ebff;
      --sklearn-color-fitted-level-2: #b3dbfd;
      --sklearn-color-fitted-level-3: cornflowerblue;

      /* Specific color for light theme */
      --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
      --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
      --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
      --sklearn-color-icon: #696969;

      @media (prefers-color-scheme: dark) {
        /* Redefinition of color scheme for dark theme */
        --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
        --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
        --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
        --sklearn-color-icon: #878787;
      }
    }

    #sk-container-id-55 {
      color: var(--sklearn-color-text);
    }

    #sk-container-id-55 pre {
      padding: 0;
    }

    #sk-container-id-55 input.sk-hidden--visually {
      border: 0;
      clip: rect(1px 1px 1px 1px);
      clip: rect(1px, 1px, 1px, 1px);
      height: 1px;
      margin: -1px;
      overflow: hidden;
      padding: 0;
      position: absolute;
      width: 1px;
    }

    #sk-container-id-55 div.sk-dashed-wrapped {
      border: 1px dashed var(--sklearn-color-line);
      margin: 0 0.4em 0.5em 0.4em;
      box-sizing: border-box;
      padding-bottom: 0.4em;
      background-color: var(--sklearn-color-background);
    }

    #sk-container-id-55 div.sk-container {
      /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
         but bootstrap.min.css set `[hidden] { display: none !important; }`
         so we also need the `!important` here to be able to override the
         default hidden behavior on the sphinx rendered scikit-learn.org.
         See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
      display: inline-block !important;
      position: relative;
    }

    #sk-container-id-55 div.sk-text-repr-fallback {
      display: none;
    }

    div.sk-parallel-item,
    div.sk-serial,
    div.sk-item {
      /* draw centered vertical line to link estimators */
      background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
      background-size: 2px 100%;
      background-repeat: no-repeat;
      background-position: center center;
    }

    /* Parallel-specific style estimator block */

    #sk-container-id-55 div.sk-parallel-item::after {
      content: "";
      width: 100%;
      border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
      flex-grow: 1;
    }

    #sk-container-id-55 div.sk-parallel {
      display: flex;
      align-items: stretch;
      justify-content: center;
      background-color: var(--sklearn-color-background);
      position: relative;
    }

    #sk-container-id-55 div.sk-parallel-item {
      display: flex;
      flex-direction: column;
    }

    #sk-container-id-55 div.sk-parallel-item:first-child::after {
      align-self: flex-end;
      width: 50%;
    }

    #sk-container-id-55 div.sk-parallel-item:last-child::after {
      align-self: flex-start;
      width: 50%;
    }

    #sk-container-id-55 div.sk-parallel-item:only-child::after {
      width: 0;
    }

    /* Serial-specific style estimator block */

    #sk-container-id-55 div.sk-serial {
      display: flex;
      flex-direction: column;
      align-items: center;
      background-color: var(--sklearn-color-background);
      padding-right: 1em;
      padding-left: 1em;
    }


    /* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
    clickable and can be expanded/collapsed.
    - Pipeline and ColumnTransformer use this feature and define the default style
    - Estimators will overwrite some part of the style using the `sk-estimator` class
    */

    /* Pipeline and ColumnTransformer style (default) */

    #sk-container-id-55 div.sk-toggleable {
      /* Default theme specific background. It is overwritten whether we have a
      specific estimator or a Pipeline/ColumnTransformer */
      background-color: var(--sklearn-color-background);
    }

    /* Toggleable label */
    #sk-container-id-55 label.sk-toggleable__label {
      cursor: pointer;
      display: block;
      width: 100%;
      margin-bottom: 0;
      padding: 0.5em;
      box-sizing: border-box;
      text-align: center;
    }

    #sk-container-id-55 label.sk-toggleable__label-arrow:before {
      /* Arrow on the left of the label */
      content: "â–¸";
      float: left;
      margin-right: 0.25em;
      color: var(--sklearn-color-icon);
    }

    #sk-container-id-55 label.sk-toggleable__label-arrow:hover:before {
      color: var(--sklearn-color-text);
    }

    /* Toggleable content - dropdown */

    #sk-container-id-55 div.sk-toggleable__content {
      max-height: 0;
      max-width: 0;
      overflow: hidden;
      text-align: left;
      /* unfitted */
      background-color: var(--sklearn-color-unfitted-level-0);
    }

    #sk-container-id-55 div.sk-toggleable__content.fitted {
      /* fitted */
      background-color: var(--sklearn-color-fitted-level-0);
    }

    #sk-container-id-55 div.sk-toggleable__content pre {
      margin: 0.2em;
      border-radius: 0.25em;
      color: var(--sklearn-color-text);
      /* unfitted */
      background-color: var(--sklearn-color-unfitted-level-0);
    }

    #sk-container-id-55 div.sk-toggleable__content.fitted pre {
      /* unfitted */
      background-color: var(--sklearn-color-fitted-level-0);
    }

    #sk-container-id-55 input.sk-toggleable__control:checked~div.sk-toggleable__content {
      /* Expand drop-down */
      max-height: 200px;
      max-width: 100%;
      overflow: auto;
    }

    #sk-container-id-55 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
      content: "â–¾";
    }

    /* Pipeline/ColumnTransformer-specific style */

    #sk-container-id-55 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
      color: var(--sklearn-color-text);
      background-color: var(--sklearn-color-unfitted-level-2);
    }

    #sk-container-id-55 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
      background-color: var(--sklearn-color-fitted-level-2);
    }

    /* Estimator-specific style */

    /* Colorize estimator box */
    #sk-container-id-55 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
      /* unfitted */
      background-color: var(--sklearn-color-unfitted-level-2);
    }

    #sk-container-id-55 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
      /* fitted */
      background-color: var(--sklearn-color-fitted-level-2);
    }

    #sk-container-id-55 div.sk-label label.sk-toggleable__label,
    #sk-container-id-55 div.sk-label label {
      /* The background is the default theme color */
      color: var(--sklearn-color-text-on-default-background);
    }

    /* On hover, darken the color of the background */
    #sk-container-id-55 div.sk-label:hover label.sk-toggleable__label {
      color: var(--sklearn-color-text);
      background-color: var(--sklearn-color-unfitted-level-2);
    }

    /* Label box, darken color on hover, fitted */
    #sk-container-id-55 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
      color: var(--sklearn-color-text);
      background-color: var(--sklearn-color-fitted-level-2);
    }

    /* Estimator label */

    #sk-container-id-55 div.sk-label label {
      font-family: monospace;
      font-weight: bold;
      display: inline-block;
      line-height: 1.2em;
    }

    #sk-container-id-55 div.sk-label-container {
      text-align: center;
    }

    /* Estimator-specific */
    #sk-container-id-55 div.sk-estimator {
      font-family: monospace;
      border: 1px dotted var(--sklearn-color-border-box);
      border-radius: 0.25em;
      box-sizing: border-box;
      margin-bottom: 0.5em;
      /* unfitted */
      background-color: var(--sklearn-color-unfitted-level-0);
    }

    #sk-container-id-55 div.sk-estimator.fitted {
      /* fitted */
      background-color: var(--sklearn-color-fitted-level-0);
    }

    /* on hover */
    #sk-container-id-55 div.sk-estimator:hover {
      /* unfitted */
      background-color: var(--sklearn-color-unfitted-level-2);
    }

    #sk-container-id-55 div.sk-estimator.fitted:hover {
      /* fitted */
      background-color: var(--sklearn-color-fitted-level-2);
    }

    /* Specification for estimator info (e.g. "i" and "?") */

    /* Common style for "i" and "?" */

    .sk-estimator-doc-link,
    a:link.sk-estimator-doc-link,
    a:visited.sk-estimator-doc-link {
      float: right;
      font-size: smaller;
      line-height: 1em;
      font-family: monospace;
      background-color: var(--sklearn-color-background);
      border-radius: 1em;
      height: 1em;
      width: 1em;
      text-decoration: none !important;
      margin-left: 1ex;
      /* unfitted */
      border: var(--sklearn-color-unfitted-level-1) 1pt solid;
      color: var(--sklearn-color-unfitted-level-1);
    }

    .sk-estimator-doc-link.fitted,
    a:link.sk-estimator-doc-link.fitted,
    a:visited.sk-estimator-doc-link.fitted {
      /* fitted */
      border: var(--sklearn-color-fitted-level-1) 1pt solid;
      color: var(--sklearn-color-fitted-level-1);
    }

    /* On hover */
    div.sk-estimator:hover .sk-estimator-doc-link:hover,
    .sk-estimator-doc-link:hover,
    div.sk-label-container:hover .sk-estimator-doc-link:hover,
    .sk-estimator-doc-link:hover {
      /* unfitted */
      background-color: var(--sklearn-color-unfitted-level-3);
      color: var(--sklearn-color-background);
      text-decoration: none;
    }

    div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
    .sk-estimator-doc-link.fitted:hover,
    div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
    .sk-estimator-doc-link.fitted:hover {
      /* fitted */
      background-color: var(--sklearn-color-fitted-level-3);
      color: var(--sklearn-color-background);
      text-decoration: none;
    }

    /* Span, style for the box shown on hovering the info icon */
    .sk-estimator-doc-link span {
      display: none;
      z-index: 9999;
      position: relative;
      font-weight: normal;
      right: .2ex;
      padding: .5ex;
      margin: .5ex;
      width: min-content;
      min-width: 20ex;
      max-width: 50ex;
      color: var(--sklearn-color-text);
      box-shadow: 2pt 2pt 4pt #999;
      /* unfitted */
      background: var(--sklearn-color-unfitted-level-0);
      border: .5pt solid var(--sklearn-color-unfitted-level-3);
    }

    .sk-estimator-doc-link.fitted span {
      /* fitted */
      background: var(--sklearn-color-fitted-level-0);
      border: var(--sklearn-color-fitted-level-3);
    }

    .sk-estimator-doc-link:hover span {
      display: block;
    }

    /* "?"-specific style due to the `<a>` HTML tag */

    #sk-container-id-55 a.estimator_doc_link {
      float: right;
      font-size: 1rem;
      line-height: 1em;
      font-family: monospace;
      background-color: var(--sklearn-color-background);
      border-radius: 1rem;
      height: 1rem;
      width: 1rem;
      text-decoration: none;
      /* unfitted */
      color: var(--sklearn-color-unfitted-level-1);
      border: var(--sklearn-color-unfitted-level-1) 1pt solid;
    }

    #sk-container-id-55 a.estimator_doc_link.fitted {
      /* fitted */
      border: var(--sklearn-color-fitted-level-1) 1pt solid;
      color: var(--sklearn-color-fitted-level-1);
    }

    /* On hover */
    #sk-container-id-55 a.estimator_doc_link:hover {
      /* unfitted */
      background-color: var(--sklearn-color-unfitted-level-3);
      color: var(--sklearn-color-background);
      text-decoration: none;
    }

    #sk-container-id-55 a.estimator_doc_link.fitted:hover {
      /* fitted */
      background-color: var(--sklearn-color-fitted-level-3);
    }
    </style><div id="sk-container-id-55" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),
                    (&#x27;logisticregression&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label  sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-227" type="checkbox" ><label for="sk-estimator-id-227" class="sk-toggleable__label  sk-toggleable__label-arrow ">&nbsp;&nbsp;Pipeline<a class="sk-estimator-doc-link " rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html">?<span>Documentation for Pipeline</span></a><span class="sk-estimator-doc-link ">i<span>Not fitted</span></span></label><div class="sk-toggleable__content "><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),
                    (&#x27;logisticregression&#x27;, LogisticRegression())])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator  sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-228" type="checkbox" ><label for="sk-estimator-id-228" class="sk-toggleable__label  sk-toggleable__label-arrow ">&nbsp;StandardScaler<a class="sk-estimator-doc-link " rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html">?<span>Documentation for StandardScaler</span></a></label><div class="sk-toggleable__content "><pre>StandardScaler()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator  sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-229" type="checkbox" ><label for="sk-estimator-id-229" class="sk-toggleable__label  sk-toggleable__label-arrow ">&nbsp;LogisticRegression<a class="sk-estimator-doc-link " rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html">?<span>Documentation for LogisticRegression</span></a></label><div class="sk-toggleable__content "><pre>LogisticRegression()</pre></div> </div></div></div></div></div></div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 58-68

We evaluate our model using cross-validation. We use the accuracy and the balanced
accuracy to report the performance of our model. The balanced accuracy is a metric
that is less sensitive to class imbalance and will allow us to put the accuracy
score in perspective.

Cross-validation allows us to study the variance of the decision threshold across
different splits of the data. However, the dataset is rather small and it would be
detrimental to use more than 5 folds to evaluate the dispersion. Therefore, we use
a :class:`~sklearn.model_selection.RepeatedStratifiedKFold` where we apply several
repetitions of 5-fold cross-validation.

.. GENERATED FROM PYTHON SOURCE LINES 68-93

.. code-block:: Python

    import pandas as pd

    from sklearn.model_selection import RepeatedStratifiedKFold, cross_validate

    scoring = ["accuracy", "balanced_accuracy"]
    cv_scores = [
        "train_accuracy",
        "test_accuracy",
        "train_balanced_accuracy",
        "test_balanced_accuracy",
    ]
    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)
    cv_results_vanilla_model = pd.DataFrame(
        cross_validate(
            model,
            data,
            target,
            scoring=scoring,
            cv=cv,
            return_train_score=True,
            return_estimator=True,
        )
    )
    cv_results_vanilla_model[cv_scores].aggregate(["mean", "std"]).T






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>mean</th>
          <th>std</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>train_accuracy</th>
          <td>0.779751</td>
          <td>0.007822</td>
        </tr>
        <tr>
          <th>test_accuracy</th>
          <td>0.770926</td>
          <td>0.030585</td>
        </tr>
        <tr>
          <th>train_balanced_accuracy</th>
          <td>0.732913</td>
          <td>0.009788</td>
        </tr>
        <tr>
          <th>test_balanced_accuracy</th>
          <td>0.723665</td>
          <td>0.035914</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 94-113

Our predictive model succeeds to grasp the relationship between the data and the
target. The training and testing scores are close to each other, meaning that our
predictive model is not overfitting. We can also observe that the balanced accuracy is
lower than the accuracy, due to the class imbalance previously mentioned.

For this classifier, we let the decision threshold, used convert the probability of
the positive class into a class prediction, to its default value: 0.5. However, this
threshold might not be optimal. If our interest is to maximize the balanced accuracy,
we should select another threshold that would maximize this metric.

The :class:`~sklearn.model_selection.TunedThresholdClassifierCV` meta-estimator allows
to tune the decision threshold of a classifier given a metric of interest.

Tuning the decision threshold
-----------------------------

We create a :class:`~sklearn.model_selection.TunedThresholdClassifierCV` and
configure it to maximize the balanced accuracy. We evaluate the model using the same
cross-validation strategy as previously.

.. GENERATED FROM PYTHON SOURCE LINES 113-129

.. code-block:: Python

    from sklearn.model_selection import TunedThresholdClassifierCV

    tuned_model = TunedThresholdClassifierCV(estimator=model, scoring="balanced_accuracy")
    cv_results_tuned_model = pd.DataFrame(
        cross_validate(
            tuned_model,
            data,
            target,
            scoring=scoring,
            cv=cv,
            return_train_score=True,
            return_estimator=True,
        )
    )
    cv_results_tuned_model[cv_scores].aggregate(["mean", "std"]).T






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>mean</th>
          <th>std</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>train_accuracy</th>
          <td>0.752470</td>
          <td>0.015579</td>
        </tr>
        <tr>
          <th>test_accuracy</th>
          <td>0.739950</td>
          <td>0.036592</td>
        </tr>
        <tr>
          <th>train_balanced_accuracy</th>
          <td>0.757915</td>
          <td>0.009747</td>
        </tr>
        <tr>
          <th>test_balanced_accuracy</th>
          <td>0.744029</td>
          <td>0.035445</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 130-137

In comparison with the vanilla model, we observe that the balanced accuracy score
increased. Of course, it comes at the cost of a lower accuracy score. It means that
our model is now more sensitive to the positive class but makes more mistakes on the
negative class.

However, it is important to note that this tuned predictive model is internally the
same model as the vanilla model: they have the same fitted coefficients.

.. GENERATED FROM PYTHON SOURCE LINES 137-156

.. code-block:: Python

    import matplotlib.pyplot as plt

    vanilla_model_coef = pd.DataFrame(
        [est[-1].coef_.ravel() for est in cv_results_vanilla_model["estimator"]],
        columns=diabetes.feature_names,
    )
    tuned_model_coef = pd.DataFrame(
        [est.estimator_[-1].coef_.ravel() for est in cv_results_tuned_model["estimator"]],
        columns=diabetes.feature_names,
    )

    fig, ax = plt.subplots(ncols=2, figsize=(12, 4), sharex=True, sharey=True)
    vanilla_model_coef.boxplot(ax=ax[0])
    ax[0].set_ylabel("Coefficient value")
    ax[0].set_title("Vanilla model")
    tuned_model_coef.boxplot(ax=ax[1])
    ax[1].set_title("Tuned model")
    _ = fig.suptitle("Coefficients of the predictive models")




.. image-sg:: /auto_examples/model_selection/images/sphx_glr_plot_tuned_decision_threshold_001.png
   :alt: Coefficients of the predictive models, Vanilla model, Tuned model
   :srcset: /auto_examples/model_selection/images/sphx_glr_plot_tuned_decision_threshold_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 157-158

Only the decision threshold of each model was changed during the cross-validation.

.. GENERATED FROM PYTHON SOURCE LINES 158-174

.. code-block:: Python

    decision_threshold = pd.Series(
        [est.best_threshold_ for est in cv_results_tuned_model["estimator"]],
    )
    ax = decision_threshold.plot.kde()
    ax.axvline(
        decision_threshold.mean(),
        color="k",
        linestyle="--",
        label=f"Mean decision threshold: {decision_threshold.mean():.2f}",
    )
    ax.set_xlabel("Decision threshold")
    ax.legend(loc="upper right")
    _ = ax.set_title(
        "Distribution of the decision threshold \nacross different cross-validation folds"
    )




.. image-sg:: /auto_examples/model_selection/images/sphx_glr_plot_tuned_decision_threshold_002.png
   :alt: Distribution of the decision threshold  across different cross-validation folds
   :srcset: /auto_examples/model_selection/images/sphx_glr_plot_tuned_decision_threshold_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 175-185

In average, a decision threshold around 0.32 maximizes the balanced accuracy, which is
different from the default decision threshold of 0.5. Thus tuning the decision
threshold is particularly important when the output of the predictive model
is used to make decisions. Besides, the metric used to tune the decision threshold
should be chosen carefully. Here, we used the balanced accuracy but it might not be
the most appropriate metric for the problem at hand. The choice of the "right" metric
is usually problem-dependent and might require some domain knowledge. Refer to the
example entitled,
:ref:`sphx_glr_auto_examples_model_selection_plot_cost_sensitive_learning.py`,
for more details.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 30.948 seconds)


.. _sphx_glr_download_auto_examples_model_selection_plot_tuned_decision_threshold.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/scikit-learn/scikit-learn/1.5.X?urlpath=lab/tree/notebooks/auto_examples/model_selection/plot_tuned_decision_threshold.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: lite-badge

      .. image:: images/jupyterlite_badge_logo.svg
        :target: ../../lite/lab/index.html?path=auto_examples/model_selection/plot_tuned_decision_threshold.ipynb
        :alt: Launch JupyterLite
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_tuned_decision_threshold.ipynb <plot_tuned_decision_threshold.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_tuned_decision_threshold.py <plot_tuned_decision_threshold.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_tuned_decision_threshold.zip <plot_tuned_decision_threshold.zip>`


.. include:: plot_tuned_decision_threshold.recommendations


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
