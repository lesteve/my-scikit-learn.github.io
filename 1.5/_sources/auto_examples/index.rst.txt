:orphan:

.. _general_examples:

Examples
========

This is the gallery of examples that showcase how scikit-learn can be used. Some
examples demonstrate the use of the :ref:`API <api_ref>` in general and some
demonstrate specific applications in tutorial form. Also check out our
:ref:`user guide <user_guide>` for more detailed illustrations.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. thumbnail-parent-div-close

.. raw:: html

    </div>


Release Highlights
------------------

These examples illustrate the main features of the releases of scikit-learn.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="We are pleased to announce the release of scikit-learn 1.5! Many bug fixes and improvements were added, as well as some key new features. Below we detail the highlights of this release. For an exhaustive list of all the changes, please refer to the release notes &lt;release_notes_1_5&gt;.">

.. only:: html

  .. image:: /auto_examples/release_highlights/images/thumb/sphx_glr_plot_release_highlights_1_5_0_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_release_highlights_plot_release_highlights_1_5_0.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Release Highlights for scikit-learn 1.5</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="We are pleased to announce the release of scikit-learn 1.4! Many bug fixes and improvements were added, as well as some new key features. We detail below a few of the major features of this release. For an exhaustive list of all the changes, please refer to the release notes &lt;release_notes_1_4&gt;.">

.. only:: html

  .. image:: /auto_examples/release_highlights/images/thumb/sphx_glr_plot_release_highlights_1_4_0_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_release_highlights_plot_release_highlights_1_4_0.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Release Highlights for scikit-learn 1.4</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="We are pleased to announce the release of scikit-learn 1.3! Many bug fixes and improvements were added, as well as some new key features. We detail below a few of the major features of this release. For an exhaustive list of all the changes, please refer to the release notes &lt;release_notes_1_3&gt;.">

.. only:: html

  .. image:: /auto_examples/release_highlights/images/thumb/sphx_glr_plot_release_highlights_1_3_0_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_release_highlights_plot_release_highlights_1_3_0.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Release Highlights for scikit-learn 1.3</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="We are pleased to announce the release of scikit-learn 1.2! Many bug fixes and improvements were added, as well as some new key features. We detail below a few of the major features of this release. For an exhaustive list of all the changes, please refer to the release notes &lt;release_notes_1_2&gt;.">

.. only:: html

  .. image:: /auto_examples/release_highlights/images/thumb/sphx_glr_plot_release_highlights_1_2_0_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_release_highlights_plot_release_highlights_1_2_0.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Release Highlights for scikit-learn 1.2</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="We are pleased to announce the release of scikit-learn 1.1! Many bug fixes and improvements were added, as well as some new key features. We detail below a few of the major features of this release. For an exhaustive list of all the changes, please refer to the release notes &lt;release_notes_1_1&gt;.">

.. only:: html

  .. image:: /auto_examples/release_highlights/images/thumb/sphx_glr_plot_release_highlights_1_1_0_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_release_highlights_plot_release_highlights_1_1_0.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Release Highlights for scikit-learn 1.1</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="We are very pleased to announce the release of scikit-learn 1.0! The library has been stable for quite some time, releasing version 1.0 is recognizing that and signalling it to our users. This release does not include any breaking changes apart from the usual two-release deprecation cycle. For the future, we do our best to keep this pattern.">

.. only:: html

  .. image:: /auto_examples/release_highlights/images/thumb/sphx_glr_plot_release_highlights_1_0_0_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_release_highlights_plot_release_highlights_1_0_0.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Release Highlights for scikit-learn 1.0</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="We are pleased to announce the release of scikit-learn 0.24! Many bug fixes and improvements were added, as well as some new key features. We detail below a few of the major features of this release. For an exhaustive list of all the changes, please refer to the release notes &lt;release_notes_0_24&gt;.">

.. only:: html

  .. image:: /auto_examples/release_highlights/images/thumb/sphx_glr_plot_release_highlights_0_24_0_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_release_highlights_plot_release_highlights_0_24_0.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Release Highlights for scikit-learn 0.24</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="We are pleased to announce the release of scikit-learn 0.23! Many bug fixes and improvements were added, as well as some new key features. We detail below a few of the major features of this release. For an exhaustive list of all the changes, please refer to the release notes &lt;release_notes_0_23&gt;.">

.. only:: html

  .. image:: /auto_examples/release_highlights/images/thumb/sphx_glr_plot_release_highlights_0_23_0_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_release_highlights_plot_release_highlights_0_23_0.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Release Highlights for scikit-learn 0.23</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="We are pleased to announce the release of scikit-learn 0.22, which comes with many bug fixes and new features! We detail below a few of the major features of this release. For an exhaustive list of all the changes, please refer to the release notes &lt;release_notes_0_22&gt;.">

.. only:: html

  .. image:: /auto_examples/release_highlights/images/thumb/sphx_glr_plot_release_highlights_0_22_0_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_release_highlights_plot_release_highlights_0_22_0.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Release Highlights for scikit-learn 0.22</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Biclustering
------------

Examples concerning biclustering techniques.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates how to generate a checkerboard dataset and bicluster it using the SpectralBiclustering algorithm. The spectral biclustering algorithm is specifically designed to cluster data by simultaneously considering both the rows (samples) and columns (features) of a matrix. It aims to identify patterns not only between samples but also within subsets of samples, allowing for the detection of localized structure within the data. This makes spectral biclustering particularly well-suited for datasets where the order or arrangement of features is fixed, such as in images, time series, or genomes.">

.. only:: html

  .. image:: /auto_examples/bicluster/images/thumb/sphx_glr_plot_spectral_biclustering_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_bicluster_plot_spectral_biclustering.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">A demo of the Spectral Biclustering algorithm</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates how to generate a dataset and bicluster it using the Spectral Co-Clustering algorithm.">

.. only:: html

  .. image:: /auto_examples/bicluster/images/thumb/sphx_glr_plot_spectral_coclustering_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_bicluster_plot_spectral_coclustering.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">A demo of the Spectral Co-Clustering algorithm</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the Spectral Co-clustering algorithm on the twenty newsgroups dataset. The &#x27;comp.os.ms-windows.misc&#x27; category is excluded because it contains many posts containing nothing but data.">

.. only:: html

  .. image:: /auto_examples/bicluster/images/thumb/sphx_glr_plot_bicluster_newsgroups_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_bicluster_plot_bicluster_newsgroups.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Biclustering documents with the Spectral Co-clustering algorithm</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Calibration
-----------------------

Examples illustrating the calibration of predicted probabilities of classifiers.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Well calibrated classifiers are probabilistic classifiers for which the output of predict_proba can be directly interpreted as a confidence level. For instance, a well calibrated (binary) classifier should classify the samples such that for the samples to which it gave a predict_proba value close to 0.8, approximately 80% actually belong to the positive class.">

.. only:: html

  .. image:: /auto_examples/calibration/images/thumb/sphx_glr_plot_compare_calibration_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_calibration_plot_compare_calibration.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Comparison of Calibration of Classifiers</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="When performing classification one often wants to predict not only the class label, but also the associated probability. This probability gives some kind of confidence on the prediction. This example demonstrates how to visualize how well calibrated the predicted probabilities are using calibration curves, also known as reliability diagrams. Calibration of an uncalibrated classifier will also be demonstrated.">

.. only:: html

  .. image:: /auto_examples/calibration/images/thumb/sphx_glr_plot_calibration_curve_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_calibration_plot_calibration_curve.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Probability Calibration curves</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how sigmoid calibration changes predicted probabilities for a 3-class classification problem. Illustrated is the standard 2-simplex, where the three corners correspond to the three classes. Arrows point from the probability vectors predicted by an uncalibrated classifier to the probability vectors predicted by the same classifier after sigmoid calibration on a hold-out validation set. Colors indicate the true class of an instance (red: class 1, green: class 2, blue: class 3).">

.. only:: html

  .. image:: /auto_examples/calibration/images/thumb/sphx_glr_plot_calibration_multiclass_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_calibration_plot_calibration_multiclass.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Probability Calibration for 3-class classification</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="When performing classification you often want to predict not only the class label, but also the associated probability. This probability gives you some kind of confidence on the prediction. However, not all classifiers provide well-calibrated probabilities, some being over-confident while others being under-confident. Thus, a separate calibration of predicted probabilities is often desirable as a postprocessing. This example illustrates two different methods for this calibration and evaluates the quality of the returned probabilities using Brier&#x27;s score (see https://en.wikipedia.org/wiki/Brier_score).">

.. only:: html

  .. image:: /auto_examples/calibration/images/thumb/sphx_glr_plot_calibration_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_calibration_plot_calibration.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Probability calibration of classifiers</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Classification
-----------------------

General examples about classification algorithms.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A comparison of several classifiers in scikit-learn on synthetic datasets. The point of this example is to illustrate the nature of decision boundaries of different classifiers. This should be taken with a grain of salt, as the intuition conveyed by these examples does not necessarily carry over to real datasets.">

.. only:: html

  .. image:: /auto_examples/classification/images/thumb/sphx_glr_plot_classifier_comparison_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_classification_plot_classifier_comparison.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Classifier comparison</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example plots the covariance ellipsoids of each class and the decision boundary learned by LinearDiscriminantAnalysis (LDA) and QuadraticDiscriminantAnalysis (QDA). The ellipsoids display the double standard deviation for each class. With LDA, the standard deviation is the same for all the classes, while each class has its own standard deviation with QDA.">

.. only:: html

  .. image:: /auto_examples/classification/images/thumb/sphx_glr_plot_lda_qda_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_classification_plot_lda_qda.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Linear and Quadratic Discriminant Analysis with covariance ellipsoid</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how the Ledoit-Wolf and Oracle Approximating Shrinkage (OAS) estimators of covariance can improve classification.">

.. only:: html

  .. image:: /auto_examples/classification/images/thumb/sphx_glr_plot_lda_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_classification_plot_lda.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Normal, Ledoit-Wolf and OAS Linear Discriminant Analysis for classification</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Plot the classification probability for different classifiers. We use a 3 class dataset, and we classify it with a Support Vector classifier, L1 and L2 penalized logistic regression (multinomial multiclass), a One-Vs-Rest version with logistic regression, and Gaussian process classification.">

.. only:: html

  .. image:: /auto_examples/classification/images/thumb/sphx_glr_plot_classification_probability_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_classification_plot_classification_probability.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Plot classification probability</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how scikit-learn can be used to recognize images of hand-written digits, from 0-9.">

.. only:: html

  .. image:: /auto_examples/classification/images/thumb/sphx_glr_plot_digits_classification_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_classification_plot_digits_classification.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Recognizing hand-written digits</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Clustering
----------

Examples concerning the :mod:`sklearn.cluster` module.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example we compare the various initialization strategies for K-means in terms of runtime and quality of the results.">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_kmeans_digits_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_kmeans_digits.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">A demo of K-Means clustering on the handwritten digits data</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Compute the segmentation of a 2D image with Ward hierarchical clustering. The clustering is spatially constrained in order for each segmented region to be in one piece.">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_coin_ward_segmentation_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_coin_ward_segmentation.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">A demo of structured Ward hierarchical clustering on an image of coins</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Reference:">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_mean_shift_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_mean_shift.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">A demo of the mean-shift clustering algorithm</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="- a first experiment with fixed &quot;ground truth labels&quot; (and therefore fixed   number of classes) and randomly &quot;predicted labels&quot;; - a second experiment with varying &quot;ground truth labels&quot;, randomly &quot;predicted   labels&quot;. The &quot;predicted labels&quot; have the same number of classes and clusters   as the &quot;ground truth labels&quot;.">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_adjusted_for_chance_measures_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_adjusted_for_chance_measures.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Adjustment for chance in clustering performance evaluation</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows the effect of imposing a connectivity graph to capture local structure in the data. The graph is simply the graph of 20 nearest neighbors.">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_agglomerative_clustering_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_agglomerative_clustering.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Agglomerative clustering with and without structure</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Demonstrates the effect of different metrics on the hierarchical clustering.">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_agglomerative_clustering_metrics_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_agglomerative_clustering_metrics.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Agglomerative clustering with different metrics</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="An example to show the output of the sklearn.cluster.kmeans_plusplus function for generating initial seeds for clustering.">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_kmeans_plusplus_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_kmeans_plusplus.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">An example of K-Means++ initialization</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows differences between Regular K-Means algorithm and Bisecting K-Means.">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_bisect_kmeans_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_bisect_kmeans.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Bisecting K-Means and Regular K-Means Performance Comparison</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Performs a pixel-wise Vector Quantization (VQ) of an image of the summer palace (China), reducing the number of colors required to show the image from 96,615 unique colors to 64, while preserving the overall appearance quality.">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_color_quantization_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_color_quantization.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Color Quantization using K-Means</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example compares the timing of BIRCH (with and without the global clustering step) and MiniBatchKMeans on a synthetic dataset having 25,000 samples and 2 features generated using make_blobs.">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_birch_vs_minibatchkmeans_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_birch_vs_minibatchkmeans.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Compare BIRCH and MiniBatchKMeans</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows characteristics of different clustering algorithms on datasets that are &quot;interesting&quot; but still in 2D. With the exception of the last dataset, the parameters of each of these dataset-algorithm pairs has been tuned to produce good clustering results. Some algorithms are more sensitive to parameter values than others.">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_cluster_comparison_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_cluster_comparison.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Comparing different clustering algorithms on toy datasets</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows characteristics of different linkage methods for hierarchical clustering on datasets that are &quot;interesting&quot; but still in 2D.">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_linkage_comparison_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_linkage_comparison.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Comparing different hierarchical linkage methods on toy datasets</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="We want to compare the performance of the MiniBatchKMeans and KMeans: the MiniBatchKMeans is faster, but gives slightly different results (see mini_batch_kmeans).">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_mini_batch_kmeans_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_mini_batch_kmeans.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Comparison of the K-Means and MiniBatchKMeans clustering algorithms</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="DBSCAN (Density-Based Spatial Clustering of Applications with Noise) finds core samples in regions of high density and expands clusters from them. This algorithm is good for data which contains clusters of similar density.">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_dbscan_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_dbscan.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Demo of DBSCAN clustering algorithm</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this demo we will take a look at cluster.HDBSCAN from the perspective of generalizing the cluster.DBSCAN algorithm. We&#x27;ll compare both algorithms on specific datasets. Finally we&#x27;ll evaluate HDBSCAN&#x27;s sensitivity to certain hyperparameters.">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_hdbscan_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_hdbscan.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Demo of HDBSCAN clustering algorithm</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Finds core samples of high density and expands clusters from them. This example uses data that is generated so that the clusters have different densities.">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_optics_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_optics.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Demo of OPTICS clustering algorithm</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Reference: Brendan J. Frey and Delbert Dueck, &quot;Clustering by Passing Messages Between Data Points&quot;, Science Feb. 2007">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_affinity_propagation_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_affinity_propagation.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Demo of affinity propagation clustering algorithm</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example is meant to illustrate situations where k-means produces unintuitive and possibly undesirable clusters.">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_kmeans_assumptions_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_kmeans_assumptions.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Demonstration of k-means assumptions</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Evaluate the ability of k-means initializations strategies to make the algorithm convergence robust, as measured by the relative standard deviation of the inertia of the clustering (i.e. the sum of squared distances to the nearest cluster center).">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_kmeans_stability_low_dim_dense_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_kmeans_stability_low_dim_dense.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Empirical evaluation of the impact of k-means initialization</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="These images show how similar features are merged together using feature agglomeration.">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_digits_agglomeration_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_digits_agglomeration.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Feature agglomeration</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example compares 2 dimensionality reduction strategies:">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_feature_agglomeration_vs_univariate_selection_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_feature_agglomeration_vs_univariate_selection.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Feature agglomeration vs. univariate selection</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Example builds a swiss roll dataset and runs hierarchical clustering on their position.">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_ward_structured_vs_unstructured_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_ward_structured_vs_unstructured.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Hierarchical clustering: structured vs unstructured ward</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Clustering can be expensive, especially when our dataset contains millions of datapoints. Many clustering algorithms are not inductive and so cannot be directly applied to new data samples without recomputing the clustering, which may be intractable. Instead, we can use clustering to then learn an inductive model with a classifier, which has several benefits:">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_inductive_clustering_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_inductive_clustering.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Inductive Clustering</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The plot shows:">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_cluster_iris_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_cluster_iris.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">K-means Clustering</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example uses a large dataset of faces to learn a set of 20 x 20 images patches that constitute faces.">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_dict_face_patches_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_dict_face_patches.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Online learning of a dictionary of parts of faces</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Plot Hierarchical Clustering Dendrogram">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_agglomerative_dendrogram_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_agglomerative_dendrogram.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Plot Hierarchical Clustering Dendrogram</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example uses spectral_clustering on a graph created from voxel-to-voxel difference on an image to break this image into multiple partly-homogeneous regions.">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_coin_segmentation_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_coin_segmentation.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Segmenting the picture of greek coins in regions</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Silhouette analysis can be used to study the separation distance between the resulting clusters. The silhouette plot displays a measure of how close each point in one cluster is to points in the neighboring clusters and thus provides a way to assess parameters like number of clusters visually. This measure has a range of [-1, 1].">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_kmeans_silhouette_analysis_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_kmeans_silhouette_analysis.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Selecting the number of clusters with silhouette analysis on KMeans clustering</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example, an image with connected circles is generated and spectral clustering is used to separate the circles.">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_segmentation_toy_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_segmentation_toy.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Spectral clustering for image segmentation</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="An illustration of various linkage option for agglomerative clustering on a 2D embedding of the digits dataset.">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_digits_linkage_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_digits_linkage.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Various Agglomerative Clustering on a 2D embedding of digits</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how one can use KBinsDiscretizer to perform vector quantization on a set of toy image, the raccoon face.">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_face_compress_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_face_compress.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Vector Quantization Example</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Covariance estimation
---------------------

Examples concerning the :mod:`sklearn.covariance` module.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The usual covariance maximum likelihood estimate can be regularized using shrinkage. Ledoit and Wolf proposed a close formula to compute the asymptotically optimal shrinkage parameter (minimizing a MSE criterion), yielding the Ledoit-Wolf covariance estimate.">

.. only:: html

  .. image:: /auto_examples/covariance/images/thumb/sphx_glr_plot_lw_vs_oas_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_covariance_plot_lw_vs_oas.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Ledoit-Wolf vs OAS estimation</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows covariance estimation with Mahalanobis distances on Gaussian distributed data.">

.. only:: html

  .. image:: /auto_examples/covariance/images/thumb/sphx_glr_plot_mahalanobis_distances_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_covariance_plot_mahalanobis_distances.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Robust covariance estimation and Mahalanobis distances relevance</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The usual covariance maximum likelihood estimate is very sensitive to the presence of outliers in the data set. In such a case, it would be better to use a robust estimator of covariance to guarantee that the estimation is resistant to &quot;erroneous&quot; observations in the data set. [1]_, [2]_">

.. only:: html

  .. image:: /auto_examples/covariance/images/thumb/sphx_glr_plot_robust_vs_empirical_covariance_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_covariance_plot_robust_vs_empirical_covariance.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Robust vs Empirical covariance estimate</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="When working with covariance estimation, the usual approach is to use a maximum likelihood estimator, such as the EmpiricalCovariance. It is unbiased, i.e. it converges to the true (population) covariance when given many observations. However, it can also be beneficial to regularize it, in order to reduce its variance; this, in turn, introduces some bias. This example illustrates the simple regularization used in shrunk_covariance estimators. In particular, it focuses on how to set the amount of regularization, i.e. how to choose the bias-variance trade-off.">

.. only:: html

  .. image:: /auto_examples/covariance/images/thumb/sphx_glr_plot_covariance_estimation_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_covariance_plot_covariance_estimation.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Using the GraphicalLasso estimator to learn a covariance and sparse precision from a small number of samples.">

.. only:: html

  .. image:: /auto_examples/covariance/images/thumb/sphx_glr_plot_sparse_cov_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_covariance_plot_sparse_cov.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Sparse inverse covariance estimation</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Cross decomposition
-------------------

Examples concerning the :mod:`sklearn.cross_decomposition` module.




.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Simple usage of various cross decomposition algorithms:">

.. only:: html

  .. image:: /auto_examples/cross_decomposition/images/thumb/sphx_glr_plot_compare_cross_decomposition_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cross_decomposition_plot_compare_cross_decomposition.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Compare cross decomposition methods</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example compares Principal Component Regression (PCR) and Partial Least Squares Regression (PLS) on a toy dataset. Our goal is to illustrate how PLS can outperform PCR when the target is strongly correlated with some directions in the data that have a low variance.">

.. only:: html

  .. image:: /auto_examples/cross_decomposition/images/thumb/sphx_glr_plot_pcr_vs_pls_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cross_decomposition_plot_pcr_vs_pls.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Principal Component Regression vs Partial Least Squares Regression</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Dataset examples
-----------------------

Examples concerning the :mod:`sklearn.datasets` module.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example plots several randomly generated classification datasets. For easy visualization, all datasets have 2 features, plotted on the x and y axis. The color of each point represents its class label.">

.. only:: html

  .. image:: /auto_examples/datasets/images/thumb/sphx_glr_plot_random_dataset_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_datasets_plot_random_dataset.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Plot randomly generated classification dataset</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This illustrates the make_multilabel_classification dataset generator. Each sample consists of counts of two features (up to 50 in total), which are differently distributed in each of two classes.">

.. only:: html

  .. image:: /auto_examples/datasets/images/thumb/sphx_glr_plot_random_multilabel_dataset_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_datasets_plot_random_multilabel_dataset.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Plot randomly generated multilabel dataset</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This dataset is made up of 1797 8x8 images. Each image, like the one shown below, is of a hand-written digit. In order to utilize an 8x8 figure like this, we&#x27;d have to first transform it into a feature vector with length 64.">

.. only:: html

  .. image:: /auto_examples/datasets/images/thumb/sphx_glr_plot_digits_last_image_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_datasets_plot_digits_last_image.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">The Digit Dataset</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The rows being the samples and the columns being: Sepal Length, Sepal Width, Petal Length and Petal Width.">

.. only:: html

  .. image:: /auto_examples/datasets/images/thumb/sphx_glr_plot_iris_dataset_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_datasets_plot_iris_dataset.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">The Iris Dataset</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Decision Trees
--------------

Examples concerning the :mod:`sklearn.tree` module.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A 1D regression with decision tree.">

.. only:: html

  .. image:: /auto_examples/tree/images/thumb/sphx_glr_plot_tree_regression_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_tree_plot_tree_regression.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Decision Tree Regression</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="An example to illustrate multi-output regression with decision tree.">

.. only:: html

  .. image:: /auto_examples/tree/images/thumb/sphx_glr_plot_tree_regression_multioutput_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_tree_plot_tree_regression_multioutput.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Multi-output Decision Tree Regression</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Plot the decision surface of a decision tree trained on pairs of features of the iris dataset.">

.. only:: html

  .. image:: /auto_examples/tree/images/thumb/sphx_glr_plot_iris_dtc_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_tree_plot_iris_dtc.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Plot the decision surface of decision trees trained on the iris dataset</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The DecisionTreeClassifier provides parameters such as min_samples_leaf and max_depth to prevent a tree from overfiting. Cost complexity pruning provides another option to control the size of a tree. In DecisionTreeClassifier, this pruning technique is parameterized by the cost complexity parameter, ccp_alpha. Greater values of ccp_alpha increase the number of nodes pruned. Here we only show the effect of ccp_alpha on regularizing the trees and how to choose a ccp_alpha based on validation scores.">

.. only:: html

  .. image:: /auto_examples/tree/images/thumb/sphx_glr_plot_cost_complexity_pruning_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Post pruning decision trees with cost complexity pruning</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The decision tree structure can be analysed to gain further insight on the relation between the features and the target to predict. In this example, we show how to retrieve:">

.. only:: html

  .. image:: /auto_examples/tree/images/thumb/sphx_glr_plot_unveil_tree_structure_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Understanding the decision tree structure</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Decomposition
-------------

Examples concerning the :mod:`sklearn.decomposition` module.




.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="An example of estimating sources from noisy data.">

.. only:: html

  .. image:: /auto_examples/decomposition/images/thumb/sphx_glr_plot_ica_blind_source_separation_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_decomposition_plot_ica_blind_source_separation.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Blind source separation using FastICA</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The Iris dataset represents 3 kind of Iris flowers (Setosa, Versicolour and Virginica) with 4 attributes: sepal length, sepal width, petal length and petal width.">

.. only:: html

  .. image:: /auto_examples/decomposition/images/thumb/sphx_glr_plot_pca_vs_lda_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_decomposition_plot_pca_vs_lda.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Comparison of LDA and PCA 2D projection of Iris dataset</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example applies to olivetti_faces_dataset different unsupervised matrix decomposition (dimension reduction) methods from the module sklearn.decomposition (see the documentation chapter decompositions).">

.. only:: html

  .. image:: /auto_examples/decomposition/images/thumb/sphx_glr_plot_faces_decomposition_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_decomposition_plot_faces_decomposition.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Faces dataset decompositions</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Investigating the Iris dataset, we see that sepal length, petal length and petal width are highly correlated. Sepal width is less redundant. Matrix decomposition techniques can uncover these latent patterns. Applying rotations to the resulting components does not inherently improve the predictive value of the derived latent space, but can help visualise their structure; here, for example, the varimax rotation, which is found by maximizing the squared variances of the weights, finds a structure where the second component only loads positively on sepal width.">

.. only:: html

  .. image:: /auto_examples/decomposition/images/thumb/sphx_glr_plot_varimax_fa_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_decomposition_plot_varimax_fa.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Factor Analysis (with rotation) to visualize patterns</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates visually in the feature space a comparison by results using two different component analysis techniques.">

.. only:: html

  .. image:: /auto_examples/decomposition/images/thumb/sphx_glr_plot_ica_vs_pca_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_decomposition_plot_ica_vs_pca.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">FastICA on 2D point clouds</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="An example comparing the effect of reconstructing noisy fragments of a raccoon face image using firstly online DictionaryLearning and various transform methods.">

.. only:: html

  .. image:: /auto_examples/decomposition/images/thumb/sphx_glr_plot_image_denoising_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_decomposition_plot_image_denoising.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Image denoising using dictionary learning</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Incremental principal component analysis (IPCA) is typically used as a replacement for principal component analysis (PCA) when the dataset to be decomposed is too large to fit in memory. IPCA builds a low-rank approximation for the input data using an amount of memory which is independent of the number of input data samples. It is still dependent on the input data features, but changing the batch size allows for control of memory usage.">

.. only:: html

  .. image:: /auto_examples/decomposition/images/thumb/sphx_glr_plot_incremental_pca_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_decomposition_plot_incremental_pca.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Incremental PCA</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows the difference between the Principal Components Analysis (~sklearn.decomposition.PCA) and its kernelized version (~sklearn.decomposition.KernelPCA).">

.. only:: html

  .. image:: /auto_examples/decomposition/images/thumb/sphx_glr_plot_kernel_pca_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_decomposition_plot_kernel_pca.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Kernel PCA</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Probabilistic PCA and Factor Analysis are probabilistic models. The consequence is that the likelihood of new data can be used for model selection and covariance estimation. Here we compare PCA and FA with cross-validation on low rank data corrupted with homoscedastic noise (noise variance is the same for each feature) or heteroscedastic noise (noise variance is the different for each feature). In a second step we compare the model likelihood to the likelihoods obtained from shrinkage covariance estimators.">

.. only:: html

  .. image:: /auto_examples/decomposition/images/thumb/sphx_glr_plot_pca_vs_fa_model_selection_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_decomposition_plot_pca_vs_fa_model_selection.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Model selection with Probabilistic PCA and Factor Analysis (FA)</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Principal Component Analysis applied to the Iris dataset.">

.. only:: html

  .. image:: /auto_examples/decomposition/images/thumb/sphx_glr_plot_pca_iris_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_decomposition_plot_pca_iris.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">PCA example with Iris Data-set</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Transform a signal as a sparse combination of Ricker wavelets. This example visually compares different sparse coding methods using the SparseCoder estimator. The Ricker (also known as Mexican hat or the second derivative of a Gaussian) is not a particularly good kernel to represent piecewise constant signals like this one. It can therefore be seen how much adding different widths of atoms matters and it therefore motivates learning the dictionary to best fit your type of signals.">

.. only:: html

  .. image:: /auto_examples/decomposition/images/thumb/sphx_glr_plot_sparse_coding_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_decomposition_plot_sparse_coding.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Sparse coding with a precomputed dictionary</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Developing Estimators
---------------------

Examples concerning the development of Custom Estimator.


.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The __sklearn_is_fitted__ method is a convention used in scikit-learn for checking whether an estimator object has been fitted or not. This method is typically implemented in custom estimator classes that are built on top of scikit-learn&#x27;s base classes like BaseEstimator or its subclasses.">

.. only:: html

  .. image:: /auto_examples/developing_estimators/images/thumb/sphx_glr_sklearn_is_fitted_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">__sklearn_is_fitted__ as Developer API</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Ensemble methods
----------------

Examples concerning the :mod:`sklearn.ensemble` module.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example, we will compare the training times and prediction performances of HistGradientBoostingRegressor with different encoding strategies for categorical features. In particular, we will evaluate:">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_gradient_boosting_categorical_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_gradient_boosting_categorical.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Categorical Feature Support in Gradient Boosting</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Stacking refers to a method to blend estimators. In this strategy, some estimators are individually fitted on some training data while a final estimator is trained using the stacked predictions of these base estimators.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_stack_predictors_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_stack_predictors.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Combine predictors using stacking</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example we compare the performance of Random Forest (RF) and Histogram Gradient Boosting (HGBT) models in terms of score and computation time for a regression dataset, though all the concepts here presented apply to classification as well.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_forest_hist_grad_boosting_comparison_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_forest_hist_grad_boosting_comparison.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Comparing Random Forests and Histogram Gradient Boosting models</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="An example to compare multi-output regression with random forest and the multiclass meta-estimator.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_random_forest_regression_multioutput_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_random_forest_regression_multioutput.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Comparing random forests and the multi-output meta estimator</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A decision tree is boosted using the AdaBoost.R2 [1]_ algorithm on a 1D sinusoidal dataset with a small amount of Gaussian noise. 299 boosts (300 decision trees) is compared with a single decision tree regressor. As the number of boosts is increased the regressor can fit more detail.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_adaboost_regression_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_adaboost_regression.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Decision Tree Regression with AdaBoost</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Gradient Boosting is an ensemble technique that combines multiple weak learners, typically decision trees, to create a robust and powerful predictive model. It does so in an iterative fashion, where each new stage (tree) corrects the errors of the previous ones.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_gradient_boosting_early_stopping_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_gradient_boosting_early_stopping.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Early stopping in Gradient Boosting</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows the use of a forest of trees to evaluate the importance of features on an artificial classification task. The blue bars are the feature importances of the forest, along with their inter-trees variability represented by the error bars.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_forest_importances_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_forest_importances.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Feature importances with a forest of trees</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Transform your features into a higher dimensional, sparse space. Then train a linear model on these features.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_feature_transformation_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_feature_transformation.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Feature transformations with ensembles of trees</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="histogram_based_gradient_boosting (HGBT) models may be one of the most useful supervised learning models in scikit-learn. They are based on a modern gradient boosting implementation comparable to LightGBM and XGBoost. As such, HGBT models are more feature rich than and often outperform alternative models like random forests, especially when the number of samples is larger than some ten thousands (see sphx_glr_auto_examples_ensemble_plot_forest_hist_grad_boosting_comparison.py).">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_hgbt_regression_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_hgbt_regression.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Features in Histogram Gradient Boosting Trees</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Gradient Boosting Out-of-Bag estimates">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_gradient_boosting_oob_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_gradient_boosting_oob.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Gradient Boosting Out-of-Bag estimates</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates Gradient Boosting to produce a predictive model from an ensemble of weak predictive models. Gradient boosting can be used for regression and classification problems. Here, we will train a model to tackle a diabetes regression task. We will obtain the results from GradientBoostingRegressor with least squares loss and 500 regression trees of depth 4.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_gradient_boosting_regression_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_gradient_boosting_regression.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Gradient Boosting regression</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Illustration of the effect of different regularization strategies for Gradient Boosting. The example is taken from Hastie et al 2009 [1]_.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_gradient_boosting_regularization_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_gradient_boosting_regularization.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Gradient Boosting regularization</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="RandomTreesEmbedding provides a way to map data to a very high-dimensional, sparse representation, which might be beneficial for classification. The mapping is completely unsupervised and very efficient.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_random_forest_embedding_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_random_forest_embedding.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Hashing feature transformation using Totally Random Trees</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="An example using IsolationForest for anomaly detection.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_isolation_forest_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_isolation_forest.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">IsolationForest example</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates the effect of monotonic constraints on a gradient boosting estimator.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_monotonic_constraints_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_monotonic_constraints.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Monotonic Constraints</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how boosting can improve the prediction accuracy on a multi-label classification problem. It reproduces a similar experiment as depicted by Figure 1 in Zhu et al [1]_.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_adaboost_multiclass_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_adaboost_multiclass.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Multi-class AdaBoosted Decision Trees</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The RandomForestClassifier is trained using bootstrap aggregation, where each new tree is fit from a bootstrap sample of the training observations z_i = (x_i, y_i). The out-of-bag (OOB) error is the average error for each z_i calculated using predictions from the trees that do not contain z_i in their respective bootstrap sample. This allows the RandomForestClassifier to be fit and validated whilst being trained [1]_.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_ensemble_oob_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_ensemble_oob.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">OOB Errors for Random Forests</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows the use of a forest of trees to evaluate the impurity based importance of the pixels in an image classification task on the faces dataset. The hotter the pixel, the more important it is.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_forest_importances_faces_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_forest_importances_faces.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Pixel importances with a parallel forest of trees</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Plot the class probabilities of the first sample in a toy dataset predicted by three different classifiers and averaged by the VotingClassifier.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_voting_probas_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_voting_probas.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Plot class probabilities calculated by the VotingClassifier</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A voting regressor is an ensemble meta-estimator that fits several base regressors, each on the whole dataset. Then it averages the individual predictions to form a final prediction. We will use three different regressors to predict the data: GradientBoostingRegressor, RandomForestRegressor, and LinearRegression). Then the above 3 regressors will be used for the VotingRegressor.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_voting_regressor_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_voting_regressor.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Plot individual and voting regression predictions</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Plot the decision boundaries of a VotingClassifier for two features of the Iris dataset.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_voting_decision_regions_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_voting_decision_regions.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Plot the decision boundaries of a VotingClassifier</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Plot the decision surfaces of forests of randomized trees trained on pairs of features of the iris dataset.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_forest_iris_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_forest_iris.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Plot the decision surfaces of ensembles of trees on the iris dataset</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how quantile regression can be used to create prediction intervals. See sphx_glr_auto_examples_ensemble_plot_hgbt_regression.py for an example showcasing some other features of HistGradientBoostingRegressor.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_gradient_boosting_quantile_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_gradient_boosting_quantile.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Prediction Intervals for Gradient Boosting Regression</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates and compares the bias-variance decomposition of the expected mean squared error of a single estimator against a bagging ensemble.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_bias_variance_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_bias_variance.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Single estimator versus bagging: bias-variance decomposition</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example fits an AdaBoosted decision stump on a non-linearly separable classification dataset composed of two &quot;Gaussian quantiles&quot; clusters (see sklearn.datasets.make_gaussian_quantiles) and plots the decision boundary and decision scores. The distributions of decision scores are shown separately for samples of class A and B. The predicted class label for each sample is determined by the sign of the decision score. Samples with decision scores greater than zero are classified as B, and are otherwise classified as A. The magnitude of a decision score determines the degree of likeness with the predicted class label. Additionally, a new dataset could be constructed containing a desired purity of class B, for example, by only selecting samples with a decision score above some value.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_adaboost_twoclass_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_adaboost_twoclass.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Two-class AdaBoost</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Examples based on real world datasets
-------------------------------------

Applications to real world problems with some medium sized datasets or
interactive user interface.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows the reconstruction of an image from a set of parallel projections, acquired along different angles. Such a dataset is acquired in computed tomography (CT).">

.. only:: html

  .. image:: /auto_examples/applications/images/thumb/sphx_glr_plot_tomography_l1_reconstruction_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_applications_plot_tomography_l1_reconstruction.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Compressive sensing: tomography reconstruction with L1 prior (Lasso)</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The dataset used in this example is a preprocessed excerpt of the &quot;Labeled Faces in the Wild&quot;, aka LFW_:">

.. only:: html

  .. image:: /auto_examples/applications/images/thumb/sphx_glr_plot_face_recognition_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_applications_plot_face_recognition.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Faces recognition example using eigenfaces and SVMs</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use KernelPCA to denoise images. In short, we take advantage of the approximation function learned during fit to reconstruct the original image.">

.. only:: html

  .. image:: /auto_examples/applications/images/thumb/sphx_glr_plot_digits_denoising_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_applications_plot_digits_denoising.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Image denoising using kernel PCA</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates how Polars-engineered lagged features can be used for time series forecasting with HistGradientBoostingRegressor on the Bike Sharing Demand dataset.">

.. only:: html

  .. image:: /auto_examples/applications/images/thumb/sphx_glr_plot_time_series_lagged_features_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_applications_plot_time_series_lagged_features.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Lagged features for time series forecasting</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Demonstrate how model complexity influences both prediction accuracy and computational performance.">

.. only:: html

  .. image:: /auto_examples/applications/images/thumb/sphx_glr_plot_model_complexity_influence_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_applications_plot_model_complexity_influence.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Model Complexity Influence</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This is an example showing how scikit-learn can be used for classification using an out-of-core approach: learning from data that doesn&#x27;t fit into main memory. We make use of an online classifier, i.e., one that supports the partial_fit method, that will be fed with batches of examples. To guarantee that the features space remains the same over time we leverage a HashingVectorizer that will project each example into the same feature space. This is especially useful in the case of text classification where new features (words) may appear in each batch.">

.. only:: html

  .. image:: /auto_examples/applications/images/thumb/sphx_glr_plot_out_of_core_classification_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_applications_plot_out_of_core_classification.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Out-of-core classification of text documents</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates the need for robust covariance estimation on a real data set. It is useful both for outlier detection and for a better understanding of the data structure.">

.. only:: html

  .. image:: /auto_examples/applications/images/thumb/sphx_glr_plot_outlier_detection_wine_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_applications_plot_outlier_detection_wine.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Outlier detection on a real data set</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This is an example showing the prediction latency of various scikit-learn estimators.">

.. only:: html

  .. image:: /auto_examples/applications/images/thumb/sphx_glr_plot_prediction_latency_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_applications_plot_prediction_latency.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Prediction Latency</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Modeling species&#x27; geographic distributions is an important problem in conservation biology. In this example, we model the geographic distribution of two South American mammals given past observations and 14 environmental variables. Since we have only positive examples (there are no unsuccessful observations), we cast this problem as a density estimation problem and use the OneClassSVM as our modeling tool. The dataset is provided by Phillips et. al. (2006). If available, the example uses basemap to plot the coast lines and national boundaries of South America.">

.. only:: html

  .. image:: /auto_examples/applications/images/thumb/sphx_glr_plot_species_distribution_modeling_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_applications_plot_species_distribution_modeling.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Species distribution modeling</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This notebook introduces different strategies to leverage time-related features for a bike sharing demand regression task that is highly dependent on business cycles (days, weeks, months) and yearly season cycles.">

.. only:: html

  .. image:: /auto_examples/applications/images/thumb/sphx_glr_plot_cyclical_feature_engineering_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_applications_plot_cyclical_feature_engineering.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Time-related feature engineering</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This is an example of applying NMF and LatentDirichletAllocation on a corpus of documents and extract additive models of the topic structure of the corpus.  The output is a plot of topics, each represented as bar plot using top few words based on weights.">

.. only:: html

  .. image:: /auto_examples/applications/images/thumb/sphx_glr_plot_topics_extraction_with_nmf_lda_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_applications_plot_topics_extraction_with_nmf_lda.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example employs several unsupervised learning techniques to extract the stock market structure from variations in historical quotes.">

.. only:: html

  .. image:: /auto_examples/applications/images/thumb/sphx_glr_plot_stock_market_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_applications_plot_stock_market.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Visualizing the stock market structure</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A classical way to assert the relative importance of vertices in a graph is to compute the principal eigenvector of the adjacency matrix so as to assign to each vertex the values of the components of the first eigenvector as a centrality score:">

.. only:: html

  .. image:: /auto_examples/applications/images/thumb/sphx_glr_wikipedia_principal_eigenvector_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_applications_wikipedia_principal_eigenvector.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Wikipedia principal eigenvector</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Feature Selection
-----------------------

Examples concerning the :mod:`sklearn.feature_selection` module.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates the differences between univariate F-test statistics and mutual information.">

.. only:: html

  .. image:: /auto_examples/feature_selection/images/thumb/sphx_glr_plot_f_test_vs_mi_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_feature_selection_plot_f_test_vs_mi.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Comparison of F-test and mutual information</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates and compares two approaches for feature selection: SelectFromModel which is based on feature importance, and SequentialFeatureSelector which relies on a greedy approach.">

.. only:: html

  .. image:: /auto_examples/feature_selection/images/thumb/sphx_glr_plot_select_from_model_diabetes_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_feature_selection_plot_select_from_model_diabetes.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Model-based and sequential feature selection</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how a feature selection can be easily integrated within a machine learning pipeline.">

.. only:: html

  .. image:: /auto_examples/feature_selection/images/thumb/sphx_glr_plot_feature_selection_pipeline_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_feature_selection_plot_feature_selection_pipeline.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Pipeline ANOVA SVM</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates how Recursive Feature Elimination (~sklearn.feature_selection.RFE) can be used to determine the importance of individual pixels for classifying handwritten digits. RFE recursively removes the least significant features, assigning ranks based on their importance, where higher ranking_ values denote lower importance. The ranking is visualized using both shades of blue and pixel annotations for clarity. As expected, pixels positioned at the center of the image tend to be more predictive than those near the edges.">

.. only:: html

  .. image:: /auto_examples/feature_selection/images/thumb/sphx_glr_plot_rfe_digits_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_feature_selection_plot_rfe_digits.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Recursive feature elimination</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A Recursive Feature Elimination (RFE) example with automatic tuning of the number of features selected with cross-validation.">

.. only:: html

  .. image:: /auto_examples/feature_selection/images/thumb/sphx_glr_plot_rfe_with_cross_validation_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_feature_selection_plot_rfe_with_cross_validation.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Recursive feature elimination with cross-validation</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This notebook is an example of using univariate feature selection to improve classification accuracy on a noisy dataset.">

.. only:: html

  .. image:: /auto_examples/feature_selection/images/thumb/sphx_glr_plot_feature_selection_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_feature_selection_plot_feature_selection.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Univariate Feature Selection</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Gaussian Mixture Models
-----------------------

Examples concerning the :mod:`sklearn.mixture` module.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example plots the ellipsoids obtained from a toy dataset (mixture of three Gaussians) fitted by the BayesianGaussianMixture class models with a Dirichlet distribution prior (``weight_concentration_prior_type=&#x27;dirichlet_distribution&#x27;``) and a Dirichlet process prior (``weight_concentration_prior_type=&#x27;dirichlet_process&#x27;``). On each figure, we plot the results for three different values of the weight concentration prior.">

.. only:: html

  .. image:: /auto_examples/mixture/images/thumb/sphx_glr_plot_concentration_prior_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_mixture_plot_concentration_prior.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Concentration Prior Type Analysis of Variation Bayesian Gaussian Mixture</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Plot the density estimation of a mixture of two Gaussians. Data is generated from two Gaussians with different centers and covariance matrices.">

.. only:: html

  .. image:: /auto_examples/mixture/images/thumb/sphx_glr_plot_gmm_pdf_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_mixture_plot_gmm_pdf.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Density Estimation for a Gaussian mixture</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Examples of the different methods of initialization in Gaussian Mixture Models">

.. only:: html

  .. image:: /auto_examples/mixture/images/thumb/sphx_glr_plot_gmm_init_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_mixture_plot_gmm_init.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">GMM Initialization Methods</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Demonstration of several covariances types for Gaussian mixture models.">

.. only:: html

  .. image:: /auto_examples/mixture/images/thumb/sphx_glr_plot_gmm_covariances_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_mixture_plot_gmm_covariances.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">GMM covariances</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Plot the confidence ellipsoids of a mixture of two Gaussians obtained with Expectation Maximisation (``GaussianMixture`` class) and Variational Inference (``BayesianGaussianMixture`` class models with a Dirichlet process prior).">

.. only:: html

  .. image:: /auto_examples/mixture/images/thumb/sphx_glr_plot_gmm_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_mixture_plot_gmm.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Gaussian Mixture Model Ellipsoids</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows that model selection can be performed with Gaussian Mixture Models (GMM) using information-theory criteria &lt;aic_bic&gt;. Model selection concerns both the covariance type and the number of components in the model.">

.. only:: html

  .. image:: /auto_examples/mixture/images/thumb/sphx_glr_plot_gmm_selection_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_mixture_plot_gmm_selection.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Gaussian Mixture Model Selection</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the behavior of Gaussian mixture models fit on data that was not sampled from a mixture of Gaussian random variables. The dataset is formed by 100 points loosely spaced following a noisy sine curve. There is therefore no ground truth value for the number of Gaussian components.">

.. only:: html

  .. image:: /auto_examples/mixture/images/thumb/sphx_glr_plot_gmm_sin_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_mixture_plot_gmm_sin.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Gaussian Mixture Model Sine Curve</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Gaussian Process for Machine Learning
-------------------------------------

Examples concerning the :mod:`sklearn.gaussian_process` module.




.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows the ability of the WhiteKernel to estimate the noise level in the data. Moreover, we show the importance of kernel hyperparameters initialization.">

.. only:: html

  .. image:: /auto_examples/gaussian_process/images/thumb/sphx_glr_plot_gpr_noisy_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_noisy.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Ability of Gaussian process regression (GPR) to estimate data noise-level</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates differences between a kernel ridge regression and a Gaussian process regression.">

.. only:: html

  .. image:: /auto_examples/gaussian_process/images/thumb/sphx_glr_plot_compare_gpr_krr_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_gaussian_process_plot_compare_gpr_krr.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Comparison of kernel ridge and Gaussian process regression</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example is based on Section 5.4.3 of &quot;Gaussian Processes for Machine Learning&quot; [1]_. It illustrates an example of complex kernel engineering and hyperparameter optimization using gradient ascent on the log-marginal-likelihood. The data consists of the monthly average atmospheric CO2 concentrations (in parts per million by volume (ppm)) collected at the Mauna Loa Observatory in Hawaii, between 1958 and 2001. The objective is to model the CO2 concentration as a function of the time t and extrapolate for years after 2001.">

.. only:: html

  .. image:: /auto_examples/gaussian_process/images/thumb/sphx_glr_plot_gpr_co2_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_co2.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Forecasting of CO2 level on Mona Loa dataset using Gaussian process regression (GPR)</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A simple one-dimensional regression example computed in two different ways:">

.. only:: html

  .. image:: /auto_examples/gaussian_process/images/thumb/sphx_glr_plot_gpr_noisy_targets_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_noisy_targets.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Gaussian Processes regression: basic introductory example</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates the predicted probability of GPC for an isotropic and anisotropic RBF kernel on a two-dimensional version for the iris-dataset. The anisotropic RBF kernel obtains slightly higher log-marginal-likelihood by assigning different length-scales to the two feature dimensions.">

.. only:: html

  .. image:: /auto_examples/gaussian_process/images/thumb/sphx_glr_plot_gpc_iris_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_gaussian_process_plot_gpc_iris.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Gaussian process classification (GPC) on iris dataset</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates the use of Gaussian processes for regression and classification tasks on data that are not in fixed-length feature vector form. This is achieved through the use of kernel functions that operates directly on discrete structures such as variable-length sequences, trees, and graphs.">

.. only:: html

  .. image:: /auto_examples/gaussian_process/images/thumb/sphx_glr_plot_gpr_on_structured_data_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_on_structured_data.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Gaussian processes on discrete data structures</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates GPC on XOR data. Compared are a stationary, isotropic kernel (RBF) and a non-stationary kernel (DotProduct). On this particular dataset, the DotProduct kernel obtains considerably better results because the class-boundaries are linear and coincide with the coordinate axes. In general, stationary kernels often obtain better results.">

.. only:: html

  .. image:: /auto_examples/gaussian_process/images/thumb/sphx_glr_plot_gpc_xor_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_gaussian_process_plot_gpc_xor.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Illustration of Gaussian process classification (GPC) on the XOR dataset</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates the prior and posterior of a GaussianProcessRegressor with different kernels. Mean, standard deviation, and 5 samples are shown for both prior and posterior distributions.">

.. only:: html

  .. image:: /auto_examples/gaussian_process/images/thumb/sphx_glr_plot_gpr_prior_posterior_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_prior_posterior.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Illustration of prior and posterior Gaussian process for different kernels</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A two-dimensional classification example showing iso-probability lines for the predicted probabilities.">

.. only:: html

  .. image:: /auto_examples/gaussian_process/images/thumb/sphx_glr_plot_gpc_isoprobability_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_gaussian_process_plot_gpc_isoprobability.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Iso-probability lines for Gaussian Processes classification (GPC)</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates the predicted probability of GPC for an RBF kernel with different choices of the hyperparameters. The first figure shows the predicted probability of GPC with arbitrarily chosen hyperparameters and with the hyperparameters corresponding to the maximum log-marginal-likelihood (LML).">

.. only:: html

  .. image:: /auto_examples/gaussian_process/images/thumb/sphx_glr_plot_gpc_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_gaussian_process_plot_gpc.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Probabilistic predictions with Gaussian process classification (GPC)</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Generalized Linear Models
-------------------------

Examples concerning the :mod:`sklearn.linear_model` module.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example compares two different bayesian regressors:">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_ard_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_ard.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Comparing Linear Bayesian Regressors</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Comparing various online solvers">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_sgd_comparison_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_sgd_comparison.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Comparing various online solvers</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Computes a Bayesian Ridge Regression of Sinusoids.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_bayesian_ridge_curvefit_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_bayesian_ridge_curvefit.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Curve Fitting with Bayesian Ridge Regression</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Stochastic Gradient Descent is an optimization technique which minimizes a loss function in a stochastic fashion, performing a gradient descent step sample by sample. In particular, it is a very efficient method to fit linear models.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_sgd_early_stopping_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_sgd_early_stopping.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Early stopping of Stochastic Gradient Descent</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The following example shows how to precompute the gram matrix while using weighted samples with an ElasticNet.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_elastic_net_precomputed_gram_matrix_with_weighted_samples_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_elastic_net_precomputed_gram_matrix_with_weighted_samples.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Fitting an Elastic Net with a precomputed Gram Matrix and Weighted Samples</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Fit Ridge and HuberRegressor on a dataset with outliers.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_huber_vs_ridge_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_huber_vs_ridge.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">HuberRegressor vs Ridge on dataset with strong outliers</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The multi-task lasso allows to fit multiple regression problems jointly enforcing the selected features to be the same across tasks. This example simulates sequential measurements, each task is a time instant, and the relevant features vary in amplitude over time while being the same. The multi-task lasso imposes that features that are selected at one time point are select for all time point. This makes feature selection by the Lasso more stable.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_multi_task_lasso_support_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_multi_task_lasso_support.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Joint feature selection with multi-task Lasso</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Comparison of the sparsity (percentage of zero coefficients) of solutions when L1, L2 and Elastic-Net penalty are used for different values of C. We can see that large values of C give more freedom to the model.  Conversely, smaller values of C constrain the model more. In the L1 penalty case, this leads to sparser solutions. As expected, the Elastic-Net penalty sparsity is between that of L1 and L2.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_logistic_l1_l2_sparsity_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_logistic_l1_l2_sparsity.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">L1 Penalty and Sparsity in Logistic Regression</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The present example compares three l1-based regression models on a synthetic signal obtained from sparse and correlated features that are further corrupted with additive gaussian noise:">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_lasso_and_elasticnet_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_lasso_and_elasticnet.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">L1-based models for Sparse Signals</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Lasso and elastic net (L1 and L2 penalisation) implemented using a coordinate descent.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_lasso_coordinate_descent_path_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_lasso_coordinate_descent_path.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Lasso and Elastic Net</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example reproduces the example of Fig. 2 of [ZHT2007]_. A LassoLarsIC estimator is fit on a diabetes dataset and the AIC and the BIC criteria are used to select the best model.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_lasso_lars_ic_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_lasso_lars_ic.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Lasso model selection via information criteria</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example focuses on model selection for Lasso models that are linear models with an L1 penalty for regression problems.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_lasso_model_selection_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_lasso_model_selection.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Lasso model selection: AIC-BIC / cross-validation</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="We show that linear_model.Lasso provides the same results for dense and sparse data and that in the case of sparse data the speed is improved.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_lasso_dense_vs_sparse_data_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_lasso_dense_vs_sparse_data.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Lasso on dense and sparse data</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Computes Lasso Path along the regularization parameter using the LARS algorithm on the diabetes dataset. Each color represents a different feature of the coefficient vector, and this is displayed as a function of the regularization parameter.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_lasso_lars_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_lasso_lars.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Lasso path using LARS</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The coefficients, residual sum of squares and the coefficient of determination are also calculated.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_ols_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_ols.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Linear Regression Example</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Show below is a logistic-regression classifiers decision boundaries on the first two dimensions (sepal length and width) of the iris dataset. The datapoints are colored according to their labels.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_iris_logistic_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_iris_logistic.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Logistic Regression 3-class Classifier</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Shown in the plot is how the logistic regression would, in this synthetic dataset, classify values as either 0 or 1, i.e. class one or two, using the logistic curve.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_logistic_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_logistic.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Logistic function</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Here we fit a multinomial logistic regression with L1 penalty on a subset of the MNIST digits classification task. We use the SAGA algorithm for this purpose: this a solver that is fast when the number of samples is significantly larger than the number of features and is able to finely optimize non-smooth objective functions which is the case with the l1-penalty. Test accuracy reaches &gt; 0.8, while weight vectors remains sparse and therefore more easily interpretable.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_sparse_logistic_regression_mnist_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_sparse_logistic_regression_mnist.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">MNIST classification using multinomial logistic + L1</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Comparison of multinomial logistic L1 vs one-versus-rest L1 logistic regression to classify documents from the newgroups20 dataset. Multinomial logistic regression yields more accurate results and is faster to train on the larger scale dataset.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_sparse_logistic_regression_20newsgroups_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_sparse_logistic_regression_20newsgroups.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Multiclass sparse logistic regression on 20newgroups</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example, we fit a linear model with positive constraints on the regression coefficients and compare the estimated coefficients to a classic linear regression.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_nnls_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_nnls.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Non-negative least squares</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how to approximate the solution of sklearn.svm.OneClassSVM in the case of an RBF kernel with sklearn.linear_model.SGDOneClassSVM, a Stochastic Gradient Descent (SGD) version of the One-Class SVM. A kernel approximation is first used in order to apply sklearn.linear_model.SGDOneClassSVM which implements a linear One-Class SVM using SGD.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_sgdocsvm_vs_ocsvm_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_sgdocsvm_vs_ocsvm.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">One-Class SVM versus One-Class SVM using Stochastic Gradient Descent</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Ridge regression is basically minimizing a penalised version of the least-squared function. The penalising shrinks the value of the regression coefficients. Despite the few data points in each dimension, the slope of the prediction is much more stable and the variance in the line itself is greatly reduced, in comparison to that of the standard linear regression">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_ols_ridge_variance_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_ols_ridge_variance.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Ordinary Least Squares and Ridge Regression Variance</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Using orthogonal matching pursuit for recovering a sparse signal from a noisy measurement encoded with a dictionary">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_omp_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_omp.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Orthogonal Matching Pursuit</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Shows the effect of collinearity in the coefficients of an estimator.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_ridge_path_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_ridge_path.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Plot Ridge coefficients as a function of the regularization</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Plot decision surface of multi-class SGD on iris dataset. The hyperplanes corresponding to the three one-versus-all (OVA) classifiers are represented by the dashed lines.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_sgd_iris_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_sgd_iris.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Plot multi-class SGD on the iris dataset</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Plot decision surface of multinomial and One-vs-Rest Logistic Regression. The hyperplanes corresponding to the three One-vs-Rest (OVR) classifiers are represented by the dashed lines.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_logistic_multinomial_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_logistic_multinomial.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Plot multinomial and One-vs-Rest Logistic Regression</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates the use of log-linear Poisson regression on the French Motor Third-Party Liability Claims dataset from [1]_ and compares it with a linear model fitted with the usual least squared error and a non-linear GBRT model fitted with the Poisson loss (and a log-link).">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_poisson_regression_non_normal_loss_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_poisson_regression_non_normal_loss.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Poisson regression and non-normal loss</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates how to approximate a function with polynomials up to degree degree by using ridge regression. We show two different ways given n_samples of 1d points x_i:">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_polynomial_interpolation_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_polynomial_interpolation.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Polynomial and Spline interpolation</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how quantile regression can predict non-trivial conditional quantiles.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_quantile_regression_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_quantile_regression.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Quantile regression</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip=" Train l1-penalized logistic regression models on a binary classification problem derived from the Iris dataset.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_logistic_path_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_logistic_path.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Regularization path of L1- Logistic Regression</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A model that overfits learns the training data too well, capturing both the underlying patterns and the noise in the data. However, when applied to unseen data, the learned associations may not hold. We normally detect this when we apply our trained predictions to the test data and see the statistical performance drop significantly compared to the training data.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_ridge_coeffs_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_ridge_coeffs.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Ridge coefficients as a function of the L2 Regularization</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Here a sine function is fit with a polynomial of order 3, for values close to zero.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_robust_fit_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_robust_fit.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Robust linear estimator fitting</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example, we see how to robustly fit a linear model to faulty data using the ransac_regression algorithm.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_ransac_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_ransac.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Robust linear model estimation using RANSAC</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Plot the maximum margin separating hyperplane within a two-class separable dataset using a linear Support Vector Machines classifier trained using SGD.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_sgd_separating_hyperplane_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_sgd_separating_hyperplane.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">SGD: Maximum margin separating hyperplane</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Contours of where the penalty is equal to 1 for the three penalties L1, L2 and elastic-net.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_sgd_penalties_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_sgd_penalties.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">SGD: Penalties</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Plot decision function of a weighted dataset, where the size of points is proportional to its weight.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_sgd_weighted_samples_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_sgd_weighted_samples.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">SGD: Weighted samples</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A plot that compares the various convex loss functions supported by SGDClassifier .">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_sgd_loss_functions_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_sgd_loss_functions.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">SGD: convex loss functions</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Features 1 and 2 of the diabetes-dataset are fitted and plotted below. It illustrates that although feature 2 has a strong coefficient on the full model, it does not give us much regarding y when compared to just feature 1.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_ols_3d_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_ols_3d.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Sparsity Example: Fitting only features 1  and 2</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Computes a Theil-Sen Regression on a synthetic dataset.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_theilsen_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_theilsen.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Theil-Sen Regression</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates the use of Poisson, Gamma and Tweedie regression on the French Motor Third-Party Liability Claims dataset, and is inspired by an R tutorial [1]_.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_tweedie_regression_insurance_claims_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_tweedie_regression_insurance_claims.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Tweedie regression on insurance claims</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Inspection
----------

Examples related to the :mod:`sklearn.inspection` module.




.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In linear models, the target value is modeled as a linear combination of the features (see the linear_model User Guide section for a description of a set of linear models available in scikit-learn). Coefficients in multiple linear models represent the relationship between the given feature, X_i and the target, y, assuming that all the other features remain constant (conditional dependence). This is different from plotting X_i versus y and fitting a linear relationship: in that case all possible values of the other features are taken into account in the estimation (marginal dependence).">

.. only:: html

  .. image:: /auto_examples/inspection/images/thumb/sphx_glr_plot_linear_model_coefficient_interpretation_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_inspection_plot_linear_model_coefficient_interpretation.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Common pitfalls in the interpretation of coefficients of linear models</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Machine Learning models are great for measuring statistical associations. Unfortunately, unless we&#x27;re willing to make strong assumptions about the data, those models are unable to infer causal effects.">

.. only:: html

  .. image:: /auto_examples/inspection/images/thumb/sphx_glr_plot_causal_interpretation_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_inspection_plot_causal_interpretation.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Failure of Machine Learning to infer causal effects</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Partial dependence plots show the dependence between the target function [2]_ and a set of features of interest, marginalizing over the values of all other features (the complement features). Due to the limits of human perception, the size of the set of features of interest must be small (usually, one or two) thus they are usually chosen among the most important features.">

.. only:: html

  .. image:: /auto_examples/inspection/images/thumb/sphx_glr_plot_partial_dependence_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_inspection_plot_partial_dependence.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Partial Dependence and Individual Conditional Expectation Plots</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example, we will compare the impurity-based feature importance of RandomForestClassifier with the permutation importance on the titanic dataset using permutation_importance. We will show that the impurity-based feature importance can inflate the importance of numerical features.">

.. only:: html

  .. image:: /auto_examples/inspection/images/thumb/sphx_glr_plot_permutation_importance_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_inspection_plot_permutation_importance.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Permutation Importance vs Random Forest Feature Importance (MDI)</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example, we compute the permutation_importance of the features to a trained RandomForestClassifier using the breast_cancer_dataset. The model can easily get about 97% accuracy on a test dataset. Because this dataset contains multicollinear features, the permutation importance shows that none of the features are important, in contradiction with the high test accuracy.">

.. only:: html

  .. image:: /auto_examples/inspection/images/thumb/sphx_glr_plot_permutation_importance_multicollinear_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_inspection_plot_permutation_importance_multicollinear.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Permutation Importance with Multicollinear or Correlated Features</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Kernel Approximation
--------------------

Examples concerning the :mod:`sklearn.kernel_approximation` module.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates the use of PolynomialCountSketch to efficiently generate polynomial kernel feature-space approximations. This is used to train linear classifiers that approximate the accuracy of kernelized ones.">

.. only:: html

  .. image:: /auto_examples/kernel_approximation/images/thumb/sphx_glr_plot_scalable_poly_kernels_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_kernel_approximation_plot_scalable_poly_kernels.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Scalable learning with polynomial kernel approximation</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Manifold learning
-----------------------

Examples concerning the :mod:`sklearn.manifold` module.




.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="An illustration of dimensionality reduction on the S-curve dataset with various manifold learning methods.">

.. only:: html

  .. image:: /auto_examples/manifold/images/thumb/sphx_glr_plot_compare_methods_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_manifold_plot_compare_methods.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Comparison of Manifold Learning methods</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="An application of the different manifold techniques on a spherical data-set. Here one can see the use of dimensionality reduction in order to gain some intuition regarding the manifold learning methods. Regarding the dataset, the poles are cut from the sphere, as well as a thin slice down its side. This enables the manifold learning techniques to &#x27;spread it open&#x27; whilst projecting it onto two dimensions.">

.. only:: html

  .. image:: /auto_examples/manifold/images/thumb/sphx_glr_plot_manifold_sphere_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_manifold_plot_manifold_sphere.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Manifold Learning methods on a severed sphere</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="We illustrate various embedding techniques on the digits dataset.">

.. only:: html

  .. image:: /auto_examples/manifold/images/thumb/sphx_glr_plot_lle_digits_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_manifold_plot_lle_digits.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Manifold learning on handwritten digits: Locally Linear Embedding, Isomap...</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="An illustration of the metric and non-metric MDS on generated noisy data.">

.. only:: html

  .. image:: /auto_examples/manifold/images/thumb/sphx_glr_plot_mds_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_manifold_plot_mds.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Multi-dimensional scaling</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Swiss Roll And Swiss-Hole Reduction">

.. only:: html

  .. image:: /auto_examples/manifold/images/thumb/sphx_glr_plot_swissroll_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_manifold_plot_swissroll.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Swiss Roll And Swiss-Hole Reduction</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="An illustration of t-SNE on the two concentric circles and the S-curve datasets for different perplexity values.">

.. only:: html

  .. image:: /auto_examples/manifold/images/thumb/sphx_glr_plot_t_sne_perplexity_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_manifold_plot_t_sne_perplexity.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">t-SNE: The effect of various perplexity values on the shape</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Miscellaneous
-------------

Miscellaneous and introductory examples for scikit-learn.




.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="    See also sphx_glr_auto_examples_miscellaneous_plot_roc_curve_visualization_api.py">

.. only:: html

  .. image:: /auto_examples/miscellaneous/images/thumb/sphx_glr_plot_partial_dependence_visualization_api_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_miscellaneous_plot_partial_dependence_visualization_api.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Advanced Plotting With Partial Dependence</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows characteristics of different anomaly detection algorithms on 2D datasets. Datasets contain one or two modes (regions of high density) to illustrate the ability of algorithms to cope with multimodal data.">

.. only:: html

  .. image:: /auto_examples/miscellaneous/images/thumb/sphx_glr_plot_anomaly_comparison_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_miscellaneous_plot_anomaly_comparison.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Comparing anomaly detection algorithms for outlier detection on toy datasets</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Both kernel ridge regression (KRR) and SVR learn a non-linear function by employing the kernel trick, i.e., they learn a linear function in the space induced by the respective kernel which corresponds to a non-linear function in the original space. They differ in the loss functions (ridge versus epsilon-insensitive loss). In contrast to SVR, fitting a KRR can be done in closed-form and is typically faster for medium-sized datasets. On the other hand, the learned model is non-sparse and thus slower than SVR at prediction-time.">

.. only:: html

  .. image:: /auto_examples/miscellaneous/images/thumb/sphx_glr_plot_kernel_ridge_regression_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_miscellaneous_plot_kernel_ridge_regression.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Comparison of kernel ridge regression and SVR</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The default configuration for displaying a pipeline in a Jupyter Notebook is &#x27;diagram&#x27; where set_config(display=&#x27;diagram&#x27;). To deactivate HTML representation, use set_config(display=&#x27;text&#x27;).">

.. only:: html

  .. image:: /auto_examples/miscellaneous/images/thumb/sphx_glr_plot_pipeline_display_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_miscellaneous_plot_pipeline_display.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Displaying Pipelines</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates different ways estimators and pipelines can be displayed.">

.. only:: html

  .. image:: /auto_examples/miscellaneous/images/thumb/sphx_glr_plot_estimator_representation_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_miscellaneous_plot_estimator_representation.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Displaying estimators and complex pipelines</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example compares two outlier detection algorithms, namely local_outlier_factor (LOF) and isolation_forest (IForest), on real-world datasets available in sklearn.datasets. The goal is to show that different algorithms perform well on different datasets and contrast their training speed and sensitivity to hyperparameters.">

.. only:: html

  .. image:: /auto_examples/miscellaneous/images/thumb/sphx_glr_plot_outlier_detection_bench_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_miscellaneous_plot_outlier_detection_bench.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Evaluation of outlier detection estimators</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="An example illustrating the approximation of the feature map of an RBF kernel.">

.. only:: html

  .. image:: /auto_examples/miscellaneous/images/thumb/sphx_glr_plot_kernel_approximation_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_miscellaneous_plot_kernel_approximation.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Explicit feature map approximation for RBF kernels</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows the use of multi-output estimator to complete images. The goal is to predict the lower half of a face given its upper half.">

.. only:: html

  .. image:: /auto_examples/miscellaneous/images/thumb/sphx_glr_plot_multioutput_face_completion_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_miscellaneous_plot_multioutput_face_completion.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Face completion with a multi-output estimators</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example will demonstrate the set_output API to configure transformers to output pandas DataFrames. set_output can be configured per estimator by calling the set_output method or globally by setting set_config(transform_output=&quot;pandas&quot;). For details, see SLEP018.">

.. only:: html

  .. image:: /auto_examples/miscellaneous/images/thumb/sphx_glr_plot_set_output_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Introducing the set_output API</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="An illustration of the isotonic regression on generated data (non-linear monotonic trend with homoscedastic uniform noise).">

.. only:: html

  .. image:: /auto_examples/miscellaneous/images/thumb/sphx_glr_plot_isotonic_regression_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_miscellaneous_plot_isotonic_regression.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Isotonic Regression</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This document shows how you can use the metadata routing mechanism &lt;metadata_routing&gt; in scikit-learn to route metadata to the estimators, scorers, and CV splitters consuming them.">

.. only:: html

  .. image:: /auto_examples/miscellaneous/images/thumb/sphx_glr_plot_metadata_routing_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_miscellaneous_plot_metadata_routing.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Metadata Routing</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example simulates a multi-label document classification problem. The dataset is generated randomly based on the following process:">

.. only:: html

  .. image:: /auto_examples/miscellaneous/images/thumb/sphx_glr_plot_multilabel_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_miscellaneous_plot_multilabel.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Multilabel classification</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="ROC Curve with Visualization API">

.. only:: html

  .. image:: /auto_examples/miscellaneous/images/thumb/sphx_glr_plot_roc_curve_visualization_api_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_miscellaneous_plot_roc_curve_visualization_api.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">ROC Curve with Visualization API</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip=" The `Johnson-Lindenstrauss lemma`_ states that any high dimensional dataset can be randomly projected into a lower dimensional Euclidean space while controlling the distortion in the pairwise distances.">

.. only:: html

  .. image:: /auto_examples/miscellaneous/images/thumb/sphx_glr_plot_johnson_lindenstrauss_bound_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_miscellaneous_plot_johnson_lindenstrauss_bound.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">The Johnson-Lindenstrauss bound for embedding with random projections</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example, we will construct display objects, ConfusionMatrixDisplay, RocCurveDisplay, and PrecisionRecallDisplay directly from their respective metrics. This is an alternative to using their corresponding plot functions when a model&#x27;s predictions are already computed or expensive to compute. Note that this is advanced usage, and in general we recommend using their respective plot functions.">

.. only:: html

  .. image:: /auto_examples/miscellaneous/images/thumb/sphx_glr_plot_display_object_visualization_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_miscellaneous_plot_display_object_visualization.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Visualizations with Display Objects</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Missing Value Imputation
------------------------

Examples concerning the :mod:`sklearn.impute` module.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Missing values can be replaced by the mean, the median or the most frequent value using the basic SimpleImputer.">

.. only:: html

  .. image:: /auto_examples/impute/images/thumb/sphx_glr_plot_missing_values_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_impute_plot_missing_values.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Imputing missing values before building an estimator</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The IterativeImputer class is very flexible - it can be used with a variety of estimators to do round-robin regression, treating every variable as an output in turn.">

.. only:: html

  .. image:: /auto_examples/impute/images/thumb/sphx_glr_plot_iterative_imputer_variants_comparison_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_impute_plot_iterative_imputer_variants_comparison.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Imputing missing values with variants of IterativeImputer</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Model Selection
-----------------------

Examples related to the :mod:`sklearn.model_selection` module.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example balances model complexity and cross-validated score by finding a decent accuracy within 1 standard deviation of the best accuracy score while minimising the number of PCA components [1].">

.. only:: html

  .. image:: /auto_examples/model_selection/images/thumb/sphx_glr_plot_grid_search_refit_callable_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_refit_callable.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Balance model complexity and cross-validated score</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the class_likelihood_ratios function, which computes the positive and negative likelihood ratios (`LR+`, LR-) to assess the predictive power of a binary classifier. As we will see, these metrics are independent of the proportion between classes in the test set, which makes them very useful when the available data for a study has a different class proportion than the target application.">

.. only:: html

  .. image:: /auto_examples/model_selection/images/thumb/sphx_glr_plot_likelihood_ratios_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_model_selection_plot_likelihood_ratios.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Class Likelihood Ratios to measure classification performance</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Compare randomized search and grid search for optimizing hyperparameters of a linear SVM with SGD training. All parameters that influence the learning are searched simultaneously (except for the number of estimators, which poses a time / quality tradeoff).">

.. only:: html

  .. image:: /auto_examples/model_selection/images/thumb/sphx_glr_plot_randomized_search_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_model_selection_plot_randomized_search.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Comparing randomized search and grid search for hyperparameter estimation</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example compares the parameter search performed by HalvingGridSearchCV and GridSearchCV.">

.. only:: html

  .. image:: /auto_examples/model_selection/images/thumb/sphx_glr_plot_successive_halving_heatmap_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_model_selection_plot_successive_halving_heatmap.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Comparison between grid search and successive halving</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Example of confusion matrix usage to evaluate the quality of the output of a classifier on the iris data set. The diagonal elements represent the number of points for which the predicted label is equal to the true label, while off-diagonal elements are those that are mislabeled by the classifier. The higher the diagonal values of the confusion matrix the better, indicating many correct predictions.">

.. only:: html

  .. image:: /auto_examples/model_selection/images/thumb/sphx_glr_plot_confusion_matrix_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_model_selection_plot_confusion_matrix.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Confusion matrix</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This examples shows how a classifier is optimized by cross-validation, which is done using the GridSearchCV object on a development set that comprises only half of the available labeled data.">

.. only:: html

  .. image:: /auto_examples/model_selection/images/thumb/sphx_glr_plot_grid_search_digits_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Custom refit strategy of a grid search with cross-validation</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Multiple metric parameter search can be done by setting the scoring parameter to a list of metric scorer names or a dict mapping the scorer names to the scorer callables.">

.. only:: html

  .. image:: /auto_examples/model_selection/images/thumb/sphx_glr_plot_multi_metric_evaluation_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_model_selection_plot_multi_metric_evaluation.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example, we compare two binary classification multi-threshold metrics: the Receiver Operating Characteristic (ROC) and the Detection Error Tradeoff (DET). For such purpose, we evaluate two different classifiers for the same classification task.">

.. only:: html

  .. image:: /auto_examples/model_selection/images/thumb/sphx_glr_plot_det_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_model_selection_plot_det.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Detection error tradeoff (DET) curve</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example describes the use of the Receiver Operating Characteristic (ROC) metric to evaluate the quality of multiclass classifiers.">

.. only:: html

  .. image:: /auto_examples/model_selection/images/thumb/sphx_glr_plot_roc_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_model_selection_plot_roc.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Multiclass Receiver Operating Characteristic (ROC)</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example compares non-nested and nested cross-validation strategies on a classifier of the iris data set. Nested cross-validation (CV) is often used to train a model in which hyperparameters also need to be optimized. Nested CV estimates the generalization error of the underlying model and its (hyper)parameter search. Choosing the parameters that maximize non-nested CV biases the model to the dataset, yielding an overly-optimistic score.">

.. only:: html

  .. image:: /auto_examples/model_selection/images/thumb/sphx_glr_plot_nested_cross_validation_iris_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_model_selection_plot_nested_cross_validation_iris.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Nested versus non-nested cross-validation</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use cross_val_predict together with PredictionErrorDisplay to visualize prediction errors.">

.. only:: html

  .. image:: /auto_examples/model_selection/images/thumb/sphx_glr_plot_cv_predict_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_model_selection_plot_cv_predict.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Plotting Cross-Validated Predictions</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example, we show how to use the class LearningCurveDisplay to easily plot learning curves. In addition, we give an interpretation to the learning curves obtained for a naive Bayes and SVM classifiers.">

.. only:: html

  .. image:: /auto_examples/model_selection/images/thumb/sphx_glr_plot_learning_curve_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_model_selection_plot_learning_curve.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Plotting Learning Curves and Checking Models' Scalability</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this plot you can see the training scores and validation scores of an SVM for different values of the kernel parameter gamma. For very low values of gamma, you can see that both the training score and the validation score are low. This is called underfitting. Medium values of gamma will result in high values for both scores, i.e. the classifier is performing fairly well. If gamma is too high, the classifier will overfit, which means that the training score is good but the validation score is poor.">

.. only:: html

  .. image:: /auto_examples/model_selection/images/thumb/sphx_glr_plot_validation_curve_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_model_selection_plot_validation_curve.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Plotting Validation Curves</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Once a binary classifier is trained, the predict method outputs class label predictions corresponding to a thresholding of either the decision_function or the predict_proba output. The default threshold is defined as a posterior probability estimate of 0.5 or a decision score of 0.0. However, this default strategy may not be optimal for the task at hand.">

.. only:: html

  .. image:: /auto_examples/model_selection/images/thumb/sphx_glr_plot_tuned_decision_threshold_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_model_selection_plot_tuned_decision_threshold.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Post-hoc tuning the cut-off point of decision function</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Once a classifier is trained, the output of the predict method outputs class label predictions corresponding to a thresholding of either the decision_function or the predict_proba output. For a binary classifier, the default threshold is defined as a posterior probability estimate of 0.5 or a decision score of 0.0.">

.. only:: html

  .. image:: /auto_examples/model_selection/images/thumb/sphx_glr_plot_cost_sensitive_learning_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_model_selection_plot_cost_sensitive_learning.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Post-tuning the decision threshold for cost-sensitive learning</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Example of Precision-Recall metric to evaluate classifier output quality.">

.. only:: html

  .. image:: /auto_examples/model_selection/images/thumb/sphx_glr_plot_precision_recall_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_model_selection_plot_precision_recall.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Precision-Recall</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example presents how to estimate and visualize the variance of the Receiver Operating Characteristic (ROC) metric using cross-validation.">

.. only:: html

  .. image:: /auto_examples/model_selection/images/thumb/sphx_glr_plot_roc_crossval_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_model_selection_plot_roc_crossval.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Receiver Operating Characteristic (ROC) with cross validation</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The dataset used in this example is 20newsgroups_dataset which will be automatically downloaded, cached and reused for the document classification example.">

.. only:: html

  .. image:: /auto_examples/model_selection/images/thumb/sphx_glr_plot_grid_search_text_feature_extraction_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_text_feature_extraction.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Sample pipeline for text feature extraction and evaluation</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to statistically compare the performance of models trained and evaluated using GridSearchCV.">

.. only:: html

  .. image:: /auto_examples/model_selection/images/thumb/sphx_glr_plot_grid_search_stats_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_stats.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Statistical comparison of models using grid search</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how a successive halving search (~sklearn.model_selection.HalvingGridSearchCV and HalvingRandomSearchCV) iteratively chooses the best parameter combination out of multiple candidates.">

.. only:: html

  .. image:: /auto_examples/model_selection/images/thumb/sphx_glr_plot_successive_halving_iterations_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_model_selection_plot_successive_halving_iterations.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Successive Halving Iterations</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the use of permutation_test_score to evaluate the significance of a cross-validated score using permutations.">

.. only:: html

  .. image:: /auto_examples/model_selection/images/thumb/sphx_glr_plot_permutation_tests_for_classification_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_model_selection_plot_permutation_tests_for_classification.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Test with permutations the significance of a classification score</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Illustration of how the performance of an estimator on unseen data (test data) is not the same as the performance on training data. As the regularization increases the performance on train decreases while the performance on test is optimal within a range of values of the regularization parameter. The example with an Elastic-Net regression model and the performance is measured using the explained variance a.k.a. R^2.">

.. only:: html

  .. image:: /auto_examples/model_selection/images/thumb/sphx_glr_plot_train_error_vs_test_error_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_model_selection_plot_train_error_vs_test_error.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Train error vs Test error</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the problems of underfitting and overfitting and how we can use linear regression with polynomial features to approximate nonlinear functions. The plot shows the function that we want to approximate, which is a part of the cosine function. In addition, the samples from the real function and the approximations of different models are displayed. The models have polynomial features of different degrees. We can see that a linear function (polynomial with degree 1) is not sufficient to fit the training samples. This is called underfitting. A polynomial of degree 4 approximates the true function almost perfectly. However, for higher degrees the model will overfit the training data, i.e. it learns the noise of the training data. We evaluate quantitatively overfitting / underfitting by using cross-validation. We calculate the mean squared error (MSE) on the validation set, the higher, the less likely the model generalizes correctly from the training data.">

.. only:: html

  .. image:: /auto_examples/model_selection/images/thumb/sphx_glr_plot_underfitting_overfitting_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_model_selection_plot_underfitting_overfitting.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Underfitting vs. Overfitting</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Choosing the right cross-validation object is a crucial part of fitting a model properly. There are many ways to split data into training and test sets in order to avoid model overfitting, to standardize the number of groups in test sets, etc.">

.. only:: html

  .. image:: /auto_examples/model_selection/images/thumb/sphx_glr_plot_cv_indices_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_model_selection_plot_cv_indices.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Visualizing cross-validation behavior in scikit-learn</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Multiclass methods
------------------

Examples concerning the :mod:`sklearn.multiclass` module.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example, we discuss the problem of classification when the target variable is composed of more than two classes. This is called multiclass classification.">

.. only:: html

  .. image:: /auto_examples/multiclass/images/thumb/sphx_glr_plot_multiclass_overview_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_multiclass_plot_multiclass_overview.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Overview of multiclass training meta-estimators</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Multioutput methods
-------------------

Examples concerning the :mod:`sklearn.multioutput` module.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The most naive strategy to solve such a task is to independently train a binary classifier on each label (i.e. each column of the target variable). At prediction time, the ensemble of binary classifiers is used to assemble multitask prediction.">

.. only:: html

  .. image:: /auto_examples/multioutput/images/thumb/sphx_glr_plot_classifier_chain_yeast_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_multioutput_plot_classifier_chain_yeast.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Multilabel classification using a classifier chain</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Nearest Neighbors
-----------------------

Examples concerning the :mod:`sklearn.neighbors` module.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example presents how to chain KNeighborsTransformer and TSNE in a pipeline. It also shows how to wrap the packages nmslib and pynndescent to replace KNeighborsTransformer and perform approximate nearest neighbors. These packages can be installed with pip install nmslib pynndescent.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_approximate_nearest_neighbors_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_approximate_nearest_neighbors.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Approximate nearest neighbors in TSNE</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This examples demonstrates how to precompute the k nearest neighbors before using them in KNeighborsClassifier. KNeighborsClassifier can compute the nearest neighbors internally, but precomputing them can have several benefits, such as finer parameter control, caching for multiple use, or custom implementations.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_plot_caching_nearest_neighbors_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_plot_caching_nearest_neighbors.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Caching nearest neighbors</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="An example comparing nearest neighbors classification with and without Neighborhood Components Analysis.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_plot_nca_classification_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_plot_nca_classification.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Comparing Nearest Neighbors with and without Neighborhood Components Analysis</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Sample usage of Neighborhood Components Analysis for dimensionality reduction.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_plot_nca_dim_reduction_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_plot_nca_dim_reduction.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Dimensionality Reduction with Neighborhood Components Analysis</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example does not perform any learning over the data (see sphx_glr_auto_examples_applications_plot_species_distribution_modeling.py for an example of classification based on the attributes in this dataset).  It simply shows the kernel density estimate of observed data points in geospatial coordinates.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_plot_species_kde_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_plot_species_kde.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Kernel Density Estimate of Species Distributions</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how kernel density estimation (KDE), a powerful non-parametric density estimation technique, can be used to learn a generative model for a dataset.  With this generative model in place, new samples can be drawn.  These new samples reflect the underlying model of the data.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_plot_digits_kde_sampling_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_plot_digits_kde_sampling.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Kernel Density Estimation</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Sample usage of Nearest Centroid classification. It will plot the decision boundaries for each class.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_plot_nearest_centroid_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_plot_nearest_centroid.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Nearest Centroid Classification</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use KNeighborsClassifier. We train such a classifier on the iris dataset and observe the difference of the decision boundary obtained with regards to the parameter weights.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_plot_classification_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_plot_classification.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Nearest Neighbors Classification</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Demonstrate the resolution of a regression problem using a k-Nearest Neighbor and the interpolation of the target using both barycenter and constant weights.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_plot_regression_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_plot_regression.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Nearest Neighbors regression</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates a learned distance metric that maximizes the nearest neighbors classification accuracy. It provides a visual representation of this metric compared to the original point space. Please refer to the User Guide &lt;nca&gt; for more information.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_plot_nca_illustration_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_plot_nca_illustration.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Neighborhood Components Analysis Illustration</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The Local Outlier Factor (LOF) algorithm is an unsupervised anomaly detection method which computes the local density deviation of a given data point with respect to its neighbors. It considers as outliers the samples that have a substantially lower density than their neighbors. This example shows how to use LOF for novelty detection. Note that when LOF is used for novelty detection you MUST not use predict, decision_function and score_samples on the training set as this would lead to wrong results. You must only use these methods on new unseen data (which are not in the training set). See User Guide &lt;outlier_detection&gt;: for details on the difference between outlier detection and novelty detection and how to use LOF for outlier detection.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_plot_lof_novelty_detection_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_plot_lof_novelty_detection.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Novelty detection with Local Outlier Factor (LOF)</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The Local Outlier Factor (LOF) algorithm is an unsupervised anomaly detection method which computes the local density deviation of a given data point with respect to its neighbors. It considers as outliers the samples that have a substantially lower density than their neighbors. This example shows how to use LOF for outlier detection which is the default use case of this estimator in scikit-learn. Note that when LOF is used for outlier detection it has no predict, decision_function and score_samples methods. See the User Guide &lt;outlier_detection&gt; for details on the difference between outlier detection and novelty detection and how to use LOF for novelty detection.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_plot_lof_outlier_detection_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_plot_lof_outlier_detection.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Outlier detection with Local Outlier Factor (LOF)</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The first plot shows one of the problems with using histograms to visualize the density of points in 1D. Intuitively, a histogram can be thought of as a scheme in which a unit &quot;block&quot; is stacked above each point on a regular grid. As the top two panels show, however, the choice of gridding for these blocks can lead to wildly divergent ideas about the underlying shape of the density distribution.  If we instead center each block on the point it represents, we get the estimate shown in the bottom left panel.  This is a kernel density estimation with a &quot;top hat&quot; kernel.  This idea can be generalized to other kernel shapes: the bottom-right panel of the first figure shows a Gaussian kernel density estimate over the same distribution.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_plot_kde_1d_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_plot_kde_1d.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Simple 1D Kernel Density Estimation</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Neural Networks
-----------------------

Examples concerning the :mod:`sklearn.neural_network` module.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example visualizes some training loss curves for different stochastic learning strategies, including SGD and Adam. Because of time-constraints, we use several small datasets, for which L-BFGS might be more suitable. The general trend shown in these examples seems to carry over to larger datasets, however.">

.. only:: html

  .. image:: /auto_examples/neural_networks/images/thumb/sphx_glr_plot_mlp_training_curves_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neural_networks_plot_mlp_training_curves.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Compare Stochastic learning strategies for MLPClassifier</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="For greyscale image data where pixel values can be interpreted as degrees of blackness on a white background, like handwritten digit recognition, the Bernoulli Restricted Boltzmann machine model (BernoulliRBM) can perform effective non-linear feature extraction.">

.. only:: html

  .. image:: /auto_examples/neural_networks/images/thumb/sphx_glr_plot_rbm_logistic_classification_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neural_networks_plot_rbm_logistic_classification.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Restricted Boltzmann Machine features for digit classification</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A comparison of different values for regularization parameter &#x27;alpha&#x27; on synthetic datasets. The plot shows that different alphas yield different decision functions.">

.. only:: html

  .. image:: /auto_examples/neural_networks/images/thumb/sphx_glr_plot_mlp_alpha_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neural_networks_plot_mlp_alpha.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Varying regularization in Multi-layer Perceptron</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Sometimes looking at the learned coefficients of a neural network can provide insight into the learning behavior. For example if weights look unstructured, maybe some were not used at all, or if very large coefficients exist, maybe regularization was too low or the learning rate too high.">

.. only:: html

  .. image:: /auto_examples/neural_networks/images/thumb/sphx_glr_plot_mnist_filters_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neural_networks_plot_mnist_filters.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Visualization of MLP weights on MNIST</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Pipelines and composite estimators
----------------------------------

Examples of how to compose transformers and pipelines from other estimators. See the :ref:`User Guide <combining_estimators>`.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Datasets can often contain components that require different feature extraction and processing pipelines. This scenario might occur when:">

.. only:: html

  .. image:: /auto_examples/compose/images/thumb/sphx_glr_plot_column_transformer_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_compose_plot_column_transformer.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Column Transformer with Heterogeneous Data Sources</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to apply different preprocessing and feature extraction pipelines to different subsets of features, using ColumnTransformer. This is particularly handy for the case of datasets that contain heterogeneous data types, since we may want to scale the numeric features and one-hot encode the categorical ones.">

.. only:: html

  .. image:: /auto_examples/compose/images/thumb/sphx_glr_plot_column_transformer_mixed_types_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_compose_plot_column_transformer_mixed_types.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Column Transformer with Mixed Types</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In many real-world examples, there are many ways to extract features from a dataset. Often it is beneficial to combine several methods to obtain good performance. This example shows how to use FeatureUnion to combine features obtained by PCA and univariate selection.">

.. only:: html

  .. image:: /auto_examples/compose/images/thumb/sphx_glr_plot_feature_union_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_compose_plot_feature_union.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Concatenating multiple feature extraction methods</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example, we give an overview of TransformedTargetRegressor. We use two examples to illustrate the benefit of transforming the targets before learning a linear regression model. The first example uses synthetic data while the second example is based on the Ames housing data set.">

.. only:: html

  .. image:: /auto_examples/compose/images/thumb/sphx_glr_plot_transformed_target_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_compose_plot_transformed_target.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Effect of transforming the targets in regression model</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The PCA does an unsupervised dimensionality reduction, while the logistic regression does the prediction.">

.. only:: html

  .. image:: /auto_examples/compose/images/thumb/sphx_glr_plot_digits_pipe_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_compose_plot_digits_pipe.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Pipelining: chaining a PCA and a logistic regression</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example constructs a pipeline that does dimensionality reduction followed by prediction with a support vector classifier. It demonstrates the use of GridSearchCV and Pipeline to optimize over different classes of estimators in a single CV run -- unsupervised PCA and NMF dimensionality reductions are compared to univariate feature selection during the grid search.">

.. only:: html

  .. image:: /auto_examples/compose/images/thumb/sphx_glr_plot_compare_reduction_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_compose_plot_compare_reduction.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Selecting dimensionality reduction with Pipeline and GridSearchCV</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Preprocessing
-------------

Examples concerning the :mod:`sklearn.preprocessing` module.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Feature 0 (median income in a block) and feature 5 (average house occupancy) of the california_housing_dataset have very different scales and contain some very large outliers. These two characteristics lead to difficulties to visualize the data and, more importantly, they can degrade the predictive performance of many machine learning algorithms. Unscaled data can also slow down or even prevent the convergence of many gradient-based estimators.">

.. only:: html

  .. image:: /auto_examples/preprocessing/images/thumb/sphx_glr_plot_all_scaling_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_preprocessing_plot_all_scaling.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Compare the effect of different scalers on data with outliers</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The TargetEncoder uses the value of the target to encode each categorical feature. In this example, we will compare three different approaches for handling categorical features: TargetEncoder, OrdinalEncoder, OneHotEncoder and dropping the category.">

.. only:: html

  .. image:: /auto_examples/preprocessing/images/thumb/sphx_glr_plot_target_encoder_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_preprocessing_plot_target_encoder.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Comparing Target Encoder with Other Encoders</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example presents the different strategies implemented in KBinsDiscretizer:">

.. only:: html

  .. image:: /auto_examples/preprocessing/images/thumb/sphx_glr_plot_discretization_strategies_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_preprocessing_plot_discretization_strategies.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Demonstrating the different strategies of KBinsDiscretizer</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A demonstration of feature discretization on synthetic classification datasets. Feature discretization decomposes each feature into a set of bins, here equally distributed in width. The discrete values are then one-hot encoded, and given to a linear classifier. This preprocessing enables a non-linear behavior even though the classifier is linear.">

.. only:: html

  .. image:: /auto_examples/preprocessing/images/thumb/sphx_glr_plot_discretization_classification_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_preprocessing_plot_discretization_classification.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Feature discretization</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Feature scaling through standardization, also called Z-score normalization, is an important preprocessing step for many machine learning algorithms. It involves rescaling each feature such that it has a standard deviation of 1 and a mean of 0.">

.. only:: html

  .. image:: /auto_examples/preprocessing/images/thumb/sphx_glr_plot_scaling_importance_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_preprocessing_plot_scaling_importance.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Importance of Feature Scaling</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the use of the Box-Cox and Yeo-Johnson transforms through PowerTransformer to map data from various distributions to a normal distribution.">

.. only:: html

  .. image:: /auto_examples/preprocessing/images/thumb/sphx_glr_plot_map_data_to_normal_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_preprocessing_plot_map_data_to_normal.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Map data to a normal distribution</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The TargetEncoder replaces each category of a categorical feature with the shrunk mean of the target variable for that category. This method is useful in cases where there is a strong relationship between the categorical feature and the target. To prevent overfitting, TargetEncoder.fit_transform uses an internal cross fitting scheme to encode the training data to be used by a downstream model. This scheme involves splitting the data into k folds and encoding each fold using the encodings learnt using the other k-1 folds. In this example, we demonstrate the importance of the cross fitting procedure to prevent overfitting.">

.. only:: html

  .. image:: /auto_examples/preprocessing/images/thumb/sphx_glr_plot_target_encoder_cross_val_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_preprocessing_plot_target_encoder_cross_val.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Target Encoder's Internal Cross fitting</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The example compares prediction result of linear regression (linear model) and decision tree (tree based model) with and without discretization of real-valued features.">

.. only:: html

  .. image:: /auto_examples/preprocessing/images/thumb/sphx_glr_plot_discretization_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_preprocessing_plot_discretization.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Using KBinsDiscretizer to discretize continuous features</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Semi Supervised Classification
------------------------------

Examples concerning the :mod:`sklearn.semi_supervised` module.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A comparison for the decision boundaries generated on the iris dataset by Label Spreading, Self-training and SVM.">

.. only:: html

  .. image:: /auto_examples/semi_supervised/images/thumb/sphx_glr_plot_semi_supervised_versus_svm_iris_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_semi_supervised_plot_semi_supervised_versus_svm_iris.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Decision boundary of semi-supervised classifiers versus SVM on the Iris dataset</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates the effect of a varying threshold on self-training. The breast_cancer dataset is loaded, and labels are deleted such that only 50 out of 569 samples have labels. A SelfTrainingClassifier is fitted on this dataset, with varying thresholds.">

.. only:: html

  .. image:: /auto_examples/semi_supervised/images/thumb/sphx_glr_plot_self_training_varying_threshold_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_semi_supervised_plot_self_training_varying_threshold.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Effect of varying threshold for self-training</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Demonstrates an active learning technique to learn handwritten digits using label propagation.">

.. only:: html

  .. image:: /auto_examples/semi_supervised/images/thumb/sphx_glr_plot_label_propagation_digits_active_learning_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_semi_supervised_plot_label_propagation_digits_active_learning.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Label Propagation digits active learning</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the power of semisupervised learning by training a Label Spreading model to classify handwritten digits with sets of very few labels.">

.. only:: html

  .. image:: /auto_examples/semi_supervised/images/thumb/sphx_glr_plot_label_propagation_digits_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_semi_supervised_plot_label_propagation_digits.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Label Propagation digits: Demonstrating performance</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Example of LabelPropagation learning a complex internal structure to demonstrate &quot;manifold learning&quot;. The outer circle should be labeled &quot;red&quot; and the inner circle &quot;blue&quot;. Because both label groups lie inside their own distinct shape, we can see that the labels propagate correctly around the circle.">

.. only:: html

  .. image:: /auto_examples/semi_supervised/images/thumb/sphx_glr_plot_label_propagation_structure_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_semi_supervised_plot_label_propagation_structure.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Label Propagation learning a complex structure</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example, semi-supervised classifiers are trained on the 20 newsgroups dataset (which will be automatically downloaded).">

.. only:: html

  .. image:: /auto_examples/semi_supervised/images/thumb/sphx_glr_plot_semi_supervised_newsgroups_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_semi_supervised_plot_semi_supervised_newsgroups.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Semi-supervised Classification on a Text Dataset</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Support Vector Machines
-----------------------

Examples concerning the :mod:`sklearn.svm` module.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="An example using a one-class SVM for novelty detection.">

.. only:: html

  .. image:: /auto_examples/svm/images/thumb/sphx_glr_plot_oneclass_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_svm_plot_oneclass.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">One-class SVM with non-linear kernel (RBF)</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="SVCs aim to find a hyperplane that effectively separates the classes in their training data by maximizing the margin between the outermost data points of each class. This is achieved by finding the best weight vector w that defines the decision boundary hyperplane and minimizes the sum of hinge losses for misclassified samples, as measured by the hinge_loss function. By default, regularization is applied with the parameter C=1, which allows for a certain degree of misclassification tolerance.">

.. only:: html

  .. image:: /auto_examples/svm/images/thumb/sphx_glr_plot_svm_kernels_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_svm_plot_svm_kernels.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Plot classification boundaries with different SVM Kernels</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Comparison of different linear SVM classifiers on a 2D projection of the iris dataset. We only consider the first 2 features of this dataset:">

.. only:: html

  .. image:: /auto_examples/svm/images/thumb/sphx_glr_plot_iris_svc_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_svm_plot_iris_svc.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Plot different SVM classifiers in the iris dataset</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Unlike SVC (based on LIBSVM), LinearSVC (based on LIBLINEAR) does not provide the support vectors. This example demonstrates how to obtain the support vectors in LinearSVC.">

.. only:: html

  .. image:: /auto_examples/svm/images/thumb/sphx_glr_plot_linearsvc_support_vectors_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_svm_plot_linearsvc_support_vectors.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Plot the support vectors in LinearSVC</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates the effect of the parameters gamma and C of the Radial Basis Function (RBF) kernel SVM.">

.. only:: html

  .. image:: /auto_examples/svm/images/thumb/sphx_glr_plot_rbf_parameters_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_svm_plot_rbf_parameters.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">RBF SVM parameters</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A small value of C includes more/all the observations, allowing the margins to be calculated using all the data in the area.">

.. only:: html

  .. image:: /auto_examples/svm/images/thumb/sphx_glr_plot_svm_margin_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_svm_plot_svm_margin.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">SVM Margins Example</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The two plots differ only in the area in the middle where the classes are tied. If break_ties=False, all input in that area would be classified as one class, whereas if break_ties=True, the tie-breaking mechanism will create a non-convex decision boundary in that area.">

.. only:: html

  .. image:: /auto_examples/svm/images/thumb/sphx_glr_plot_svm_tie_breaking_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_svm_plot_svm_tie_breaking.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">SVM Tie Breaking Example</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Simple usage of Support Vector Machines to classify a sample. It will plot the decision surface and the support vectors.">

.. only:: html

  .. image:: /auto_examples/svm/images/thumb/sphx_glr_plot_custom_kernel_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_svm_plot_custom_kernel.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">SVM with custom kernel</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how to perform univariate feature selection before running a SVC (support vector classifier) to improve the classification scores. We use the iris dataset (4 features) and add 36 non-informative features. We can find that our model achieves best performance when we select around 10% of features.">

.. only:: html

  .. image:: /auto_examples/svm/images/thumb/sphx_glr_plot_svm_anova_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_svm_plot_svm_anova.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">SVM-Anova: SVM with univariate feature selection</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Plot the maximum margin separating hyperplane within a two-class separable dataset using a Support Vector Machine classifier with linear kernel.">

.. only:: html

  .. image:: /auto_examples/svm/images/thumb/sphx_glr_plot_separating_hyperplane_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_svm_plot_separating_hyperplane.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">SVM: Maximum margin separating hyperplane</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Find the optimal separating hyperplane using an SVC for classes that are unbalanced.">

.. only:: html

  .. image:: /auto_examples/svm/images/thumb/sphx_glr_plot_separating_hyperplane_unbalanced_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_svm_plot_separating_hyperplane_unbalanced.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">SVM: Separating hyperplane for unbalanced classes</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Plot decision function of a weighted dataset, where the size of points is proportional to its weight.">

.. only:: html

  .. image:: /auto_examples/svm/images/thumb/sphx_glr_plot_weighted_samples_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_svm_plot_weighted_samples.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">SVM: Weighted samples</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The following example illustrates the effect of scaling the regularization parameter when using svm for svm_classification. For SVC classification, we are interested in a risk minimization for the equation:">

.. only:: html

  .. image:: /auto_examples/svm/images/thumb/sphx_glr_plot_svm_scale_c_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_svm_plot_svm_scale_c.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Scaling the regularization parameter for SVCs</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Toy example of 1D regression using linear, polynomial and RBF kernels.">

.. only:: html

  .. image:: /auto_examples/svm/images/thumb/sphx_glr_plot_svm_regression_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_svm_plot_svm_regression.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Support Vector Regression (SVR) using linear and non-linear kernels</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>

Tutorial exercises
------------------

Exercises for the tutorials



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A tutorial exercise which uses cross-validation with linear models.">

.. only:: html

  .. image:: /auto_examples/exercises/images/thumb/sphx_glr_plot_cv_diabetes_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_exercises_plot_cv_diabetes.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Cross-validation on diabetes Dataset Exercise</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A tutorial exercise regarding the use of classification techniques on the Digits dataset.">

.. only:: html

  .. image:: /auto_examples/exercises/images/thumb/sphx_glr_plot_digits_classification_exercise_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_exercises_plot_digits_classification_exercise.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Digits Classification Exercise</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A tutorial exercise for using different SVM kernels.">

.. only:: html

  .. image:: /auto_examples/exercises/images/thumb/sphx_glr_plot_iris_exercise_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_exercises_plot_iris_exercise.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">SVM Exercise</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


Working with text documents
----------------------------

Examples concerning the :mod:`sklearn.feature_extraction.text` module.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This is an example showing how scikit-learn can be used to classify documents by topics using a Bag of Words approach. This example uses a Tf-idf-weighted document-term sparse matrix to encode the features and demonstrates various classifiers that can efficiently handle sparse matrices.">

.. only:: html

  .. image:: /auto_examples/text/images/thumb/sphx_glr_plot_document_classification_20newsgroups_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Classification of text documents using sparse features</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This is an example showing how the scikit-learn API can be used to cluster documents by topics using a Bag of Words approach.">

.. only:: html

  .. image:: /auto_examples/text/images/thumb/sphx_glr_plot_document_clustering_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_text_plot_document_clustering.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Clustering text documents using k-means</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example we illustrate text vectorization, which is the process of representing non-numerical input data (such as dictionaries or text documents) as vectors of real numbers.">

.. only:: html

  .. image:: /auto_examples/text/images/thumb/sphx_glr_plot_hashing_vs_dict_vectorizer_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_text_plot_hashing_vs_dict_vectorizer.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">FeatureHasher and DictVectorizer Comparison</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


.. toctree::
   :hidden:
   :includehidden:


   /auto_examples/release_highlights/index.rst
   /auto_examples/bicluster/index.rst
   /auto_examples/calibration/index.rst
   /auto_examples/classification/index.rst
   /auto_examples/cluster/index.rst
   /auto_examples/covariance/index.rst
   /auto_examples/cross_decomposition/index.rst
   /auto_examples/datasets/index.rst
   /auto_examples/tree/index.rst
   /auto_examples/decomposition/index.rst
   /auto_examples/developing_estimators/index.rst
   /auto_examples/ensemble/index.rst
   /auto_examples/applications/index.rst
   /auto_examples/feature_selection/index.rst
   /auto_examples/mixture/index.rst
   /auto_examples/gaussian_process/index.rst
   /auto_examples/linear_model/index.rst
   /auto_examples/inspection/index.rst
   /auto_examples/kernel_approximation/index.rst
   /auto_examples/manifold/index.rst
   /auto_examples/miscellaneous/index.rst
   /auto_examples/impute/index.rst
   /auto_examples/model_selection/index.rst
   /auto_examples/multiclass/index.rst
   /auto_examples/multioutput/index.rst
   /auto_examples/neighbors/index.rst
   /auto_examples/neural_networks/index.rst
   /auto_examples/compose/index.rst
   /auto_examples/preprocessing/index.rst
   /auto_examples/semi_supervised/index.rst
   /auto_examples/svm/index.rst
   /auto_examples/exercises/index.rst
   /auto_examples/text/index.rst


.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-gallery

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download all examples in Python source code: auto_examples_python.zip </auto_examples/auto_examples_python.zip>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download all examples in Jupyter notebooks: auto_examples_jupyter.zip </auto_examples/auto_examples_jupyter.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
