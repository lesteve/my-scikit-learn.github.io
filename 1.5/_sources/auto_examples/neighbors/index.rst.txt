

.. _sphx_glr_auto_examples_neighbors:

.. _neighbors_examples:

Nearest Neighbors
-----------------------

Examples concerning the :mod:`sklearn.neighbors` module.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example presents how to chain KNeighborsTransformer and TSNE in a pipeline. It also shows how to wrap the packages nmslib and pynndescent to replace KNeighborsTransformer and perform approximate nearest neighbors. These packages can be installed with pip install nmslib pynndescent.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_approximate_nearest_neighbors_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_approximate_nearest_neighbors.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Approximate nearest neighbors in TSNE</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This examples demonstrates how to precompute the k nearest neighbors before using them in KNeighborsClassifier. KNeighborsClassifier can compute the nearest neighbors internally, but precomputing them can have several benefits, such as finer parameter control, caching for multiple use, or custom implementations.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_plot_caching_nearest_neighbors_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_plot_caching_nearest_neighbors.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Caching nearest neighbors</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="An example comparing nearest neighbors classification with and without Neighborhood Components Analysis.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_plot_nca_classification_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_plot_nca_classification.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Comparing Nearest Neighbors with and without Neighborhood Components Analysis</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Sample usage of Neighborhood Components Analysis for dimensionality reduction.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_plot_nca_dim_reduction_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_plot_nca_dim_reduction.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Dimensionality Reduction with Neighborhood Components Analysis</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example does not perform any learning over the data (see sphx_glr_auto_examples_applications_plot_species_distribution_modeling.py for an example of classification based on the attributes in this dataset).  It simply shows the kernel density estimate of observed data points in geospatial coordinates.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_plot_species_kde_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_plot_species_kde.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Kernel Density Estimate of Species Distributions</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how kernel density estimation (KDE), a powerful non-parametric density estimation technique, can be used to learn a generative model for a dataset.  With this generative model in place, new samples can be drawn.  These new samples reflect the underlying model of the data.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_plot_digits_kde_sampling_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_plot_digits_kde_sampling.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Kernel Density Estimation</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Sample usage of Nearest Centroid classification. It will plot the decision boundaries for each class.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_plot_nearest_centroid_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_plot_nearest_centroid.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Nearest Centroid Classification</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use KNeighborsClassifier. We train such a classifier on the iris dataset and observe the difference of the decision boundary obtained with regards to the parameter weights.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_plot_classification_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_plot_classification.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Nearest Neighbors Classification</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Demonstrate the resolution of a regression problem using a k-Nearest Neighbor and the interpolation of the target using both barycenter and constant weights.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_plot_regression_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_plot_regression.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Nearest Neighbors regression</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates a learned distance metric that maximizes the nearest neighbors classification accuracy. It provides a visual representation of this metric compared to the original point space. Please refer to the User Guide &lt;nca&gt; for more information.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_plot_nca_illustration_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_plot_nca_illustration.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Neighborhood Components Analysis Illustration</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The Local Outlier Factor (LOF) algorithm is an unsupervised anomaly detection method which computes the local density deviation of a given data point with respect to its neighbors. It considers as outliers the samples that have a substantially lower density than their neighbors. This example shows how to use LOF for novelty detection. Note that when LOF is used for novelty detection you MUST not use predict, decision_function and score_samples on the training set as this would lead to wrong results. You must only use these methods on new unseen data (which are not in the training set). See User Guide &lt;outlier_detection&gt;: for details on the difference between outlier detection and novelty detection and how to use LOF for outlier detection.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_plot_lof_novelty_detection_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_plot_lof_novelty_detection.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Novelty detection with Local Outlier Factor (LOF)</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The Local Outlier Factor (LOF) algorithm is an unsupervised anomaly detection method which computes the local density deviation of a given data point with respect to its neighbors. It considers as outliers the samples that have a substantially lower density than their neighbors. This example shows how to use LOF for outlier detection which is the default use case of this estimator in scikit-learn. Note that when LOF is used for outlier detection it has no predict, decision_function and score_samples methods. See the User Guide &lt;outlier_detection&gt; for details on the difference between outlier detection and novelty detection and how to use LOF for novelty detection.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_plot_lof_outlier_detection_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_plot_lof_outlier_detection.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Outlier detection with Local Outlier Factor (LOF)</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The first plot shows one of the problems with using histograms to visualize the density of points in 1D. Intuitively, a histogram can be thought of as a scheme in which a unit &quot;block&quot; is stacked above each point on a regular grid. As the top two panels show, however, the choice of gridding for these blocks can lead to wildly divergent ideas about the underlying shape of the density distribution.  If we instead center each block on the point it represents, we get the estimate shown in the bottom left panel.  This is a kernel density estimation with a &quot;top hat&quot; kernel.  This idea can be generalized to other kernel shapes: the bottom-right panel of the first figure shows a Gaussian kernel density estimate over the same distribution.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_plot_kde_1d_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_plot_kde_1d.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Simple 1D Kernel Density Estimation</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /auto_examples/neighbors/approximate_nearest_neighbors
   /auto_examples/neighbors/plot_caching_nearest_neighbors
   /auto_examples/neighbors/plot_nca_classification
   /auto_examples/neighbors/plot_nca_dim_reduction
   /auto_examples/neighbors/plot_species_kde
   /auto_examples/neighbors/plot_digits_kde_sampling
   /auto_examples/neighbors/plot_nearest_centroid
   /auto_examples/neighbors/plot_classification
   /auto_examples/neighbors/plot_regression
   /auto_examples/neighbors/plot_nca_illustration
   /auto_examples/neighbors/plot_lof_novelty_detection
   /auto_examples/neighbors/plot_lof_outlier_detection
   /auto_examples/neighbors/plot_kde_1d

