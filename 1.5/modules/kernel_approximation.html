
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="6.7. Kernel Approximation" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://scikit-learn/stable/modules/kernel_approximation.html" />
<meta property="og:site_name" content="scikit-learn" />
<meta property="og:description" content="This submodule contains functions that approximate the feature mappings that correspond to certain kernels, as they are used for example in support vector machines (see Support Vector Machines). Th..." />
<meta property="og:image" content="https://scikit-learn/stable/_images/sphx_glr_plot_kernel_approximation_002.png" />
<meta property="og:image:alt" content="scikit-learn" />
<meta name="description" content="This submodule contains functions that approximate the feature mappings that correspond to certain kernels, as they are used for example in support vector machines (see Support Vector Machines). Th..." />

    <title>6.7. Kernel Approximation &#8212; scikit-learn 1.5.2 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Vibur" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyterlite_sphinx.css?v=ca70e7f1" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/colors.css?v=cc94ab7d" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/custom.css?v=e4cb1417" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=73275c37"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=97f0b27d"></script>
    <script src="../_static/jupyterlite_sphinx.js?v=d6bdf5f8"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script data-domain="scikit-learn.org" defer="defer" src="https://views.scientific-python.org/js/script.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'modules/kernel_approximation';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.15.4';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://scikit-learn.org/dev/_static/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '1.5.2';
        DOCUMENTATION_OPTIONS.show_version_warning_banner = true;
        </script>
    <script src="../_static/scripts/dropdown.js?v=e2048168"></script>
    <script src="../_static/scripts/version-switcher.js?v=a6dd8357"></script>
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="6.8. Pairwise metrics, Affinities and Kernels" href="metrics.html" />
    <link rel="prev" title="6.6. Random Projection" href="random_projection.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/scikit-learn-logo-small.png" class="logo__image only-light" alt="scikit-learn homepage"/>
    <script>document.write(`<img src="../_static/scikit-learn-logo-small.png" class="logo__image only-dark" alt="scikit-learn homepage"/>`);</script>
  
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../install.html">
    Install
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../user_guide.html">
    User Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/index.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../auto_examples/index.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://blog.scikit-learn.org/">
    Community
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../getting_started.html">
    Getting Started
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../whats_new.html">
    Release History
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../glossary.html">
    Glossary
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-external" href="https://scikit-learn.org/dev/developers/index.html">
    Development
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../faq.html">
    FAQ
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../support.html">
    Support
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../related_projects.html">
    Related Projects
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../roadmap.html">
    Roadmap
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../governance.html">
    Governance
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../about.html">
    About us
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
        </div>
      
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/scikit-learn/scikit-learn" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
        <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-2"
      type="button"
      class="version-switcher__button btn btn-sm dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-2"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-2"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-2">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../install.html">
    Install
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../user_guide.html">
    User Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/index.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../auto_examples/index.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://blog.scikit-learn.org/">
    Community
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../getting_started.html">
    Getting Started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../whats_new.html">
    Release History
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../glossary.html">
    Glossary
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://scikit-learn.org/dev/developers/index.html">
    Development
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../faq.html">
    FAQ
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../support.html">
    Support
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../related_projects.html">
    Related Projects
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../roadmap.html">
    Roadmap
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../governance.html">
    Governance
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../about.html">
    About us
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/scikit-learn/scikit-learn" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
          <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-3"
      type="button"
      class="version-switcher__button btn btn-sm dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-3"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-3"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-3">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../supervised_learning.html">1. Supervised learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="linear_model.html">1.1. Linear Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="lda_qda.html">1.2. Linear and Quadratic Discriminant Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="kernel_ridge.html">1.3. Kernel ridge regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="svm.html">1.4. Support Vector Machines</a></li>
<li class="toctree-l2"><a class="reference internal" href="sgd.html">1.5. Stochastic Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="neighbors.html">1.6. Nearest Neighbors</a></li>
<li class="toctree-l2"><a class="reference internal" href="gaussian_process.html">1.7. Gaussian Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="cross_decomposition.html">1.8. Cross decomposition</a></li>
<li class="toctree-l2"><a class="reference internal" href="naive_bayes.html">1.9. Naive Bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="tree.html">1.10. Decision Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble.html">1.11. Ensembles: Gradient boosting, random forests, bagging, voting, stacking</a></li>
<li class="toctree-l2"><a class="reference internal" href="multiclass.html">1.12. Multiclass and multioutput algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="feature_selection.html">1.13. Feature selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="semi_supervised.html">1.14. Semi-supervised learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="isotonic.html">1.15. Isotonic regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="calibration.html">1.16. Probability calibration</a></li>
<li class="toctree-l2"><a class="reference internal" href="neural_networks_supervised.html">1.17. Neural network models (supervised)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../unsupervised_learning.html">2. Unsupervised learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="mixture.html">2.1. Gaussian mixture models</a></li>
<li class="toctree-l2"><a class="reference internal" href="manifold.html">2.2. Manifold learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="clustering.html">2.3. Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="biclustering.html">2.4. Biclustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="decomposition.html">2.5. Decomposing signals in components (matrix factorization problems)</a></li>
<li class="toctree-l2"><a class="reference internal" href="covariance.html">2.6. Covariance estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="outlier_detection.html">2.7. Novelty and Outlier Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="density.html">2.8. Density Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="neural_networks_unsupervised.html">2.9. Neural network models (unsupervised)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../model_selection.html">3. Model selection and evaluation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="cross_validation.html">3.1. Cross-validation: evaluating estimator performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="grid_search.html">3.2. Tuning the hyper-parameters of an estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="classification_threshold.html">3.3. Tuning the decision threshold for class prediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_evaluation.html">3.4. Metrics and scoring: quantifying the quality of predictions</a></li>
<li class="toctree-l2"><a class="reference internal" href="learning_curve.html">3.5. Validation curves: plotting scores to evaluate models</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../inspection.html">4. Inspection</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="partial_dependence.html">4.1. Partial Dependence and Individual Conditional Expectation plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="permutation_importance.html">4.2. Permutation feature importance</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../visualizations.html">5. Visualizations</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../data_transforms.html">6. Dataset transformations</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="compose.html">6.1. Pipelines and composite estimators</a></li>
<li class="toctree-l2"><a class="reference internal" href="feature_extraction.html">6.2. Feature extraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing.html">6.3. Preprocessing data</a></li>
<li class="toctree-l2"><a class="reference internal" href="impute.html">6.4. Imputation of missing values</a></li>
<li class="toctree-l2"><a class="reference internal" href="unsupervised_reduction.html">6.5. Unsupervised dimensionality reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="random_projection.html">6.6. Random Projection</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">6.7. Kernel Approximation</a></li>
<li class="toctree-l2"><a class="reference internal" href="metrics.html">6.8. Pairwise metrics, Affinities and Kernels</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing_targets.html">6.9. Transforming the prediction target (<code class="docutils literal notranslate"><span class="pre">y</span></code>)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../datasets.html">7. Dataset loading utilities</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../datasets/toy_dataset.html">7.1. Toy datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datasets/real_world.html">7.2. Real world datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datasets/sample_generators.html">7.3. Generated datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datasets/loading_other_datasets.html">7.4. Loading other datasets</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../computing.html">8. Computing with scikit-learn</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../computing/scaling_strategies.html">8.1. Strategies to scale computationally: bigger data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../computing/computational_performance.html">8.2. Computational Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../computing/parallelism.html">8.3. Parallelism, resource management, and configuration</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../model_persistence.html">9. Model persistence</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common_pitfalls.html">10. Common pitfalls and recommended practices</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../dispatching.html">11. Dispatching</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="array_api.html">11.1. Array API support (experimental)</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../machine_learning_map.html">12. Choosing the right estimator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../presentations.html">13. External Resources, Videos and Talks</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../user_guide.html" class="nav-link">User Guide</a></li>
    
    
    <li class="breadcrumb-item"><a href="../data_transforms.html" class="nav-link"><span class="section-number">6. </span>Dataset transformations</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="kernel-approximation">
<span id="id1"></span><h1><span class="section-number">6.7. </span>Kernel Approximation<a class="headerlink" href="#kernel-approximation" title="Link to this heading">#</a></h1>
<p>This submodule contains functions that approximate the feature mappings that
correspond to certain kernels, as they are used for example in support vector
machines (see <a class="reference internal" href="svm.html#svm"><span class="std std-ref">Support Vector Machines</span></a>).
The following feature functions perform non-linear transformations of the
input, which can serve as a basis for linear classification or other
algorithms.</p>
<p>The advantage of using approximate explicit feature maps compared to the
<a class="reference external" href="https://en.wikipedia.org/wiki/Kernel_trick">kernel trick</a>,
which makes use of feature maps implicitly, is that explicit mappings
can be better suited for online learning and can significantly reduce the cost
of learning with very large datasets.
Standard kernelized SVMs do not scale well to large datasets, but using an
approximate kernel map it is possible to use much more efficient linear SVMs.
In particular, the combination of kernel map approximations with
<a class="reference internal" href="generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier" title="sklearn.linear_model.SGDClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">SGDClassifier</span></code></a> can make non-linear learning on large datasets possible.</p>
<p>Since there has not been much empirical work using approximate embeddings, it
is advisable to compare results against exact kernel methods when possible.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="linear_model.html#polynomial-regression"><span class="std std-ref">Polynomial regression: extending linear models with basis functions</span></a> for an exact polynomial transformation.</p>
</div>
<section id="nystroem-method-for-kernel-approximation">
<span id="nystroem-kernel-approx"></span><h2><span class="section-number">6.7.1. </span>Nystroem Method for Kernel Approximation<a class="headerlink" href="#nystroem-method-for-kernel-approximation" title="Link to this heading">#</a></h2>
<p>The Nystroem method, as implemented in <a class="reference internal" href="generated/sklearn.kernel_approximation.Nystroem.html#sklearn.kernel_approximation.Nystroem" title="sklearn.kernel_approximation.Nystroem"><code class="xref py py-class docutils literal notranslate"><span class="pre">Nystroem</span></code></a> is a general method for
reduced rank approximations of kernels. It achieves this by subsampling without
replacement rows/columns of the data on which the kernel is evaluated. While the
computational complexity of the exact method is
<span class="math notranslate nohighlight">\(\mathcal{O}(n^3_{\text{samples}})\)</span>, the complexity of the approximation
is <span class="math notranslate nohighlight">\(\mathcal{O}(n^2_{\text{components}} \cdot n_{\text{samples}})\)</span>, where
one can set <span class="math notranslate nohighlight">\(n_{\text{components}} \ll n_{\text{samples}}\)</span> without a
significative decrease in performance <a class="reference internal" href="#ws2001" id="id2"><span>[WS2001]</span></a>.</p>
<p>We can construct the eigendecomposition of the kernel matrix <span class="math notranslate nohighlight">\(K\)</span>, based
on the features of the data, and then split it into sampled and unsampled data
points.</p>
<div class="math notranslate nohighlight">
\[\begin{split}K = U \Lambda U^T
= \begin{bmatrix} U_1 \\ U_2\end{bmatrix} \Lambda \begin{bmatrix} U_1 \\ U_2 \end{bmatrix}^T
= \begin{bmatrix} U_1 \Lambda U_1^T &amp; U_1 \Lambda U_2^T \\ U_2 \Lambda U_1^T &amp; U_2 \Lambda U_2^T \end{bmatrix}
\equiv \begin{bmatrix} K_{11} &amp; K_{12} \\ K_{21} &amp; K_{22} \end{bmatrix}\end{split}\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(U\)</span> is orthonormal</p></li>
<li><p><span class="math notranslate nohighlight">\(\Lambda\)</span> is diagonal matrix of eigenvalues</p></li>
<li><p><span class="math notranslate nohighlight">\(U_1\)</span> is orthonormal matrix of samples that were chosen</p></li>
<li><p><span class="math notranslate nohighlight">\(U_2\)</span> is orthonormal matrix of samples that were not chosen</p></li>
</ul>
<p>Given that <span class="math notranslate nohighlight">\(U_1 \Lambda U_1^T\)</span> can be obtained by orthonormalization of
the matrix <span class="math notranslate nohighlight">\(K_{11}\)</span>, and <span class="math notranslate nohighlight">\(U_2 \Lambda U_1^T\)</span> can be evaluated (as
well as its transpose), the only remaining term to elucidate is
<span class="math notranslate nohighlight">\(U_2 \Lambda U_2^T\)</span>. To do this we can express it in terms of the already
evaluated matrices:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align} U_2 \Lambda U_2^T &amp;= \left(K_{21} U_1 \Lambda^{-1}\right) \Lambda \left(K_{21} U_1 \Lambda^{-1}\right)^T
\\&amp;= K_{21} U_1 (\Lambda^{-1} \Lambda) \Lambda^{-1} U_1^T K_{21}^T
\\&amp;= K_{21} U_1 \Lambda^{-1} U_1^T K_{21}^T
\\&amp;= K_{21} K_{11}^{-1} K_{21}^T
\\&amp;= \left( K_{21} K_{11}^{-\frac12} \right) \left( K_{21} K_{11}^{-\frac12} \right)^T
.\end{align}\end{split}\]</div>
<p>During <code class="docutils literal notranslate"><span class="pre">fit</span></code>, the class <a class="reference internal" href="generated/sklearn.kernel_approximation.Nystroem.html#sklearn.kernel_approximation.Nystroem" title="sklearn.kernel_approximation.Nystroem"><code class="xref py py-class docutils literal notranslate"><span class="pre">Nystroem</span></code></a> evaluates the basis <span class="math notranslate nohighlight">\(U_1\)</span>, and
computes the normalization constant, <span class="math notranslate nohighlight">\(K_{11}^{-\frac12}\)</span>. Later, during
<code class="docutils literal notranslate"><span class="pre">transform</span></code>, the kernel matrix is determined between the basis (given by the
<code class="docutils literal notranslate"><span class="pre">components_</span></code> attribute) and the new data points, <code class="docutils literal notranslate"><span class="pre">X</span></code>. This matrix is then
multiplied by the <code class="docutils literal notranslate"><span class="pre">normalization_</span></code> matrix for the final result.</p>
<p>By default <a class="reference internal" href="generated/sklearn.kernel_approximation.Nystroem.html#sklearn.kernel_approximation.Nystroem" title="sklearn.kernel_approximation.Nystroem"><code class="xref py py-class docutils literal notranslate"><span class="pre">Nystroem</span></code></a> uses the <code class="docutils literal notranslate"><span class="pre">rbf</span></code> kernel, but it can use any kernel
function or a precomputed kernel matrix. The number of samples used - which is
also the dimensionality of the features computed - is given by the parameter
<code class="docutils literal notranslate"><span class="pre">n_components</span></code>.</p>
<p class="rubric">Examples</p>
<ul class="simple">
<li><p>See the example entitled
<a class="reference internal" href="../auto_examples/applications/plot_cyclical_feature_engineering.html#sphx-glr-auto-examples-applications-plot-cyclical-feature-engineering-py"><span class="std std-ref">Time-related feature engineering</span></a>,
that shows an efficient machine learning pipeline that uses a
<a class="reference internal" href="generated/sklearn.kernel_approximation.Nystroem.html#sklearn.kernel_approximation.Nystroem" title="sklearn.kernel_approximation.Nystroem"><code class="xref py py-class docutils literal notranslate"><span class="pre">Nystroem</span></code></a> kernel.</p></li>
</ul>
</section>
<section id="radial-basis-function-kernel">
<span id="rbf-kernel-approx"></span><h2><span class="section-number">6.7.2. </span>Radial Basis Function Kernel<a class="headerlink" href="#radial-basis-function-kernel" title="Link to this heading">#</a></h2>
<p>The <a class="reference internal" href="generated/sklearn.kernel_approximation.RBFSampler.html#sklearn.kernel_approximation.RBFSampler" title="sklearn.kernel_approximation.RBFSampler"><code class="xref py py-class docutils literal notranslate"><span class="pre">RBFSampler</span></code></a> constructs an approximate mapping for the radial basis
function kernel, also known as <em>Random Kitchen Sinks</em> <a class="reference internal" href="#rr2007" id="id3"><span>[RR2007]</span></a>. This
transformation can be used to explicitly model a kernel map, prior to applying
a linear algorithm, for example a linear SVM:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.kernel_approximation</span> <span class="kn">import</span> <span class="n">RBFSampler</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">SGDClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rbf_feature</span> <span class="o">=</span> <span class="n">RBFSampler</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_features</span> <span class="o">=</span> <span class="n">rbf_feature</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">SGDClassifier</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_features</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">SGDClassifier(max_iter=5)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_features</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">1.0</span>
</pre></div>
</div>
<p>The mapping relies on a Monte Carlo approximation to the
kernel values. The <code class="docutils literal notranslate"><span class="pre">fit</span></code> function performs the Monte Carlo sampling, whereas
the <code class="docutils literal notranslate"><span class="pre">transform</span></code> method performs the mapping of the data.  Because of the
inherent randomness of the process, results may vary between different calls to
the <code class="docutils literal notranslate"><span class="pre">fit</span></code> function.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">fit</span></code> function takes two arguments:
<code class="docutils literal notranslate"><span class="pre">n_components</span></code>, which is the target dimensionality of the feature transform,
and <code class="docutils literal notranslate"><span class="pre">gamma</span></code>, the parameter of the RBF-kernel.  A higher <code class="docutils literal notranslate"><span class="pre">n_components</span></code> will
result in a better approximation of the kernel and will yield results more
similar to those produced by a kernel SVM. Note that “fitting” the feature
function does not actually depend on the data given to the <code class="docutils literal notranslate"><span class="pre">fit</span></code> function.
Only the dimensionality of the data is used.
Details on the method can be found in <a class="reference internal" href="#rr2007" id="id4"><span>[RR2007]</span></a>.</p>
<p>For a given value of <code class="docutils literal notranslate"><span class="pre">n_components</span></code> <a class="reference internal" href="generated/sklearn.kernel_approximation.RBFSampler.html#sklearn.kernel_approximation.RBFSampler" title="sklearn.kernel_approximation.RBFSampler"><code class="xref py py-class docutils literal notranslate"><span class="pre">RBFSampler</span></code></a> is often less accurate
as <a class="reference internal" href="generated/sklearn.kernel_approximation.Nystroem.html#sklearn.kernel_approximation.Nystroem" title="sklearn.kernel_approximation.Nystroem"><code class="xref py py-class docutils literal notranslate"><span class="pre">Nystroem</span></code></a>. <a class="reference internal" href="generated/sklearn.kernel_approximation.RBFSampler.html#sklearn.kernel_approximation.RBFSampler" title="sklearn.kernel_approximation.RBFSampler"><code class="xref py py-class docutils literal notranslate"><span class="pre">RBFSampler</span></code></a> is cheaper to compute, though, making
use of larger feature spaces more efficient.</p>
<figure class="align-center" id="id12">
<a class="reference external image-reference" href="../auto_examples/miscellaneous/plot_kernel_approximation.html"><img alt="../_images/sphx_glr_plot_kernel_approximation_002.png" src="../_images/sphx_glr_plot_kernel_approximation_002.png" style="width: 900.0px; height: 375.0px;" />
</a>
<figcaption>
<p><span class="caption-text">Comparing an exact RBF kernel (left) with the approximation (right)</span><a class="headerlink" href="#id12" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p class="rubric">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/miscellaneous/plot_kernel_approximation.html#sphx-glr-auto-examples-miscellaneous-plot-kernel-approximation-py"><span class="std std-ref">Explicit feature map approximation for RBF kernels</span></a></p></li>
</ul>
</section>
<section id="additive-chi-squared-kernel">
<span id="additive-chi-kernel-approx"></span><h2><span class="section-number">6.7.3. </span>Additive Chi Squared Kernel<a class="headerlink" href="#additive-chi-squared-kernel" title="Link to this heading">#</a></h2>
<p>The additive chi squared kernel is a kernel on histograms, often used in computer vision.</p>
<p>The additive chi squared kernel as used here is given by</p>
<div class="math notranslate nohighlight">
\[k(x, y) = \sum_i \frac{2x_iy_i}{x_i+y_i}\]</div>
<p>This is not exactly the same as <a class="reference internal" href="generated/sklearn.metrics.pairwise.additive_chi2_kernel.html#sklearn.metrics.pairwise.additive_chi2_kernel" title="sklearn.metrics.pairwise.additive_chi2_kernel"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.pairwise.additive_chi2_kernel</span></code></a>.
The authors of <a class="reference internal" href="#vz2010" id="id5"><span>[VZ2010]</span></a> prefer the version above as it is always positive
definite.
Since the kernel is additive, it is possible to treat all components
<span class="math notranslate nohighlight">\(x_i\)</span> separately for embedding. This makes it possible to sample
the Fourier transform in regular intervals, instead of approximating
using Monte Carlo sampling.</p>
<p>The class <a class="reference internal" href="generated/sklearn.kernel_approximation.AdditiveChi2Sampler.html#sklearn.kernel_approximation.AdditiveChi2Sampler" title="sklearn.kernel_approximation.AdditiveChi2Sampler"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdditiveChi2Sampler</span></code></a> implements this component wise
deterministic sampling. Each component is sampled <span class="math notranslate nohighlight">\(n\)</span> times, yielding
<span class="math notranslate nohighlight">\(2n+1\)</span> dimensions per input dimension (the multiple of two stems
from the real and complex part of the Fourier transform).
In the literature, <span class="math notranslate nohighlight">\(n\)</span> is usually chosen to be 1 or 2, transforming
the dataset to size <code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">5</span> <span class="pre">*</span> <span class="pre">n_features</span></code> (in the case of <span class="math notranslate nohighlight">\(n=2\)</span>).</p>
<p>The approximate feature map provided by <a class="reference internal" href="generated/sklearn.kernel_approximation.AdditiveChi2Sampler.html#sklearn.kernel_approximation.AdditiveChi2Sampler" title="sklearn.kernel_approximation.AdditiveChi2Sampler"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdditiveChi2Sampler</span></code></a> can be combined
with the approximate feature map provided by <a class="reference internal" href="generated/sklearn.kernel_approximation.RBFSampler.html#sklearn.kernel_approximation.RBFSampler" title="sklearn.kernel_approximation.RBFSampler"><code class="xref py py-class docutils literal notranslate"><span class="pre">RBFSampler</span></code></a> to yield an approximate
feature map for the exponentiated chi squared kernel.
See the <a class="reference internal" href="#vz2010" id="id6"><span>[VZ2010]</span></a> for details and <a class="reference internal" href="#vvz2010" id="id7"><span>[VVZ2010]</span></a> for combination with the <a class="reference internal" href="generated/sklearn.kernel_approximation.RBFSampler.html#sklearn.kernel_approximation.RBFSampler" title="sklearn.kernel_approximation.RBFSampler"><code class="xref py py-class docutils literal notranslate"><span class="pre">RBFSampler</span></code></a>.</p>
</section>
<section id="skewed-chi-squared-kernel">
<span id="skewed-chi-kernel-approx"></span><h2><span class="section-number">6.7.4. </span>Skewed Chi Squared Kernel<a class="headerlink" href="#skewed-chi-squared-kernel" title="Link to this heading">#</a></h2>
<p>The skewed chi squared kernel is given by:</p>
<div class="math notranslate nohighlight">
\[k(x,y) = \prod_i \frac{2\sqrt{x_i+c}\sqrt{y_i+c}}{x_i + y_i + 2c}\]</div>
<p>It has properties that are similar to the exponentiated chi squared kernel
often used in computer vision, but allows for a simple Monte Carlo
approximation of the feature map.</p>
<p>The usage of the <a class="reference internal" href="generated/sklearn.kernel_approximation.SkewedChi2Sampler.html#sklearn.kernel_approximation.SkewedChi2Sampler" title="sklearn.kernel_approximation.SkewedChi2Sampler"><code class="xref py py-class docutils literal notranslate"><span class="pre">SkewedChi2Sampler</span></code></a> is the same as the usage described
above for the <a class="reference internal" href="generated/sklearn.kernel_approximation.RBFSampler.html#sklearn.kernel_approximation.RBFSampler" title="sklearn.kernel_approximation.RBFSampler"><code class="xref py py-class docutils literal notranslate"><span class="pre">RBFSampler</span></code></a>. The only difference is in the free
parameter, that is called <span class="math notranslate nohighlight">\(c\)</span>.
For a motivation for this mapping and the mathematical details see <a class="reference internal" href="#ls2010" id="id8"><span>[LS2010]</span></a>.</p>
</section>
<section id="polynomial-kernel-approximation-via-tensor-sketch">
<span id="polynomial-kernel-approx"></span><h2><span class="section-number">6.7.5. </span>Polynomial Kernel Approximation via Tensor Sketch<a class="headerlink" href="#polynomial-kernel-approximation-via-tensor-sketch" title="Link to this heading">#</a></h2>
<p>The <a class="reference internal" href="metrics.html#polynomial-kernel"><span class="std std-ref">polynomial kernel</span></a> is a popular type of kernel
function given by:</p>
<div class="math notranslate nohighlight">
\[k(x, y) = (\gamma x^\top y +c_0)^d\]</div>
<p>where:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">x</span></code>, <code class="docutils literal notranslate"><span class="pre">y</span></code> are the input vectors</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">d</span></code> is the kernel degree</p></li>
</ul>
<p>Intuitively, the feature space of the polynomial kernel of degree <code class="docutils literal notranslate"><span class="pre">d</span></code>
consists of all possible degree-<code class="docutils literal notranslate"><span class="pre">d</span></code> products among input features, which enables
learning algorithms using this kernel to account for interactions between features.</p>
<p>The TensorSketch <a class="reference internal" href="#pp2013" id="id9"><span>[PP2013]</span></a> method, as implemented in <a class="reference internal" href="generated/sklearn.kernel_approximation.PolynomialCountSketch.html#sklearn.kernel_approximation.PolynomialCountSketch" title="sklearn.kernel_approximation.PolynomialCountSketch"><code class="xref py py-class docutils literal notranslate"><span class="pre">PolynomialCountSketch</span></code></a>, is a
scalable, input data independent method for polynomial kernel approximation.
It is based on the concept of Count sketch <a class="reference internal" href="#wikics" id="id10"><span>[WIKICS]</span></a> <a class="reference internal" href="#ccf2002" id="id11"><span>[CCF2002]</span></a> , a dimensionality
reduction technique similar to feature hashing, which instead uses several
independent hash functions. TensorSketch obtains a Count Sketch of the outer product
of two vectors (or a vector with itself), which can be used as an approximation of the
polynomial kernel feature space. In particular, instead of explicitly computing
the outer product, TensorSketch computes the Count Sketch of the vectors and then
uses polynomial multiplication via the Fast Fourier Transform to compute the
Count Sketch of their outer product.</p>
<p>Conveniently, the training phase of TensorSketch simply consists of initializing
some random variables. It is thus independent of the input data, i.e. it only
depends on the number of input features, but not the data values.
In addition, this method can transform samples in
<span class="math notranslate nohighlight">\(\mathcal{O}(n_{\text{samples}}(n_{\text{features}} + n_{\text{components}} \log(n_{\text{components}})))\)</span>
time, where <span class="math notranslate nohighlight">\(n_{\text{components}}\)</span> is the desired output dimension,
determined by <code class="docutils literal notranslate"><span class="pre">n_components</span></code>.</p>
<p class="rubric">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/kernel_approximation/plot_scalable_poly_kernels.html#sphx-glr-auto-examples-kernel-approximation-plot-scalable-poly-kernels-py"><span class="std std-ref">Scalable learning with polynomial kernel approximation</span></a></p></li>
</ul>
</section>
<section id="mathematical-details">
<span id="tensor-sketch-kernel-approx"></span><h2><span class="section-number">6.7.6. </span>Mathematical Details<a class="headerlink" href="#mathematical-details" title="Link to this heading">#</a></h2>
<p>Kernel methods like support vector machines or kernelized
PCA rely on a property of reproducing kernel Hilbert spaces.
For any positive definite kernel function <span class="math notranslate nohighlight">\(k\)</span> (a so called Mercer kernel),
it is guaranteed that there exists a mapping <span class="math notranslate nohighlight">\(\phi\)</span>
into a Hilbert space <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>, such that</p>
<div class="math notranslate nohighlight">
\[k(x,y) = \langle \phi(x), \phi(y) \rangle\]</div>
<p>Where <span class="math notranslate nohighlight">\(\langle \cdot, \cdot \rangle\)</span> denotes the inner product in the
Hilbert space.</p>
<p>If an algorithm, such as a linear support vector machine or PCA,
relies only on the scalar product of data points <span class="math notranslate nohighlight">\(x_i\)</span>, one may use
the value of <span class="math notranslate nohighlight">\(k(x_i, x_j)\)</span>, which corresponds to applying the algorithm
to the mapped data points <span class="math notranslate nohighlight">\(\phi(x_i)\)</span>.
The advantage of using <span class="math notranslate nohighlight">\(k\)</span> is that the mapping <span class="math notranslate nohighlight">\(\phi\)</span> never has
to be calculated explicitly, allowing for arbitrary large
features (even infinite).</p>
<p>One drawback of kernel methods is, that it might be necessary
to store many kernel values <span class="math notranslate nohighlight">\(k(x_i, x_j)\)</span> during optimization.
If a kernelized classifier is applied to new data <span class="math notranslate nohighlight">\(y_j\)</span>,
<span class="math notranslate nohighlight">\(k(x_i, y_j)\)</span> needs to be computed to make predictions,
possibly for many different <span class="math notranslate nohighlight">\(x_i\)</span> in the training set.</p>
<p>The classes in this submodule allow to approximate the embedding
<span class="math notranslate nohighlight">\(\phi\)</span>, thereby working explicitly with the representations
<span class="math notranslate nohighlight">\(\phi(x_i)\)</span>, which obviates the need to apply the kernel
or store training examples.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="ws2001" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">WS2001</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://papers.nips.cc/paper_files/paper/2000/hash/19de10adbaa1b2ee13f77f679fa1483a-Abstract.html">“Using the Nyström method to speed up kernel machines”</a>
Williams, C.K.I.; Seeger, M. - 2001.</p>
</div>
<div class="citation" id="rr2007" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>RR2007<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id3">1</a>,<a role="doc-backlink" href="#id4">2</a>)</span>
<p><a class="reference external" href="https://papers.nips.cc/paper/2007/hash/013a006f03dbc5392effeb8f18fda755-Abstract.html">“Random features for large-scale kernel machines”</a>
Rahimi, A. and Recht, B. - Advances in neural information processing 2007,</p>
</div>
<div class="citation" id="ls2010" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id8">LS2010</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://www.researchgate.net/publication/221114584_Random_Fourier_Approximations_for_Skewed_Multiplicative_Histogram_Kernels">“Random Fourier approximations for skewed multiplicative histogram kernels”</a>
Li, F., Ionescu, C., and Sminchisescu, C.
- Pattern Recognition,  DAGM 2010, Lecture Notes in Computer Science.</p>
</div>
<div class="citation" id="vz2010" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>VZ2010<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id5">1</a>,<a role="doc-backlink" href="#id6">2</a>)</span>
<p><a class="reference external" href="https://www.robots.ox.ac.uk/~vgg/publications/2011/Vedaldi11/vedaldi11.pdf">“Efficient additive kernels via explicit feature maps”</a>
Vedaldi, A. and Zisserman, A. - Computer Vision and Pattern Recognition 2010</p>
</div>
<div class="citation" id="vvz2010" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id7">VVZ2010</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://www.robots.ox.ac.uk/~vgg/publications/2010/Sreekanth10/sreekanth10.pdf">“Generalized RBF feature maps for Efficient Detection”</a>
Vempati, S. and Vedaldi, A. and Zisserman, A. and Jawahar, CV - 2010</p>
</div>
<div class="citation" id="pp2013" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id9">PP2013</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://doi.org/10.1145/2487575.2487591">“Fast and scalable polynomial kernels via explicit feature maps”</a>
Pham, N., &amp; Pagh, R. - 2013</p>
</div>
<div class="citation" id="ccf2002" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id11">CCF2002</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://www.cs.princeton.edu/courses/archive/spring04/cos598B/bib/CharikarCF.pdf">“Finding frequent items in data streams”</a>
Charikar, M., Chen, K., &amp; Farach-Colton - 2002</p>
</div>
<div class="citation" id="wikics" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id10">WIKICS</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Count_sketch">“Wikipedia: Count sketch”</a></p>
</div>
</div>
</section>
</section>


                </article>
              
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="prev-next-area">
    <a class="left-prev"
       href="random_projection.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">6.6. </span>Random Projection</p>
      </div>
    </a>
    <a class="right-next"
       href="metrics.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">6.8. </span>Pairwise metrics, Affinities and Kernels</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>
                </footer>
              
              
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nystroem-method-for-kernel-approximation">6.7.1. Nystroem Method for Kernel Approximation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#radial-basis-function-kernel">6.7.2. Radial Basis Function Kernel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#additive-chi-squared-kernel">6.7.3. Additive Chi Squared Kernel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skewed-chi-squared-kernel">6.7.4. Skewed Chi Squared Kernel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#polynomial-kernel-approximation-via-tensor-sketch">6.7.5. Polynomial Kernel Approximation via Tensor Sketch</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mathematical-details">6.7.6. Mathematical Details</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">

  <div class="tocsection sourcelink">
    <a href="../_sources/modules/kernel_approximation.rst.txt">
      <i class="fa-solid fa-file-lines"></i> Show Source
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2007 - 2024, scikit-learn developers (BSD License).
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
</div>

  </footer>
  </body>
</html>