
<!DOCTYPE html>

<html data-content_root="../../" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="Time-related feature engineering" property="og:title"/>
<meta content="website" property="og:type"/>
<meta content="https://scikit-learn/stable/auto_examples/applications/plot_cyclical_feature_engineering.html" property="og:url"/>
<meta content="scikit-learn" property="og:site_name"/>
<meta content="This notebook introduces different strategies to leverage time-related features for a bike sharing demand regression task that is highly dependent on business cycles (days, weeks, months) and yearl..." property="og:description"/>
<meta content="https://scikit-learn.org/stable/_static/scikit-learn-logo-small.png" property="og:image"/>
<meta content="scikit-learn" property="og:image:alt"/>
<meta content="This notebook introduces different strategies to leverage time-related features for a bike sharing demand regression task that is highly dependent on business cycles (days, weeks, months) and yearl..." name="description"/>
<title>Time-related feature engineering â€” scikit-learn 1.5.2 documentation</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../_static/pygments.css?v=a746c00c" rel="stylesheet" type="text/css"/>
<link href="../../_static/copybutton.css?v=76b2166b" rel="stylesheet" type="text/css"/>
<link href="../../_static/plot_directive.css" rel="stylesheet" type="text/css"/>
<link href="https://fonts.googleapis.com/css?family=Vibur" rel="stylesheet" type="text/css"/>
<link href="../../_static/jupyterlite_sphinx.css?v=ca70e7f1" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery.css?v=d2d258e8" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery-binder.css?v=f4aeca0c" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" rel="stylesheet" type="text/css"/>
<link href="../../_static/sphinx-design.min.css?v=95c83b7e" rel="stylesheet" type="text/css"/>
<link href="../../_static/styles/colors.css?v=cc94ab7d" rel="stylesheet" type="text/css"/>
<link href="../../_static/styles/custom.css?v=e4cb1417" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<link as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/documentation_options.js?v=73275c37"></script>
<script src="../../_static/doctools.js?v=9a2dae69"></script>
<script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
<script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
<script src="../../_static/copybutton.js?v=97f0b27d"></script>
<script src="../../_static/jupyterlite_sphinx.js?v=d6bdf5f8"></script>
<script src="../../_static/design-tabs.js?v=f930bc37"></script>
<script data-domain="scikit-learn.org" defer="defer" src="https://views.scientific-python.org/js/script.js"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'auto_examples/applications/plot_cyclical_feature_engineering';</script>
<script>
        DOCUMENTATION_OPTIONS.theme_version = '0.15.4';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://scikit-learn.org/dev/_static/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '1.5.2';
        DOCUMENTATION_OPTIONS.show_version_warning_banner = true;
        </script>
<script src="../../_static/scripts/dropdown.js?v=e2048168"></script>
<script src="../../_static/scripts/version-switcher.js?v=a6dd8357"></script>
<link href="../../_static/favicon.ico" rel="icon"/>
<link href="../../about.html" rel="author" title="About these documents"/>
<link href="../../search.html" rel="search" title="Search"/>
<link href="plot_topics_extraction_with_nmf_lda.html" rel="next" title="Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation"/>
<link href="plot_species_distribution_modeling.html" rel="prev" title="Species distribution modeling"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
</head>
<body data-bs-root-margin="0px 0px -60%" data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-default-mode="" data-offset="180">
<div class="skip-link d-print-none" id="pst-skip-link"><a href="#main-content">Skip to main content</a></div>
<div id="pst-scroll-pixel-helper"></div>
<button class="btn rounded-pill" id="pst-back-to-top" type="button">
<i class="fa-solid fa-arrow-up"></i>Back to top</button>
<input class="sidebar-toggle" id="pst-primary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
<input class="sidebar-toggle" id="pst-secondary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
</div>
<div class="pst-async-banner-revealer d-none">
<aside aria-label="Version warning" class="d-none d-print-none" id="bd-header-version-warning"></aside>
</div>
<header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
<button aria-label="Site navigation" class="pst-navbar-icon sidebar-toggle primary-toggle">
<span class="fa-solid fa-bars"></span>
</button>
<div class="navbar-header-items__start">
<div class="navbar-item">
<a class="navbar-brand logo" href="../../index.html">
<img alt="scikit-learn homepage" class="logo__image only-light" src="../../_static/scikit-learn-logo-small.png"/>
<script>document.write(`<img src="../../_static/scikit-learn-logo-small.png" class="logo__image only-dark" alt="scikit-learn homepage"/>`);</script>
</a></div>
</div>
<div class="navbar-header-items">
<div class="me-auto navbar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../install.html">
    Install
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../user_guide.html">
    User Guide
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../api/index.html">
    API
  </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../index.html">
    Examples
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-external" href="https://blog.scikit-learn.org/">
    Community
  </a>
</li>
<li class="nav-item dropdown">
<button aria-controls="pst-nav-more-links" aria-expanded="false" class="btn dropdown-toggle nav-item" data-bs-toggle="dropdown" type="button">
                    More
                </button>
<ul class="dropdown-menu" id="pst-nav-more-links">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../getting_started.html">
    Getting Started
  </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../whats_new.html">
    Release History
  </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../glossary.html">
    Glossary
  </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-external" href="https://scikit-learn.org/dev/developers/index.html">
    Development
  </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../faq.html">
    FAQ
  </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../support.html">
    Support
  </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../related_projects.html">
    Related Projects
  </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../roadmap.html">
    Roadmap
  </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../governance.html">
    Governance
  </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../about.html">
    About us
  </a>
</li>
</ul>
</li>
</ul>
</nav></div>
</div>
<div class="navbar-header-items__end">
<div class="navbar-item navbar-persistent--container">
<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
</div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/scikit-learn/scikit-learn" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-square-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
</ul></div>
<div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-2"
      type="button"
      class="version-switcher__button btn btn-sm dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-2"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-2"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-2">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
</div>
</div>
<div class="navbar-persistent--mobile">
<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
</div>
<button aria-label="On this page" class="pst-navbar-icon sidebar-toggle secondary-toggle">
<span class="fa-solid fa-outdent"></span>
</button>
</div>
</header>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../install.html">
    Install
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../user_guide.html">
    User Guide
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../api/index.html">
    API
  </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../index.html">
    Examples
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-external" href="https://blog.scikit-learn.org/">
    Community
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../getting_started.html">
    Getting Started
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../whats_new.html">
    Release History
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../glossary.html">
    Glossary
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-external" href="https://scikit-learn.org/dev/developers/index.html">
    Development
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../faq.html">
    FAQ
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../support.html">
    Support
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../related_projects.html">
    Related Projects
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../roadmap.html">
    Roadmap
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../governance.html">
    Governance
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../about.html">
    About us
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/scikit-learn/scikit-learn" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-square-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
</ul></div>
<div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-3"
      type="button"
      class="version-switcher__button btn btn-sm dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-3"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-3"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-3">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
</div>
</div>
<div class="sidebar-primary-items__start sidebar-primary__section">
<div class="sidebar-primary-item">
<nav aria-label="Section Navigation" class="bd-docs-nav bd-links">
<p aria-level="1" class="bd-links__title" role="heading">Section Navigation</p>
<div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../release_highlights/index.html">Release Highlights</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../release_highlights/plot_release_highlights_1_5_0.html">Release Highlights for scikit-learn 1.5</a></li>
<li class="toctree-l2"><a class="reference internal" href="../release_highlights/plot_release_highlights_1_4_0.html">Release Highlights for scikit-learn 1.4</a></li>
<li class="toctree-l2"><a class="reference internal" href="../release_highlights/plot_release_highlights_1_3_0.html">Release Highlights for scikit-learn 1.3</a></li>
<li class="toctree-l2"><a class="reference internal" href="../release_highlights/plot_release_highlights_1_2_0.html">Release Highlights for scikit-learn 1.2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../release_highlights/plot_release_highlights_1_1_0.html">Release Highlights for scikit-learn 1.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../release_highlights/plot_release_highlights_1_0_0.html">Release Highlights for scikit-learn 1.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../release_highlights/plot_release_highlights_0_24_0.html">Release Highlights for scikit-learn 0.24</a></li>
<li class="toctree-l2"><a class="reference internal" href="../release_highlights/plot_release_highlights_0_23_0.html">Release Highlights for scikit-learn 0.23</a></li>
<li class="toctree-l2"><a class="reference internal" href="../release_highlights/plot_release_highlights_0_22_0.html">Release Highlights for scikit-learn 0.22</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../bicluster/index.html">Biclustering</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../bicluster/plot_spectral_biclustering.html">A demo of the Spectral Biclustering algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bicluster/plot_spectral_coclustering.html">A demo of the Spectral Co-Clustering algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bicluster/plot_bicluster_newsgroups.html">Biclustering documents with the Spectral Co-clustering algorithm</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../calibration/index.html">Calibration</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../calibration/plot_compare_calibration.html">Comparison of Calibration of Classifiers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../calibration/plot_calibration_curve.html">Probability Calibration curves</a></li>
<li class="toctree-l2"><a class="reference internal" href="../calibration/plot_calibration_multiclass.html">Probability Calibration for 3-class classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../calibration/plot_calibration.html">Probability calibration of classifiers</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../classification/index.html">Classification</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../classification/plot_classifier_comparison.html">Classifier comparison</a></li>
<li class="toctree-l2"><a class="reference internal" href="../classification/plot_lda_qda.html">Linear and Quadratic Discriminant Analysis with covariance ellipsoid</a></li>
<li class="toctree-l2"><a class="reference internal" href="../classification/plot_lda.html">Normal, Ledoit-Wolf and OAS Linear Discriminant Analysis for classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../classification/plot_classification_probability.html">Plot classification probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../classification/plot_digits_classification.html">Recognizing hand-written digits</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cluster/index.html">Clustering</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_kmeans_digits.html">A demo of K-Means clustering on the handwritten digits data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_coin_ward_segmentation.html">A demo of structured Ward hierarchical clustering on an image of coins</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_mean_shift.html">A demo of the mean-shift clustering algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_adjusted_for_chance_measures.html">Adjustment for chance in clustering performance evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_agglomerative_clustering.html">Agglomerative clustering with and without structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_agglomerative_clustering_metrics.html">Agglomerative clustering with different metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_kmeans_plusplus.html">An example of K-Means++ initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_bisect_kmeans.html">Bisecting K-Means and Regular K-Means Performance Comparison</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_color_quantization.html">Color Quantization using K-Means</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_birch_vs_minibatchkmeans.html">Compare BIRCH and MiniBatchKMeans</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_cluster_comparison.html">Comparing different clustering algorithms on toy datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_linkage_comparison.html">Comparing different hierarchical linkage methods on toy datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_mini_batch_kmeans.html">Comparison of the K-Means and MiniBatchKMeans clustering algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_dbscan.html">Demo of DBSCAN clustering algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_hdbscan.html">Demo of HDBSCAN clustering algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_optics.html">Demo of OPTICS clustering algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_affinity_propagation.html">Demo of affinity propagation clustering algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_kmeans_assumptions.html">Demonstration of k-means assumptions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_kmeans_stability_low_dim_dense.html">Empirical evaluation of the impact of k-means initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_digits_agglomeration.html">Feature agglomeration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_feature_agglomeration_vs_univariate_selection.html">Feature agglomeration vs. univariate selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_ward_structured_vs_unstructured.html">Hierarchical clustering: structured vs unstructured ward</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_inductive_clustering.html">Inductive Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_cluster_iris.html">K-means Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_dict_face_patches.html">Online learning of a dictionary of parts of faces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_agglomerative_dendrogram.html">Plot Hierarchical Clustering Dendrogram</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_coin_segmentation.html">Segmenting the picture of greek coins in regions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_kmeans_silhouette_analysis.html">Selecting the number of clusters with silhouette analysis on KMeans clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_segmentation_toy.html">Spectral clustering for image segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_digits_linkage.html">Various Agglomerative Clustering on a 2D embedding of digits</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_face_compress.html">Vector Quantization Example</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../covariance/index.html">Covariance estimation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../covariance/plot_lw_vs_oas.html">Ledoit-Wolf vs OAS estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../covariance/plot_mahalanobis_distances.html">Robust covariance estimation and Mahalanobis distances relevance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../covariance/plot_robust_vs_empirical_covariance.html">Robust vs Empirical covariance estimate</a></li>
<li class="toctree-l2"><a class="reference internal" href="../covariance/plot_covariance_estimation.html">Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood</a></li>
<li class="toctree-l2"><a class="reference internal" href="../covariance/plot_sparse_cov.html">Sparse inverse covariance estimation</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cross_decomposition/index.html">Cross decomposition</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../cross_decomposition/plot_compare_cross_decomposition.html">Compare cross decomposition methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cross_decomposition/plot_pcr_vs_pls.html">Principal Component Regression vs Partial Least Squares Regression</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../datasets/index.html">Dataset examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../datasets/plot_random_dataset.html">Plot randomly generated classification dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datasets/plot_random_multilabel_dataset.html">Plot randomly generated multilabel dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datasets/plot_digits_last_image.html">The Digit Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datasets/plot_iris_dataset.html">The Iris Dataset</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tree/index.html">Decision Trees</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../tree/plot_tree_regression.html">Decision Tree Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tree/plot_tree_regression_multioutput.html">Multi-output Decision Tree Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tree/plot_iris_dtc.html">Plot the decision surface of decision trees trained on the iris dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tree/plot_cost_complexity_pruning.html">Post pruning decision trees with cost complexity pruning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tree/plot_unveil_tree_structure.html">Understanding the decision tree structure</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../decomposition/index.html">Decomposition</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../decomposition/plot_ica_blind_source_separation.html">Blind source separation using FastICA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../decomposition/plot_pca_vs_lda.html">Comparison of LDA and PCA 2D projection of Iris dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../decomposition/plot_faces_decomposition.html">Faces dataset decompositions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../decomposition/plot_varimax_fa.html">Factor Analysis (with rotation) to visualize patterns</a></li>
<li class="toctree-l2"><a class="reference internal" href="../decomposition/plot_ica_vs_pca.html">FastICA on 2D point clouds</a></li>
<li class="toctree-l2"><a class="reference internal" href="../decomposition/plot_image_denoising.html">Image denoising using dictionary learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../decomposition/plot_incremental_pca.html">Incremental PCA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../decomposition/plot_kernel_pca.html">Kernel PCA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../decomposition/plot_pca_vs_fa_model_selection.html">Model selection with Probabilistic PCA and Factor Analysis (FA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../decomposition/plot_pca_iris.html">PCA example with Iris Data-set</a></li>
<li class="toctree-l2"><a class="reference internal" href="../decomposition/plot_sparse_coding.html">Sparse coding with a precomputed dictionary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../developing_estimators/index.html">Developing Estimators</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../developing_estimators/sklearn_is_fitted.html"><code class="docutils literal notranslate"><span class="pre">__sklearn_is_fitted__</span></code> as Developer API</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ensemble/index.html">Ensemble methods</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_gradient_boosting_categorical.html">Categorical Feature Support in Gradient Boosting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_stack_predictors.html">Combine predictors using stacking</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_forest_hist_grad_boosting_comparison.html">Comparing Random Forests and Histogram Gradient Boosting models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_random_forest_regression_multioutput.html">Comparing random forests and the multi-output meta estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_adaboost_regression.html">Decision Tree Regression with AdaBoost</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_gradient_boosting_early_stopping.html">Early stopping in Gradient Boosting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_forest_importances.html">Feature importances with a forest of trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_feature_transformation.html">Feature transformations with ensembles of trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_hgbt_regression.html">Features in Histogram Gradient Boosting Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_gradient_boosting_oob.html">Gradient Boosting Out-of-Bag estimates</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_gradient_boosting_regression.html">Gradient Boosting regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_gradient_boosting_regularization.html">Gradient Boosting regularization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_random_forest_embedding.html">Hashing feature transformation using Totally Random Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_isolation_forest.html">IsolationForest example</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_monotonic_constraints.html">Monotonic Constraints</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_adaboost_multiclass.html">Multi-class AdaBoosted Decision Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_ensemble_oob.html">OOB Errors for Random Forests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_forest_importances_faces.html">Pixel importances with a parallel forest of trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_voting_probas.html">Plot class probabilities calculated by the VotingClassifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_voting_regressor.html">Plot individual and voting regression predictions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_voting_decision_regions.html">Plot the decision boundaries of a VotingClassifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_forest_iris.html">Plot the decision surfaces of ensembles of trees on the iris dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_gradient_boosting_quantile.html">Prediction Intervals for Gradient Boosting Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_bias_variance.html">Single estimator versus bagging: bias-variance decomposition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_adaboost_twoclass.html">Two-class AdaBoost</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">Examples based on real world datasets</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="plot_tomography_l1_reconstruction.html">Compressive sensing: tomography reconstruction with L1 prior (Lasso)</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_face_recognition.html">Faces recognition example using eigenfaces and SVMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_digits_denoising.html">Image denoising using kernel PCA</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_time_series_lagged_features.html">Lagged features for time series forecasting</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_model_complexity_influence.html">Model Complexity Influence</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_out_of_core_classification.html">Out-of-core classification of text documents</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_outlier_detection_wine.html">Outlier detection on a real data set</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_prediction_latency.html">Prediction Latency</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_species_distribution_modeling.html">Species distribution modeling</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Time-related feature engineering</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_topics_extraction_with_nmf_lda.html">Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_stock_market.html">Visualizing the stock market structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="wikipedia_principal_eigenvector.html">Wikipedia principal eigenvector</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../feature_selection/index.html">Feature Selection</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../feature_selection/plot_f_test_vs_mi.html">Comparison of F-test and mutual information</a></li>
<li class="toctree-l2"><a class="reference internal" href="../feature_selection/plot_select_from_model_diabetes.html">Model-based and sequential feature selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../feature_selection/plot_feature_selection_pipeline.html">Pipeline ANOVA SVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../feature_selection/plot_rfe_digits.html">Recursive feature elimination</a></li>
<li class="toctree-l2"><a class="reference internal" href="../feature_selection/plot_rfe_with_cross_validation.html">Recursive feature elimination with cross-validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../feature_selection/plot_feature_selection.html">Univariate Feature Selection</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../mixture/index.html">Gaussian Mixture Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../mixture/plot_concentration_prior.html">Concentration Prior Type Analysis of Variation Bayesian Gaussian Mixture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mixture/plot_gmm_pdf.html">Density Estimation for a Gaussian mixture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mixture/plot_gmm_init.html">GMM Initialization Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mixture/plot_gmm_covariances.html">GMM covariances</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mixture/plot_gmm.html">Gaussian Mixture Model Ellipsoids</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mixture/plot_gmm_selection.html">Gaussian Mixture Model Selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mixture/plot_gmm_sin.html">Gaussian Mixture Model Sine Curve</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../gaussian_process/index.html">Gaussian Process for Machine Learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_process/plot_gpr_noisy.html">Ability of Gaussian process regression (GPR) to estimate data noise-level</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_process/plot_compare_gpr_krr.html">Comparison of kernel ridge and Gaussian process regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_process/plot_gpr_co2.html">Forecasting of CO2 level on Mona Loa dataset using Gaussian process regression (GPR)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_process/plot_gpr_noisy_targets.html">Gaussian Processes regression: basic introductory example</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_process/plot_gpc_iris.html">Gaussian process classification (GPC) on iris dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_process/plot_gpr_on_structured_data.html">Gaussian processes on discrete data structures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_process/plot_gpc_xor.html">Illustration of Gaussian process classification (GPC) on the XOR dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_process/plot_gpr_prior_posterior.html">Illustration of prior and posterior Gaussian process for different kernels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_process/plot_gpc_isoprobability.html">Iso-probability lines for Gaussian Processes classification (GPC)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_process/plot_gpc.html">Probabilistic predictions with Gaussian process classification (GPC)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../linear_model/index.html">Generalized Linear Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_ard.html">Comparing Linear Bayesian Regressors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_sgd_comparison.html">Comparing various online solvers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_bayesian_ridge_curvefit.html">Curve Fitting with Bayesian Ridge Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_sgd_early_stopping.html">Early stopping of Stochastic Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_elastic_net_precomputed_gram_matrix_with_weighted_samples.html">Fitting an Elastic Net with a precomputed Gram Matrix and Weighted Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_huber_vs_ridge.html">HuberRegressor vs Ridge on dataset with strong outliers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_multi_task_lasso_support.html">Joint feature selection with multi-task Lasso</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_logistic_l1_l2_sparsity.html">L1 Penalty and Sparsity in Logistic Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_lasso_and_elasticnet.html">L1-based models for Sparse Signals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_lasso_coordinate_descent_path.html">Lasso and Elastic Net</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_lasso_lars_ic.html">Lasso model selection via information criteria</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_lasso_model_selection.html">Lasso model selection: AIC-BIC / cross-validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_lasso_dense_vs_sparse_data.html">Lasso on dense and sparse data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_lasso_lars.html">Lasso path using LARS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_ols.html">Linear Regression Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_iris_logistic.html">Logistic Regression 3-class Classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_logistic.html">Logistic function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_sparse_logistic_regression_mnist.html">MNIST classification using multinomial logistic + L1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_sparse_logistic_regression_20newsgroups.html">Multiclass sparse logistic regression on 20newgroups</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_nnls.html">Non-negative least squares</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_sgdocsvm_vs_ocsvm.html">One-Class SVM versus One-Class SVM using Stochastic Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_ols_ridge_variance.html">Ordinary Least Squares and Ridge Regression Variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_omp.html">Orthogonal Matching Pursuit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_ridge_path.html">Plot Ridge coefficients as a function of the regularization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_sgd_iris.html">Plot multi-class SGD on the iris dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_logistic_multinomial.html">Plot multinomial and One-vs-Rest Logistic Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_poisson_regression_non_normal_loss.html">Poisson regression and non-normal loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_polynomial_interpolation.html">Polynomial and Spline interpolation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_quantile_regression.html">Quantile regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_logistic_path.html">Regularization path of L1- Logistic Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_ridge_coeffs.html">Ridge coefficients as a function of the L2 Regularization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_robust_fit.html">Robust linear estimator fitting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_ransac.html">Robust linear model estimation using RANSAC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_sgd_separating_hyperplane.html">SGD: Maximum margin separating hyperplane</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_sgd_penalties.html">SGD: Penalties</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_sgd_weighted_samples.html">SGD: Weighted samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_sgd_loss_functions.html">SGD: convex loss functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_ols_3d.html">Sparsity Example: Fitting only features 1  and 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_theilsen.html">Theil-Sen Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_model/plot_tweedie_regression_insurance_claims.html">Tweedie regression on insurance claims</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../inspection/index.html">Inspection</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../inspection/plot_linear_model_coefficient_interpretation.html">Common pitfalls in the interpretation of coefficients of linear models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../inspection/plot_causal_interpretation.html">Failure of Machine Learning to infer causal effects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../inspection/plot_partial_dependence.html">Partial Dependence and Individual Conditional Expectation Plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../inspection/plot_permutation_importance.html">Permutation Importance vs Random Forest Feature Importance (MDI)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../inspection/plot_permutation_importance_multicollinear.html">Permutation Importance with Multicollinear or Correlated Features</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../kernel_approximation/index.html">Kernel Approximation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../kernel_approximation/plot_scalable_poly_kernels.html">Scalable learning with polynomial kernel approximation</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../manifold/index.html">Manifold learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../manifold/plot_compare_methods.html">Comparison of Manifold Learning methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../manifold/plot_manifold_sphere.html">Manifold Learning methods on a severed sphere</a></li>
<li class="toctree-l2"><a class="reference internal" href="../manifold/plot_lle_digits.html">Manifold learning on handwritten digits: Locally Linear Embedding, Isomapâ€¦</a></li>
<li class="toctree-l2"><a class="reference internal" href="../manifold/plot_mds.html">Multi-dimensional scaling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../manifold/plot_swissroll.html">Swiss Roll And Swiss-Hole Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../manifold/plot_t_sne_perplexity.html">t-SNE: The effect of various perplexity values on the shape</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../miscellaneous/index.html">Miscellaneous</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_partial_dependence_visualization_api.html">Advanced Plotting With Partial Dependence</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_anomaly_comparison.html">Comparing anomaly detection algorithms for outlier detection on toy datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_kernel_ridge_regression.html">Comparison of kernel ridge regression and SVR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_pipeline_display.html">Displaying Pipelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_estimator_representation.html">Displaying estimators and complex pipelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_outlier_detection_bench.html">Evaluation of outlier detection estimators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_kernel_approximation.html">Explicit feature map approximation for RBF kernels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_multioutput_face_completion.html">Face completion with a multi-output estimators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_set_output.html">Introducing the <code class="docutils literal notranslate"><span class="pre">set_output</span></code> API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_isotonic_regression.html">Isotonic Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_metadata_routing.html">Metadata Routing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_multilabel.html">Multilabel classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_roc_curve_visualization_api.html">ROC Curve with Visualization API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_johnson_lindenstrauss_bound.html">The Johnson-Lindenstrauss bound for embedding with random projections</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_display_object_visualization.html">Visualizations with Display Objects</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../impute/index.html">Missing Value Imputation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../impute/plot_missing_values.html">Imputing missing values before building an estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../impute/plot_iterative_imputer_variants_comparison.html">Imputing missing values with variants of IterativeImputer</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../model_selection/index.html">Model Selection</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_grid_search_refit_callable.html">Balance model complexity and cross-validated score</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_likelihood_ratios.html">Class Likelihood Ratios to measure classification performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_randomized_search.html">Comparing randomized search and grid search for hyperparameter estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_successive_halving_heatmap.html">Comparison between grid search and successive halving</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_confusion_matrix.html">Confusion matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_grid_search_digits.html">Custom refit strategy of a grid search with cross-validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_multi_metric_evaluation.html">Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_det.html">Detection error tradeoff (DET) curve</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_roc.html">Multiclass Receiver Operating Characteristic (ROC)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_nested_cross_validation_iris.html">Nested versus non-nested cross-validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_cv_predict.html">Plotting Cross-Validated Predictions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_learning_curve.html">Plotting Learning Curves and Checking Modelsâ€™ Scalability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_validation_curve.html">Plotting Validation Curves</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_tuned_decision_threshold.html">Post-hoc tuning the cut-off point of decision function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_cost_sensitive_learning.html">Post-tuning the decision threshold for cost-sensitive learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_precision_recall.html">Precision-Recall</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_roc_crossval.html">Receiver Operating Characteristic (ROC) with cross validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_grid_search_text_feature_extraction.html">Sample pipeline for text feature extraction and evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_grid_search_stats.html">Statistical comparison of models using grid search</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_successive_halving_iterations.html">Successive Halving Iterations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_permutation_tests_for_classification.html">Test with permutations the significance of a classification score</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_train_error_vs_test_error.html">Train error vs Test error</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_underfitting_overfitting.html">Underfitting vs. Overfitting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_cv_indices.html">Visualizing cross-validation behavior in scikit-learn</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../multiclass/index.html">Multiclass methods</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../multiclass/plot_multiclass_overview.html">Overview of multiclass training meta-estimators</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../multioutput/index.html">Multioutput methods</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../multioutput/plot_classifier_chain_yeast.html">Multilabel classification using a classifier chain</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../neighbors/index.html">Nearest Neighbors</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/approximate_nearest_neighbors.html">Approximate nearest neighbors in TSNE</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/plot_caching_nearest_neighbors.html">Caching nearest neighbors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/plot_nca_classification.html">Comparing Nearest Neighbors with and without Neighborhood Components Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/plot_nca_dim_reduction.html">Dimensionality Reduction with Neighborhood Components Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/plot_species_kde.html">Kernel Density Estimate of Species Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/plot_digits_kde_sampling.html">Kernel Density Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/plot_nearest_centroid.html">Nearest Centroid Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/plot_classification.html">Nearest Neighbors Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/plot_regression.html">Nearest Neighbors regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/plot_nca_illustration.html">Neighborhood Components Analysis Illustration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/plot_lof_novelty_detection.html">Novelty detection with Local Outlier Factor (LOF)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/plot_lof_outlier_detection.html">Outlier detection with Local Outlier Factor (LOF)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/plot_kde_1d.html">Simple 1D Kernel Density Estimation</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../neural_networks/index.html">Neural Networks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../neural_networks/plot_mlp_training_curves.html">Compare Stochastic learning strategies for MLPClassifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neural_networks/plot_rbm_logistic_classification.html">Restricted Boltzmann Machine features for digit classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neural_networks/plot_mlp_alpha.html">Varying regularization in Multi-layer Perceptron</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neural_networks/plot_mnist_filters.html">Visualization of MLP weights on MNIST</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../compose/index.html">Pipelines and composite estimators</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../compose/plot_column_transformer.html">Column Transformer with Heterogeneous Data Sources</a></li>
<li class="toctree-l2"><a class="reference internal" href="../compose/plot_column_transformer_mixed_types.html">Column Transformer with Mixed Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../compose/plot_feature_union.html">Concatenating multiple feature extraction methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../compose/plot_transformed_target.html">Effect of transforming the targets in regression model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../compose/plot_digits_pipe.html">Pipelining: chaining a PCA and a logistic regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../compose/plot_compare_reduction.html">Selecting dimensionality reduction with Pipeline and GridSearchCV</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../preprocessing/index.html">Preprocessing</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../preprocessing/plot_all_scaling.html">Compare the effect of different scalers on data with outliers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preprocessing/plot_target_encoder.html">Comparing Target Encoder with Other Encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preprocessing/plot_discretization_strategies.html">Demonstrating the different strategies of KBinsDiscretizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preprocessing/plot_discretization_classification.html">Feature discretization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preprocessing/plot_scaling_importance.html">Importance of Feature Scaling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preprocessing/plot_map_data_to_normal.html">Map data to a normal distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preprocessing/plot_target_encoder_cross_val.html">Target Encoderâ€™s Internal Cross fitting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preprocessing/plot_discretization.html">Using KBinsDiscretizer to discretize continuous features</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../semi_supervised/index.html">Semi Supervised Classification</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../semi_supervised/plot_semi_supervised_versus_svm_iris.html">Decision boundary of semi-supervised classifiers versus SVM on the Iris dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../semi_supervised/plot_self_training_varying_threshold.html">Effect of varying threshold for self-training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../semi_supervised/plot_label_propagation_digits_active_learning.html">Label Propagation digits active learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../semi_supervised/plot_label_propagation_digits.html">Label Propagation digits: Demonstrating performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../semi_supervised/plot_label_propagation_structure.html">Label Propagation learning a complex structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../semi_supervised/plot_semi_supervised_newsgroups.html">Semi-supervised Classification on a Text Dataset</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../svm/index.html">Support Vector Machines</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_oneclass.html">One-class SVM with non-linear kernel (RBF)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_svm_kernels.html">Plot classification boundaries with different SVM Kernels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_iris_svc.html">Plot different SVM classifiers in the iris dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_linearsvc_support_vectors.html">Plot the support vectors in LinearSVC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_rbf_parameters.html">RBF SVM parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_svm_margin.html">SVM Margins Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_svm_tie_breaking.html">SVM Tie Breaking Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_custom_kernel.html">SVM with custom kernel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_svm_anova.html">SVM-Anova: SVM with univariate feature selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_separating_hyperplane.html">SVM: Maximum margin separating hyperplane</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_separating_hyperplane_unbalanced.html">SVM: Separating hyperplane for unbalanced classes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_weighted_samples.html">SVM: Weighted samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_svm_scale_c.html">Scaling the regularization parameter for SVCs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_svm_regression.html">Support Vector Regression (SVR) using linear and non-linear kernels</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../exercises/index.html">Tutorial exercises</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../exercises/plot_cv_diabetes.html">Cross-validation on diabetes Dataset Exercise</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/plot_digits_classification_exercise.html">Digits Classification Exercise</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/plot_iris_exercise.html">SVM Exercise</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../text/index.html">Working with text documents</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../text/plot_document_classification_20newsgroups.html">Classification of text documents using sparse features</a></li>
<li class="toctree-l2"><a class="reference internal" href="../text/plot_document_clustering.html">Clustering text documents using k-means</a></li>
<li class="toctree-l2"><a class="reference internal" href="../text/plot_hashing_vs_dict_vectorizer.html">FeatureHasher and DictVectorizer Comparison</a></li>
</ul>
</details></li>
</ul>
</div>
</nav></div>
</div>
<div class="sidebar-primary-items__end sidebar-primary__section">
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content" role="main">
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
<div class="header-article-items__start">
<div class="header-article-item">
<nav aria-label="Breadcrumb" class="d-print-none">
<ul class="bd-breadcrumbs">
<li class="breadcrumb-item breadcrumb-home">
<a aria-label="Home" class="nav-link" href="../../index.html">
<i class="fa-solid fa-home"></i>
</a>
</li>
<li class="breadcrumb-item"><a class="nav-link" href="../index.html">Examples</a></li>
<li class="breadcrumb-item"><a class="nav-link" href="index.html">Examples based on real world datasets</a></li>
<li aria-current="page" class="breadcrumb-item active">Time-related...</li>
</ul>
</nav>
</div>
</div>
</div>
</div>
<div id="searchbox"></div>
<article class="bd-article">

<section class="sphx-glr-example-title" id="time-related-feature-engineering">
<span id="sphx-glr-auto-examples-applications-plot-cyclical-feature-engineering-py"></span><h1>Time-related feature engineering<a class="headerlink" href="#time-related-feature-engineering" title="Link to this heading">#</a></h1>
<p>This notebook introduces different strategies to leverage time-related features
for a bike sharing demand regression task that is highly dependent on business
cycles (days, weeks, months) and yearly season cycles.</p>
<p>In the process, we introduce how to perform periodic feature engineering using
the <a class="reference internal" href="../../modules/generated/sklearn.preprocessing.SplineTransformer.html#sklearn.preprocessing.SplineTransformer" title="sklearn.preprocessing.SplineTransformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.preprocessing.SplineTransformer</span></code></a> class and its
<code class="docutils literal notranslate"><span class="pre">extrapolation="periodic"</span></code> option.</p>
<section id="data-exploration-on-the-bike-sharing-demand-dataset">
<h2>Data exploration on the Bike Sharing Demand dataset<a class="headerlink" href="#data-exploration-on-the-bike-sharing-demand-dataset" title="Link to this heading">#</a></h2>
<p>We start by loading the data from the OpenML repository.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <a class="sphx-glr-backref-module-sklearn-datasets sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.datasets.fetch_openml.html#sklearn.datasets.fetch_openml" title="sklearn.datasets.fetch_openml"><span class="n">fetch_openml</span></a>

<span class="n">bike_sharing</span> <span class="o">=</span> <a class="sphx-glr-backref-module-sklearn-datasets sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.datasets.fetch_openml.html#sklearn.datasets.fetch_openml" title="sklearn.datasets.fetch_openml"><span class="n">fetch_openml</span></a><span class="p">(</span><span class="s2">"Bike_Sharing_Demand"</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">as_frame</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">bike_sharing</span><span class="o">.</span><span class="n">frame</span>
</pre></div>
</div>
<p>To get a quick understanding of the periodic patterns of the data, let us
have a look at the average demand per hour during a week.</p>
<p>Note that the week starts on a Sunday, during the weekend. We can clearly
distinguish the commute patterns in the morning and evenings of the work days
and the leisure use of the bikes on the weekends with a more spread peak
demand around the middle of the days:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">average_week_demand</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s2">"weekday"</span><span class="p">,</span> <span class="s2">"hour"</span><span class="p">])[</span><span class="s2">"count"</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">average_week_demand</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Average hourly bike demand during the week"</span><span class="p">,</span>
    <span class="n">xticks</span><span class="o">=</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">24</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">7</span><span class="p">)],</span>
    <span class="n">xticklabels</span><span class="o">=</span><span class="p">[</span><span class="s2">"Sun"</span><span class="p">,</span> <span class="s2">"Mon"</span><span class="p">,</span> <span class="s2">"Tue"</span><span class="p">,</span> <span class="s2">"Wed"</span><span class="p">,</span> <span class="s2">"Thu"</span><span class="p">,</span> <span class="s2">"Fri"</span><span class="p">,</span> <span class="s2">"Sat"</span><span class="p">],</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">"Time of the week"</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">"Number of bike rentals"</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<img alt="Average hourly bike demand during the week" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_cyclical_feature_engineering_001.png" srcset="../../_images/sphx_glr_plot_cyclical_feature_engineering_001.png"/><p>The target of the prediction problem is the absolute count of bike rentals on
a hourly basis:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s2">"count"</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>np.int64(977)
</pre></div>
</div>
<p>Let us rescale the target variable (number of hourly bike rentals) to predict
a relative demand so that the mean absolute error is more easily interpreted
as a fraction of the maximum demand.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The fit method of the models used in this notebook all minimize the
mean squared error to estimate the conditional mean.
The absolute error, however, would estimate the conditional median.</p>
<p>Nevertheless, when reporting performance measures on the test set in
the discussion, we choose to focus on the mean absolute error instead
of the (root) mean squared error because it is more intuitive to
interpret. Note, however, that in this study the best models for one
metric are also the best ones in terms of the other metric.</p>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">"count"</span><span class="p">]</span> <span class="o">/</span> <span class="n">df</span><span class="p">[</span><span class="s2">"count"</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">y</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">"Fraction of rented fleet demand"</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">"Number of hours"</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<img alt="plot cyclical feature engineering" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_cyclical_feature_engineering_002.png" srcset="../../_images/sphx_glr_plot_cyclical_feature_engineering_002.png"/><p>The input feature data frame is a time annotated hourly log of variables
describing the weather conditions. It includes both numerical and categorical
variables. Note that the time information has already been expanded into
several complementary columns.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">"count"</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>
<span class="n">X</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>season</th>
<th>year</th>
<th>month</th>
<th>hour</th>
<th>holiday</th>
<th>weekday</th>
<th>workingday</th>
<th>weather</th>
<th>temp</th>
<th>feel_temp</th>
<th>humidity</th>
<th>windspeed</th>
</tr>
</thead>
<tbody>
<tr>
<th>0</th>
<td>spring</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>False</td>
<td>6</td>
<td>False</td>
<td>clear</td>
<td>9.84</td>
<td>14.395</td>
<td>0.81</td>
<td>0.0000</td>
</tr>
<tr>
<th>1</th>
<td>spring</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>False</td>
<td>6</td>
<td>False</td>
<td>clear</td>
<td>9.02</td>
<td>13.635</td>
<td>0.80</td>
<td>0.0000</td>
</tr>
<tr>
<th>2</th>
<td>spring</td>
<td>0</td>
<td>1</td>
<td>2</td>
<td>False</td>
<td>6</td>
<td>False</td>
<td>clear</td>
<td>9.02</td>
<td>13.635</td>
<td>0.80</td>
<td>0.0000</td>
</tr>
<tr>
<th>3</th>
<td>spring</td>
<td>0</td>
<td>1</td>
<td>3</td>
<td>False</td>
<td>6</td>
<td>False</td>
<td>clear</td>
<td>9.84</td>
<td>14.395</td>
<td>0.75</td>
<td>0.0000</td>
</tr>
<tr>
<th>4</th>
<td>spring</td>
<td>0</td>
<td>1</td>
<td>4</td>
<td>False</td>
<td>6</td>
<td>False</td>
<td>clear</td>
<td>9.84</td>
<td>14.395</td>
<td>0.75</td>
<td>0.0000</td>
</tr>
<tr>
<th>...</th>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr>
<th>17374</th>
<td>spring</td>
<td>1</td>
<td>12</td>
<td>19</td>
<td>False</td>
<td>1</td>
<td>True</td>
<td>misty</td>
<td>10.66</td>
<td>12.880</td>
<td>0.60</td>
<td>11.0014</td>
</tr>
<tr>
<th>17375</th>
<td>spring</td>
<td>1</td>
<td>12</td>
<td>20</td>
<td>False</td>
<td>1</td>
<td>True</td>
<td>misty</td>
<td>10.66</td>
<td>12.880</td>
<td>0.60</td>
<td>11.0014</td>
</tr>
<tr>
<th>17376</th>
<td>spring</td>
<td>1</td>
<td>12</td>
<td>21</td>
<td>False</td>
<td>1</td>
<td>True</td>
<td>clear</td>
<td>10.66</td>
<td>12.880</td>
<td>0.60</td>
<td>11.0014</td>
</tr>
<tr>
<th>17377</th>
<td>spring</td>
<td>1</td>
<td>12</td>
<td>22</td>
<td>False</td>
<td>1</td>
<td>True</td>
<td>clear</td>
<td>10.66</td>
<td>13.635</td>
<td>0.56</td>
<td>8.9981</td>
</tr>
<tr>
<th>17378</th>
<td>spring</td>
<td>1</td>
<td>12</td>
<td>23</td>
<td>False</td>
<td>1</td>
<td>True</td>
<td>clear</td>
<td>10.66</td>
<td>13.635</td>
<td>0.65</td>
<td>8.9981</td>
</tr>
</tbody>
</table>
<p>17379 rows Ã— 12 columns</p>
</div>
</div>
<br/>
<br/><div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the time information was only present as a date or datetime column, we
could have expanded it into hour-in-the-day, day-in-the-week,
day-in-the-month, month-in-the-year using pandas:
<a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#time-date-components">https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#time-date-components</a></p>
</div>
<p>We now introspect the distribution of the categorical variables, starting
with <code class="docutils literal notranslate"><span class="pre">"weather"</span></code>:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">[</span><span class="s2">"weather"</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>weather
clear         11413
misty          4544
rain           1419
heavy_rain        3
Name: count, dtype: int64
</pre></div>
</div>
<p>Since there are only 3 <code class="docutils literal notranslate"><span class="pre">"heavy_rain"</span></code> events, we cannot use this category to
train machine learning models with cross validation. Instead, we simplify the
representation by collapsing those into the <code class="docutils literal notranslate"><span class="pre">"rain"</span></code> category.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">[</span><span class="s2">"weather"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">X</span><span class="p">[</span><span class="s2">"weather"</span><span class="p">]</span>
    <span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">object</span><span class="p">)</span>
    <span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">to_replace</span><span class="o">=</span><span class="s2">"heavy_rain"</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="s2">"rain"</span><span class="p">)</span>
    <span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">"category"</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">[</span><span class="s2">"weather"</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>weather
clear    11413
misty     4544
rain      1422
Name: count, dtype: int64
</pre></div>
</div>
<p>As expected, the <code class="docutils literal notranslate"><span class="pre">"season"</span></code> variable is well balanced:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">[</span><span class="s2">"season"</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>season
fall      4496
summer    4409
spring    4242
winter    4232
Name: count, dtype: int64
</pre></div>
</div>
</section>
<section id="time-based-cross-validation">
<h2>Time-based cross-validation<a class="headerlink" href="#time-based-cross-validation" title="Link to this heading">#</a></h2>
<p>Since the dataset is a time-ordered event log (hourly demand), we will use a
time-sensitive cross-validation splitter to evaluate our demand forecasting
model as realistically as possible. We use a gap of 2 days between the train
and test side of the splits. We also limit the training set size to make the
performance of the CV folds more stable.</p>
<p>1000 test datapoints should be enough to quantify the performance of the
model. This represents a bit less than a month and a half of contiguous test
data:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <a class="sphx-glr-backref-module-sklearn-model_selection sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.model_selection.TimeSeriesSplit.html#sklearn.model_selection.TimeSeriesSplit" title="sklearn.model_selection.TimeSeriesSplit"><span class="n">TimeSeriesSplit</span></a>

<span class="n">ts_cv</span> <span class="o">=</span> <a class="sphx-glr-backref-module-sklearn-model_selection sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.model_selection.TimeSeriesSplit.html#sklearn.model_selection.TimeSeriesSplit" title="sklearn.model_selection.TimeSeriesSplit"><span class="n">TimeSeriesSplit</span></a><span class="p">(</span>
    <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">gap</span><span class="o">=</span><span class="mi">48</span><span class="p">,</span>
    <span class="n">max_train_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Let us manually inspect the various splits to check that the
<code class="docutils literal notranslate"><span class="pre">TimeSeriesSplit</span></code> works as we expect, starting with the first split:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">all_splits</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">ts_cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
<span class="n">train_0</span><span class="p">,</span> <span class="n">test_0</span> <span class="o">=</span> <span class="n">all_splits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_0</span><span class="p">]</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>season</th>
<th>year</th>
<th>month</th>
<th>hour</th>
<th>holiday</th>
<th>weekday</th>
<th>workingday</th>
<th>weather</th>
<th>temp</th>
<th>feel_temp</th>
<th>humidity</th>
<th>windspeed</th>
</tr>
</thead>
<tbody>
<tr>
<th>12379</th>
<td>summer</td>
<td>1</td>
<td>6</td>
<td>0</td>
<td>False</td>
<td>2</td>
<td>True</td>
<td>clear</td>
<td>22.14</td>
<td>25.760</td>
<td>0.68</td>
<td>27.9993</td>
</tr>
<tr>
<th>12380</th>
<td>summer</td>
<td>1</td>
<td>6</td>
<td>1</td>
<td>False</td>
<td>2</td>
<td>True</td>
<td>misty</td>
<td>21.32</td>
<td>25.000</td>
<td>0.77</td>
<td>22.0028</td>
</tr>
<tr>
<th>12381</th>
<td>summer</td>
<td>1</td>
<td>6</td>
<td>2</td>
<td>False</td>
<td>2</td>
<td>True</td>
<td>rain</td>
<td>21.32</td>
<td>25.000</td>
<td>0.72</td>
<td>19.9995</td>
</tr>
<tr>
<th>12382</th>
<td>summer</td>
<td>1</td>
<td>6</td>
<td>3</td>
<td>False</td>
<td>2</td>
<td>True</td>
<td>rain</td>
<td>20.50</td>
<td>24.240</td>
<td>0.82</td>
<td>12.9980</td>
</tr>
<tr>
<th>12383</th>
<td>summer</td>
<td>1</td>
<td>6</td>
<td>4</td>
<td>False</td>
<td>2</td>
<td>True</td>
<td>rain</td>
<td>20.50</td>
<td>24.240</td>
<td>0.82</td>
<td>12.9980</td>
</tr>
<tr>
<th>...</th>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr>
<th>13374</th>
<td>fall</td>
<td>1</td>
<td>7</td>
<td>11</td>
<td>False</td>
<td>1</td>
<td>True</td>
<td>clear</td>
<td>34.44</td>
<td>40.150</td>
<td>0.53</td>
<td>15.0013</td>
</tr>
<tr>
<th>13375</th>
<td>fall</td>
<td>1</td>
<td>7</td>
<td>12</td>
<td>False</td>
<td>1</td>
<td>True</td>
<td>clear</td>
<td>34.44</td>
<td>39.395</td>
<td>0.49</td>
<td>8.9981</td>
</tr>
<tr>
<th>13376</th>
<td>fall</td>
<td>1</td>
<td>7</td>
<td>13</td>
<td>False</td>
<td>1</td>
<td>True</td>
<td>clear</td>
<td>34.44</td>
<td>39.395</td>
<td>0.49</td>
<td>19.0012</td>
</tr>
<tr>
<th>13377</th>
<td>fall</td>
<td>1</td>
<td>7</td>
<td>14</td>
<td>False</td>
<td>1</td>
<td>True</td>
<td>clear</td>
<td>36.08</td>
<td>40.910</td>
<td>0.42</td>
<td>7.0015</td>
</tr>
<tr>
<th>13378</th>
<td>fall</td>
<td>1</td>
<td>7</td>
<td>15</td>
<td>False</td>
<td>1</td>
<td>True</td>
<td>clear</td>
<td>35.26</td>
<td>40.150</td>
<td>0.47</td>
<td>16.9979</td>
</tr>
</tbody>
</table>
<p>1000 rows Ã— 12 columns</p>
</div>
</div>
<br/>
<br/><div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_0</span><span class="p">]</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>season</th>
<th>year</th>
<th>month</th>
<th>hour</th>
<th>holiday</th>
<th>weekday</th>
<th>workingday</th>
<th>weather</th>
<th>temp</th>
<th>feel_temp</th>
<th>humidity</th>
<th>windspeed</th>
</tr>
</thead>
<tbody>
<tr>
<th>2331</th>
<td>summer</td>
<td>0</td>
<td>4</td>
<td>1</td>
<td>False</td>
<td>2</td>
<td>True</td>
<td>misty</td>
<td>25.42</td>
<td>31.060</td>
<td>0.50</td>
<td>6.0032</td>
</tr>
<tr>
<th>2332</th>
<td>summer</td>
<td>0</td>
<td>4</td>
<td>2</td>
<td>False</td>
<td>2</td>
<td>True</td>
<td>misty</td>
<td>24.60</td>
<td>31.060</td>
<td>0.53</td>
<td>8.9981</td>
</tr>
<tr>
<th>2333</th>
<td>summer</td>
<td>0</td>
<td>4</td>
<td>3</td>
<td>False</td>
<td>2</td>
<td>True</td>
<td>misty</td>
<td>23.78</td>
<td>27.275</td>
<td>0.56</td>
<td>8.9981</td>
</tr>
<tr>
<th>2334</th>
<td>summer</td>
<td>0</td>
<td>4</td>
<td>4</td>
<td>False</td>
<td>2</td>
<td>True</td>
<td>misty</td>
<td>22.96</td>
<td>26.515</td>
<td>0.64</td>
<td>8.9981</td>
</tr>
<tr>
<th>2335</th>
<td>summer</td>
<td>0</td>
<td>4</td>
<td>5</td>
<td>False</td>
<td>2</td>
<td>True</td>
<td>misty</td>
<td>22.14</td>
<td>25.760</td>
<td>0.68</td>
<td>8.9981</td>
</tr>
<tr>
<th>...</th>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr>
<th>12326</th>
<td>summer</td>
<td>1</td>
<td>6</td>
<td>19</td>
<td>False</td>
<td>6</td>
<td>False</td>
<td>clear</td>
<td>26.24</td>
<td>31.060</td>
<td>0.36</td>
<td>11.0014</td>
</tr>
<tr>
<th>12327</th>
<td>summer</td>
<td>1</td>
<td>6</td>
<td>20</td>
<td>False</td>
<td>6</td>
<td>False</td>
<td>clear</td>
<td>25.42</td>
<td>31.060</td>
<td>0.35</td>
<td>19.0012</td>
</tr>
<tr>
<th>12328</th>
<td>summer</td>
<td>1</td>
<td>6</td>
<td>21</td>
<td>False</td>
<td>6</td>
<td>False</td>
<td>clear</td>
<td>24.60</td>
<td>31.060</td>
<td>0.40</td>
<td>7.0015</td>
</tr>
<tr>
<th>12329</th>
<td>summer</td>
<td>1</td>
<td>6</td>
<td>22</td>
<td>False</td>
<td>6</td>
<td>False</td>
<td>clear</td>
<td>23.78</td>
<td>27.275</td>
<td>0.46</td>
<td>8.9981</td>
</tr>
<tr>
<th>12330</th>
<td>summer</td>
<td>1</td>
<td>6</td>
<td>23</td>
<td>False</td>
<td>6</td>
<td>False</td>
<td>clear</td>
<td>22.96</td>
<td>26.515</td>
<td>0.52</td>
<td>7.0015</td>
</tr>
</tbody>
</table>
<p>10000 rows Ã— 12 columns</p>
</div>
</div>
<br/>
<br/><p>We now inspect the last split:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">train_4</span><span class="p">,</span> <span class="n">test_4</span> <span class="o">=</span> <span class="n">all_splits</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_4</span><span class="p">]</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>season</th>
<th>year</th>
<th>month</th>
<th>hour</th>
<th>holiday</th>
<th>weekday</th>
<th>workingday</th>
<th>weather</th>
<th>temp</th>
<th>feel_temp</th>
<th>humidity</th>
<th>windspeed</th>
</tr>
</thead>
<tbody>
<tr>
<th>16379</th>
<td>winter</td>
<td>1</td>
<td>11</td>
<td>5</td>
<td>False</td>
<td>2</td>
<td>True</td>
<td>misty</td>
<td>13.94</td>
<td>16.665</td>
<td>0.66</td>
<td>8.9981</td>
</tr>
<tr>
<th>16380</th>
<td>winter</td>
<td>1</td>
<td>11</td>
<td>6</td>
<td>False</td>
<td>2</td>
<td>True</td>
<td>misty</td>
<td>13.94</td>
<td>16.665</td>
<td>0.71</td>
<td>11.0014</td>
</tr>
<tr>
<th>16381</th>
<td>winter</td>
<td>1</td>
<td>11</td>
<td>7</td>
<td>False</td>
<td>2</td>
<td>True</td>
<td>clear</td>
<td>13.12</td>
<td>16.665</td>
<td>0.76</td>
<td>6.0032</td>
</tr>
<tr>
<th>16382</th>
<td>winter</td>
<td>1</td>
<td>11</td>
<td>8</td>
<td>False</td>
<td>2</td>
<td>True</td>
<td>clear</td>
<td>13.94</td>
<td>16.665</td>
<td>0.71</td>
<td>8.9981</td>
</tr>
<tr>
<th>16383</th>
<td>winter</td>
<td>1</td>
<td>11</td>
<td>9</td>
<td>False</td>
<td>2</td>
<td>True</td>
<td>misty</td>
<td>14.76</td>
<td>18.940</td>
<td>0.71</td>
<td>0.0000</td>
</tr>
<tr>
<th>...</th>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr>
<th>17374</th>
<td>spring</td>
<td>1</td>
<td>12</td>
<td>19</td>
<td>False</td>
<td>1</td>
<td>True</td>
<td>misty</td>
<td>10.66</td>
<td>12.880</td>
<td>0.60</td>
<td>11.0014</td>
</tr>
<tr>
<th>17375</th>
<td>spring</td>
<td>1</td>
<td>12</td>
<td>20</td>
<td>False</td>
<td>1</td>
<td>True</td>
<td>misty</td>
<td>10.66</td>
<td>12.880</td>
<td>0.60</td>
<td>11.0014</td>
</tr>
<tr>
<th>17376</th>
<td>spring</td>
<td>1</td>
<td>12</td>
<td>21</td>
<td>False</td>
<td>1</td>
<td>True</td>
<td>clear</td>
<td>10.66</td>
<td>12.880</td>
<td>0.60</td>
<td>11.0014</td>
</tr>
<tr>
<th>17377</th>
<td>spring</td>
<td>1</td>
<td>12</td>
<td>22</td>
<td>False</td>
<td>1</td>
<td>True</td>
<td>clear</td>
<td>10.66</td>
<td>13.635</td>
<td>0.56</td>
<td>8.9981</td>
</tr>
<tr>
<th>17378</th>
<td>spring</td>
<td>1</td>
<td>12</td>
<td>23</td>
<td>False</td>
<td>1</td>
<td>True</td>
<td>clear</td>
<td>10.66</td>
<td>13.635</td>
<td>0.65</td>
<td>8.9981</td>
</tr>
</tbody>
</table>
<p>1000 rows Ã— 12 columns</p>
</div>
</div>
<br/>
<br/><div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_4</span><span class="p">]</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>season</th>
<th>year</th>
<th>month</th>
<th>hour</th>
<th>holiday</th>
<th>weekday</th>
<th>workingday</th>
<th>weather</th>
<th>temp</th>
<th>feel_temp</th>
<th>humidity</th>
<th>windspeed</th>
</tr>
</thead>
<tbody>
<tr>
<th>6331</th>
<td>winter</td>
<td>0</td>
<td>9</td>
<td>9</td>
<td>False</td>
<td>1</td>
<td>True</td>
<td>misty</td>
<td>26.24</td>
<td>28.790</td>
<td>0.89</td>
<td>12.9980</td>
</tr>
<tr>
<th>6332</th>
<td>winter</td>
<td>0</td>
<td>9</td>
<td>10</td>
<td>False</td>
<td>1</td>
<td>True</td>
<td>misty</td>
<td>26.24</td>
<td>28.790</td>
<td>0.89</td>
<td>12.9980</td>
</tr>
<tr>
<th>6333</th>
<td>winter</td>
<td>0</td>
<td>9</td>
<td>11</td>
<td>False</td>
<td>1</td>
<td>True</td>
<td>clear</td>
<td>27.88</td>
<td>31.820</td>
<td>0.79</td>
<td>15.0013</td>
</tr>
<tr>
<th>6334</th>
<td>winter</td>
<td>0</td>
<td>9</td>
<td>12</td>
<td>False</td>
<td>1</td>
<td>True</td>
<td>misty</td>
<td>27.88</td>
<td>31.820</td>
<td>0.79</td>
<td>11.0014</td>
</tr>
<tr>
<th>6335</th>
<td>winter</td>
<td>0</td>
<td>9</td>
<td>13</td>
<td>False</td>
<td>1</td>
<td>True</td>
<td>misty</td>
<td>28.70</td>
<td>33.335</td>
<td>0.74</td>
<td>11.0014</td>
</tr>
<tr>
<th>...</th>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr>
<th>16326</th>
<td>winter</td>
<td>1</td>
<td>11</td>
<td>0</td>
<td>False</td>
<td>0</td>
<td>False</td>
<td>misty</td>
<td>12.30</td>
<td>15.150</td>
<td>0.70</td>
<td>11.0014</td>
</tr>
<tr>
<th>16327</th>
<td>winter</td>
<td>1</td>
<td>11</td>
<td>1</td>
<td>False</td>
<td>0</td>
<td>False</td>
<td>clear</td>
<td>12.30</td>
<td>14.395</td>
<td>0.70</td>
<td>12.9980</td>
</tr>
<tr>
<th>16328</th>
<td>winter</td>
<td>1</td>
<td>11</td>
<td>2</td>
<td>False</td>
<td>0</td>
<td>False</td>
<td>clear</td>
<td>11.48</td>
<td>14.395</td>
<td>0.81</td>
<td>7.0015</td>
</tr>
<tr>
<th>16329</th>
<td>winter</td>
<td>1</td>
<td>11</td>
<td>3</td>
<td>False</td>
<td>0</td>
<td>False</td>
<td>misty</td>
<td>12.30</td>
<td>15.150</td>
<td>0.81</td>
<td>11.0014</td>
</tr>
<tr>
<th>16330</th>
<td>winter</td>
<td>1</td>
<td>11</td>
<td>4</td>
<td>False</td>
<td>0</td>
<td>False</td>
<td>misty</td>
<td>12.30</td>
<td>14.395</td>
<td>0.81</td>
<td>12.9980</td>
</tr>
</tbody>
</table>
<p>10000 rows Ã— 12 columns</p>
</div>
</div>
<br/>
<br/><p>All is well. We are now ready to do some predictive modeling!</p>
</section>
<section id="gradient-boosting">
<h2>Gradient Boosting<a class="headerlink" href="#gradient-boosting" title="Link to this heading">#</a></h2>
<p>Gradient Boosting Regression with decision trees is often flexible enough to
efficiently handle heterogeneous tabular data with a mix of categorical and
numerical features as long as the number of samples is large enough.</p>
<p>Here, we use the modern
<a class="reference internal" href="../../modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#sklearn.ensemble.HistGradientBoostingRegressor" title="sklearn.ensemble.HistGradientBoostingRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingRegressor</span></code></a> with native support
for categorical features. Therefore, we only need to set
<code class="docutils literal notranslate"><span class="pre">categorical_features="from_dtype"</span></code> such that features with categorical dtype
are considered categorical features. For reference, we extract the categorical
features from the dataframe based on the dtype. The internal trees use a dedicated
tree splitting rule for these features.</p>
<p>The numerical variables need no preprocessing and, for the sake of simplicity,
we only try the default hyper-parameters for this model:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <a class="sphx-glr-backref-module-sklearn-compose sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer" title="sklearn.compose.ColumnTransformer"><span class="n">ColumnTransformer</span></a>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#sklearn.ensemble.HistGradientBoostingRegressor" title="sklearn.ensemble.HistGradientBoostingRegressor"><span class="n">HistGradientBoostingRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <a class="sphx-glr-backref-module-sklearn-model_selection sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate" title="sklearn.model_selection.cross_validate"><span class="n">cross_validate</span></a>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <a class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="sklearn.pipeline.make_pipeline"><span class="n">make_pipeline</span></a>

<span class="n">gbrt</span> <span class="o">=</span> <a class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#sklearn.ensemble.HistGradientBoostingRegressor" title="sklearn.ensemble.HistGradientBoostingRegressor"><span class="n">HistGradientBoostingRegressor</span></a><span class="p">(</span><span class="n">categorical_features</span><span class="o">=</span><span class="s2">"from_dtype"</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">categorical_columns</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">X</span><span class="o">.</span><span class="n">dtypes</span> <span class="o">==</span> <span class="s2">"category"</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Categorical features:"</span><span class="p">,</span> <span class="n">categorical_columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Categorical features: ['season', 'holiday', 'workingday', 'weather']
</pre></div>
</div>
<p>Lets evaluate our gradient boosting model with the mean absolute error of the
relative demand averaged across our 5 time-based cross-validation splits:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="p">,</span> <span class="n">model_prop</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">model_step</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">cv_results</span> <span class="o">=</span> <a class="sphx-glr-backref-module-sklearn-model_selection sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate" title="sklearn.model_selection.cross_validate"><span class="n">cross_validate</span></a><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">X</span><span class="p">,</span>
        <span class="n">y</span><span class="p">,</span>
        <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
        <span class="n">scoring</span><span class="o">=</span><span class="p">[</span><span class="s2">"neg_mean_absolute_error"</span><span class="p">,</span> <span class="s2">"neg_root_mean_squared_error"</span><span class="p">],</span>
        <span class="n">return_estimator</span><span class="o">=</span><span class="n">model_prop</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">model_prop</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">model_step</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">values</span> <span class="o">=</span> <span class="p">[</span>
                <span class="nb">getattr</span><span class="p">(</span><span class="n">m</span><span class="p">[</span><span class="n">model_step</span><span class="p">],</span> <span class="n">model_prop</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">cv_results</span><span class="p">[</span><span class="s2">"estimator"</span><span class="p">]</span>
            <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">values</span> <span class="o">=</span> <span class="p">[</span><span class="nb">getattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">model_prop</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">cv_results</span><span class="p">[</span><span class="s2">"estimator"</span><span class="p">]]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Mean model.</span><span class="si">{</span><span class="n">model_prop</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function" href="https://numpy.org/doc/stable/reference/generated/numpy.mean.html#numpy.mean" title="numpy.mean"><span class="n">np</span><span class="o">.</span><span class="n">mean</span></a><span class="p">(</span><span class="n">values</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="n">mae</span> <span class="o">=</span> <span class="o">-</span><span class="n">cv_results</span><span class="p">[</span><span class="s2">"test_neg_mean_absolute_error"</span><span class="p">]</span>
    <span class="n">rmse</span> <span class="o">=</span> <span class="o">-</span><span class="n">cv_results</span><span class="p">[</span><span class="s2">"test_neg_root_mean_squared_error"</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">"Mean Absolute Error:     </span><span class="si">{</span><span class="n">mae</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> +/- </span><span class="si">{</span><span class="n">mae</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span>
        <span class="sa">f</span><span class="s2">"Root Mean Squared Error: </span><span class="si">{</span><span class="n">rmse</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> +/- </span><span class="si">{</span><span class="n">rmse</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">"</span>
    <span class="p">)</span>


<span class="n">evaluate</span><span class="p">(</span><span class="n">gbrt</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">ts_cv</span><span class="p">,</span> <span class="n">model_prop</span><span class="o">=</span><span class="s2">"n_iter_"</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Mean model.n_iter_ = 100.0
Mean Absolute Error:     0.044 +/- 0.003
Root Mean Squared Error: 0.068 +/- 0.005
</pre></div>
</div>
<p>We see that we set <code class="docutils literal notranslate"><span class="pre">max_iter</span></code> large enough such that early stopping took place.</p>
<p>This model has an average error around 4 to 5% of the maximum demand. This is
quite good for a first trial without any hyper-parameter tuning! We just had
to make the categorical variables explicit. Note that the time related
features are passed as is, i.e. without processing them. But this is not much
of a problem for tree-based models as they can learn a non-monotonic
relationship between ordinal input features and the target.</p>
<p>This is not the case for linear regression models as we will see in the
following.</p>
</section>
<section id="naive-linear-regression">
<h2>Naive linear regression<a class="headerlink" href="#naive-linear-regression" title="Link to this heading">#</a></h2>
<p>As usual for linear models, categorical variables need to be one-hot encoded.
For consistency, we scale the numerical features to the same 0-1 range using
<a class="reference internal" href="../../modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler" title="sklearn.preprocessing.MinMaxScaler"><code class="xref py py-class docutils literal notranslate"><span class="pre">MinMaxScaler</span></code></a>, although in this case it does not
impact the results much because they are already on comparable scales:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <a class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV" title="sklearn.linear_model.RidgeCV"><span class="n">RidgeCV</span></a>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <a class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler" title="sklearn.preprocessing.MinMaxScaler"><span class="n">MinMaxScaler</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder" title="sklearn.preprocessing.OneHotEncoder"><span class="n">OneHotEncoder</span></a>

<span class="n">one_hot_encoder</span> <span class="o">=</span> <a class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder" title="sklearn.preprocessing.OneHotEncoder"><span class="n">OneHotEncoder</span></a><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="s2">"ignore"</span><span class="p">,</span> <span class="n">sparse_output</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">alphas</span> <span class="o">=</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function" href="https://numpy.org/doc/stable/reference/generated/numpy.logspace.html#numpy.logspace" title="numpy.logspace"><span class="n">np</span><span class="o">.</span><span class="n">logspace</span></a><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">25</span><span class="p">)</span>
<span class="n">naive_linear_pipeline</span> <span class="o">=</span> <a class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="sklearn.pipeline.make_pipeline"><span class="n">make_pipeline</span></a><span class="p">(</span>
    <a class="sphx-glr-backref-module-sklearn-compose sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer" title="sklearn.compose.ColumnTransformer"><span class="n">ColumnTransformer</span></a><span class="p">(</span>
        <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
            <span class="p">(</span><span class="s2">"categorical"</span><span class="p">,</span> <span class="n">one_hot_encoder</span><span class="p">,</span> <span class="n">categorical_columns</span><span class="p">),</span>
        <span class="p">],</span>
        <span class="n">remainder</span><span class="o">=</span><a class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler" title="sklearn.preprocessing.MinMaxScaler"><span class="n">MinMaxScaler</span></a><span class="p">(),</span>
    <span class="p">),</span>
    <a class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV" title="sklearn.linear_model.RidgeCV"><span class="n">RidgeCV</span></a><span class="p">(</span><span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">),</span>
<span class="p">)</span>


<span class="n">evaluate</span><span class="p">(</span>
    <span class="n">naive_linear_pipeline</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">ts_cv</span><span class="p">,</span> <span class="n">model_prop</span><span class="o">=</span><span class="s2">"alpha_"</span><span class="p">,</span> <span class="n">model_step</span><span class="o">=</span><span class="s2">"ridgecv"</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Mean model.alpha_ = 2.7298221281347037
Mean Absolute Error:     0.142 +/- 0.014
Root Mean Squared Error: 0.184 +/- 0.020
</pre></div>
</div>
<p>It is affirmative to see that the selected <code class="docutils literal notranslate"><span class="pre">alpha_</span></code> is in our specified
range.</p>
<p>The performance is not good: the average error is around 14% of the maximum
demand. This is more than three times higher than the average error of the
gradient boosting model. We can suspect that the naive original encoding
(merely min-max scaled) of the periodic time-related features might prevent
the linear regression model to properly leverage the time information: linear
regression does not automatically model non-monotonic relationships between
the input features and the target. Non-linear terms have to be engineered in
the input.</p>
<p>For example, the raw numerical encoding of the <code class="docutils literal notranslate"><span class="pre">"hour"</span></code> feature prevents the
linear model from recognizing that an increase of hour in the morning from 6
to 8 should have a strong positive impact on the number of bike rentals while
an increase of similar magnitude in the evening from 18 to 20 should have a
strong negative impact on the predicted number of bike rentals.</p>
</section>
<section id="time-steps-as-categories">
<h2>Time-steps as categories<a class="headerlink" href="#time-steps-as-categories" title="Link to this heading">#</a></h2>
<p>Since the time features are encoded in a discrete manner using integers (24
unique values in the â€œhoursâ€ feature), we could decide to treat those as
categorical variables using a one-hot encoding and thereby ignore any
assumption implied by the ordering of the hour values.</p>
<p>Using one-hot encoding for the time features gives the linear model a lot
more flexibility as we introduce one additional feature per discrete time
level.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">one_hot_linear_pipeline</span> <span class="o">=</span> <a class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="sklearn.pipeline.make_pipeline"><span class="n">make_pipeline</span></a><span class="p">(</span>
    <a class="sphx-glr-backref-module-sklearn-compose sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer" title="sklearn.compose.ColumnTransformer"><span class="n">ColumnTransformer</span></a><span class="p">(</span>
        <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
            <span class="p">(</span><span class="s2">"categorical"</span><span class="p">,</span> <span class="n">one_hot_encoder</span><span class="p">,</span> <span class="n">categorical_columns</span><span class="p">),</span>
            <span class="p">(</span><span class="s2">"one_hot_time"</span><span class="p">,</span> <span class="n">one_hot_encoder</span><span class="p">,</span> <span class="p">[</span><span class="s2">"hour"</span><span class="p">,</span> <span class="s2">"weekday"</span><span class="p">,</span> <span class="s2">"month"</span><span class="p">]),</span>
        <span class="p">],</span>
        <span class="n">remainder</span><span class="o">=</span><a class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler" title="sklearn.preprocessing.MinMaxScaler"><span class="n">MinMaxScaler</span></a><span class="p">(),</span>
    <span class="p">),</span>
    <a class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV" title="sklearn.linear_model.RidgeCV"><span class="n">RidgeCV</span></a><span class="p">(</span><span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">evaluate</span><span class="p">(</span><span class="n">one_hot_linear_pipeline</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">ts_cv</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Mean Absolute Error:     0.099 +/- 0.011
Root Mean Squared Error: 0.131 +/- 0.011
</pre></div>
</div>
<p>The average error rate of this model is 10% which is much better than using
the original (ordinal) encoding of the time feature, confirming our intuition
that the linear regression model benefits from the added flexibility to not
treat time progression in a monotonic manner.</p>
<p>However, this introduces a very large number of new features. If the time of
the day was represented in minutes since the start of the day instead of
hours, one-hot encoding would have introduced 1440 features instead of 24.
This could cause some significant overfitting. To avoid this we could use
<a class="reference internal" href="../../modules/generated/sklearn.preprocessing.KBinsDiscretizer.html#sklearn.preprocessing.KBinsDiscretizer" title="sklearn.preprocessing.KBinsDiscretizer"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.preprocessing.KBinsDiscretizer</span></code></a> instead to re-bin the number
of levels of fine-grained ordinal or numerical variables while still
benefitting from the non-monotonic expressivity advantages of one-hot
encoding.</p>
<p>Finally, we also observe that one-hot encoding completely ignores the
ordering of the hour levels while this could be an interesting inductive bias
to preserve to some level. In the following we try to explore smooth,
non-monotonic encoding that locally preserves the relative ordering of time
features.</p>
</section>
<section id="trigonometric-features">
<h2>Trigonometric features<a class="headerlink" href="#trigonometric-features" title="Link to this heading">#</a></h2>
<p>As a first attempt, we can try to encode each of those periodic features
using a sine and cosine transformation with the matching period.</p>
<p>Each ordinal time feature is transformed into 2 features that together encode
equivalent information in a non-monotonic way, and more importantly without
any jump between the first and the last value of the periodic range.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <a class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.preprocessing.FunctionTransformer.html#sklearn.preprocessing.FunctionTransformer" title="sklearn.preprocessing.FunctionTransformer"><span class="n">FunctionTransformer</span></a>


<span class="k">def</span> <span class="nf">sin_transformer</span><span class="p">(</span><span class="n">period</span><span class="p">):</span>
    <span class="k">return</span> <a class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.preprocessing.FunctionTransformer.html#sklearn.preprocessing.FunctionTransformer" title="sklearn.preprocessing.FunctionTransformer"><span class="n">FunctionTransformer</span></a><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-data" href="https://numpy.org/doc/stable/reference/generated/numpy.sin.html#numpy.sin" title="numpy.sin"><span class="n">np</span><span class="o">.</span><span class="n">sin</span></a><span class="p">(</span><span class="n">x</span> <span class="o">/</span> <span class="n">period</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-data" href="https://numpy.org/doc/stable/reference/constants.html#numpy.pi" title="numpy.pi"><span class="n">np</span><span class="o">.</span><span class="n">pi</span></a><span class="p">))</span>


<span class="k">def</span> <span class="nf">cos_transformer</span><span class="p">(</span><span class="n">period</span><span class="p">):</span>
    <span class="k">return</span> <a class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.preprocessing.FunctionTransformer.html#sklearn.preprocessing.FunctionTransformer" title="sklearn.preprocessing.FunctionTransformer"><span class="n">FunctionTransformer</span></a><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-data" href="https://numpy.org/doc/stable/reference/generated/numpy.cos.html#numpy.cos" title="numpy.cos"><span class="n">np</span><span class="o">.</span><span class="n">cos</span></a><span class="p">(</span><span class="n">x</span> <span class="o">/</span> <span class="n">period</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-data" href="https://numpy.org/doc/stable/reference/constants.html#numpy.pi" title="numpy.pi"><span class="n">np</span><span class="o">.</span><span class="n">pi</span></a><span class="p">))</span>
</pre></div>
</div>
<p>Let us visualize the effect of this feature expansion on some synthetic hour
data with a bit of extrapolation beyond hour=23:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">hour_df</span> <span class="o">=</span> <a class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span>
    <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function" href="https://numpy.org/doc/stable/reference/generated/numpy.arange.html#numpy.arange" title="numpy.arange"><span class="n">np</span><span class="o">.</span><span class="n">arange</span></a><span class="p">(</span><span class="mi">26</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"hour"</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">hour_df</span><span class="p">[</span><span class="s2">"hour_sin"</span><span class="p">]</span> <span class="o">=</span> <span class="n">sin_transformer</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">hour_df</span><span class="p">)[</span><span class="s2">"hour"</span><span class="p">]</span>
<span class="n">hour_df</span><span class="p">[</span><span class="s2">"hour_cos"</span><span class="p">]</span> <span class="o">=</span> <span class="n">cos_transformer</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">hour_df</span><span class="p">)[</span><span class="s2">"hour"</span><span class="p">]</span>
<span class="n">hour_df</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"hour"</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <a class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.title.html#matplotlib.pyplot.title" title="matplotlib.pyplot.title"><span class="n">plt</span><span class="o">.</span><span class="n">title</span></a><span class="p">(</span><span class="s2">"Trigonometric encoding for the 'hour' feature"</span><span class="p">)</span>
</pre></div>
</div>
<img alt="Trigonometric encoding for the 'hour' feature" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_cyclical_feature_engineering_003.png" srcset="../../_images/sphx_glr_plot_cyclical_feature_engineering_003.png"/><p>Letâ€™s use a 2D scatter plot with the hours encoded as colors to better see
how this representation maps the 24 hours of the day to a 2D space, akin to
some sort of a 24 hour version of an analog clock. Note that the â€œ25thâ€ hour
is mapped back to the 1st hour because of the periodic nature of the
sine/cosine representation.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">sp</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">hour_df</span><span class="p">[</span><span class="s2">"hour_sin"</span><span class="p">],</span> <span class="n">hour_df</span><span class="p">[</span><span class="s2">"hour_cos"</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">hour_df</span><span class="p">[</span><span class="s2">"hour"</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">"sin(hour)"</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">"cos(hour)"</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">sp</span><span class="p">)</span>
</pre></div>
</div>
<img alt="plot cyclical feature engineering" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_cyclical_feature_engineering_004.png" srcset="../../_images/sphx_glr_plot_cyclical_feature_engineering_004.png"/><p>We can now build a feature extraction pipeline using this strategy:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">cyclic_cossin_transformer</span> <span class="o">=</span> <a class="sphx-glr-backref-module-sklearn-compose sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer" title="sklearn.compose.ColumnTransformer"><span class="n">ColumnTransformer</span></a><span class="p">(</span>
    <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s2">"categorical"</span><span class="p">,</span> <span class="n">one_hot_encoder</span><span class="p">,</span> <span class="n">categorical_columns</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">"month_sin"</span><span class="p">,</span> <span class="n">sin_transformer</span><span class="p">(</span><span class="mi">12</span><span class="p">),</span> <span class="p">[</span><span class="s2">"month"</span><span class="p">]),</span>
        <span class="p">(</span><span class="s2">"month_cos"</span><span class="p">,</span> <span class="n">cos_transformer</span><span class="p">(</span><span class="mi">12</span><span class="p">),</span> <span class="p">[</span><span class="s2">"month"</span><span class="p">]),</span>
        <span class="p">(</span><span class="s2">"weekday_sin"</span><span class="p">,</span> <span class="n">sin_transformer</span><span class="p">(</span><span class="mi">7</span><span class="p">),</span> <span class="p">[</span><span class="s2">"weekday"</span><span class="p">]),</span>
        <span class="p">(</span><span class="s2">"weekday_cos"</span><span class="p">,</span> <span class="n">cos_transformer</span><span class="p">(</span><span class="mi">7</span><span class="p">),</span> <span class="p">[</span><span class="s2">"weekday"</span><span class="p">]),</span>
        <span class="p">(</span><span class="s2">"hour_sin"</span><span class="p">,</span> <span class="n">sin_transformer</span><span class="p">(</span><span class="mi">24</span><span class="p">),</span> <span class="p">[</span><span class="s2">"hour"</span><span class="p">]),</span>
        <span class="p">(</span><span class="s2">"hour_cos"</span><span class="p">,</span> <span class="n">cos_transformer</span><span class="p">(</span><span class="mi">24</span><span class="p">),</span> <span class="p">[</span><span class="s2">"hour"</span><span class="p">]),</span>
    <span class="p">],</span>
    <span class="n">remainder</span><span class="o">=</span><a class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler" title="sklearn.preprocessing.MinMaxScaler"><span class="n">MinMaxScaler</span></a><span class="p">(),</span>
<span class="p">)</span>
<span class="n">cyclic_cossin_linear_pipeline</span> <span class="o">=</span> <a class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="sklearn.pipeline.make_pipeline"><span class="n">make_pipeline</span></a><span class="p">(</span>
    <span class="n">cyclic_cossin_transformer</span><span class="p">,</span>
    <a class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV" title="sklearn.linear_model.RidgeCV"><span class="n">RidgeCV</span></a><span class="p">(</span><span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">cyclic_cossin_linear_pipeline</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">ts_cv</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Mean Absolute Error:     0.125 +/- 0.014
Root Mean Squared Error: 0.166 +/- 0.020
</pre></div>
</div>
<p>The performance of our linear regression model with this simple feature
engineering is a bit better than using the original ordinal time features but
worse than using the one-hot encoded time features. We will further analyze
possible reasons for this disappointing outcome at the end of this notebook.</p>
</section>
<section id="periodic-spline-features">
<h2>Periodic spline features<a class="headerlink" href="#periodic-spline-features" title="Link to this heading">#</a></h2>
<p>We can try an alternative encoding of the periodic time-related features
using spline transformations with a large enough number of splines, and as a
result a larger number of expanded features compared to the sine/cosine
transformation:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <a class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.preprocessing.SplineTransformer.html#sklearn.preprocessing.SplineTransformer" title="sklearn.preprocessing.SplineTransformer"><span class="n">SplineTransformer</span></a>


<span class="k">def</span> <span class="nf">periodic_spline_transformer</span><span class="p">(</span><span class="n">period</span><span class="p">,</span> <span class="n">n_splines</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">n_splines</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">n_splines</span> <span class="o">=</span> <span class="n">period</span>
    <span class="n">n_knots</span> <span class="o">=</span> <span class="n">n_splines</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># periodic and include_bias is True</span>
    <span class="k">return</span> <a class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.preprocessing.SplineTransformer.html#sklearn.preprocessing.SplineTransformer" title="sklearn.preprocessing.SplineTransformer"><span class="n">SplineTransformer</span></a><span class="p">(</span>
        <span class="n">degree</span><span class="o">=</span><span class="n">degree</span><span class="p">,</span>
        <span class="n">n_knots</span><span class="o">=</span><span class="n">n_knots</span><span class="p">,</span>
        <span class="n">knots</span><span class="o">=</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function" href="https://numpy.org/doc/stable/reference/generated/numpy.linspace.html#numpy.linspace" title="numpy.linspace"><span class="n">np</span><span class="o">.</span><span class="n">linspace</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">period</span><span class="p">,</span> <span class="n">n_knots</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_knots</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">extrapolation</span><span class="o">=</span><span class="s2">"periodic"</span><span class="p">,</span>
        <span class="n">include_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
<p>Again, let us visualize the effect of this feature expansion on some
synthetic hour data with a bit of extrapolation beyond hour=23:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">hour_df</span> <span class="o">=</span> <a class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span>
    <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function" href="https://numpy.org/doc/stable/reference/generated/numpy.linspace.html#numpy.linspace" title="numpy.linspace"><span class="n">np</span><span class="o">.</span><span class="n">linspace</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">26</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"hour"</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">splines</span> <span class="o">=</span> <span class="n">periodic_spline_transformer</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="n">n_splines</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">hour_df</span><span class="p">)</span>
<span class="n">splines_df</span> <span class="o">=</span> <a class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span>
    <span class="n">splines</span><span class="p">,</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="s2">"spline_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">splines</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span>
<span class="p">)</span>
<a class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-function" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html#pandas.concat" title="pandas.concat"><span class="n">pd</span><span class="o">.</span><span class="n">concat</span></a><span class="p">([</span><span class="n">hour_df</span><span class="p">,</span> <span class="n">splines_df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"hour"</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">tab20b</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <a class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.title.html#matplotlib.pyplot.title" title="matplotlib.pyplot.title"><span class="n">plt</span><span class="o">.</span><span class="n">title</span></a><span class="p">(</span><span class="s2">"Periodic spline-based encoding for the 'hour' feature"</span><span class="p">)</span>
</pre></div>
</div>
<img alt="Periodic spline-based encoding for the 'hour' feature" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_cyclical_feature_engineering_005.png" srcset="../../_images/sphx_glr_plot_cyclical_feature_engineering_005.png"/><p>Thanks to the use of the <code class="docutils literal notranslate"><span class="pre">extrapolation="periodic"</span></code> parameter, we observe
that the feature encoding stays smooth when extrapolating beyond midnight.</p>
<p>We can now build a predictive pipeline using this alternative periodic
feature engineering strategy.</p>
<p>It is possible to use fewer splines than discrete levels for those ordinal
values. This makes spline-based encoding more efficient than one-hot encoding
while preserving most of the expressivity:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">cyclic_spline_transformer</span> <span class="o">=</span> <a class="sphx-glr-backref-module-sklearn-compose sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer" title="sklearn.compose.ColumnTransformer"><span class="n">ColumnTransformer</span></a><span class="p">(</span>
    <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s2">"categorical"</span><span class="p">,</span> <span class="n">one_hot_encoder</span><span class="p">,</span> <span class="n">categorical_columns</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">"cyclic_month"</span><span class="p">,</span> <span class="n">periodic_spline_transformer</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="n">n_splines</span><span class="o">=</span><span class="mi">6</span><span class="p">),</span> <span class="p">[</span><span class="s2">"month"</span><span class="p">]),</span>
        <span class="p">(</span><span class="s2">"cyclic_weekday"</span><span class="p">,</span> <span class="n">periodic_spline_transformer</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="n">n_splines</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span> <span class="p">[</span><span class="s2">"weekday"</span><span class="p">]),</span>
        <span class="p">(</span><span class="s2">"cyclic_hour"</span><span class="p">,</span> <span class="n">periodic_spline_transformer</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="n">n_splines</span><span class="o">=</span><span class="mi">12</span><span class="p">),</span> <span class="p">[</span><span class="s2">"hour"</span><span class="p">]),</span>
    <span class="p">],</span>
    <span class="n">remainder</span><span class="o">=</span><a class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler" title="sklearn.preprocessing.MinMaxScaler"><span class="n">MinMaxScaler</span></a><span class="p">(),</span>
<span class="p">)</span>
<span class="n">cyclic_spline_linear_pipeline</span> <span class="o">=</span> <a class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="sklearn.pipeline.make_pipeline"><span class="n">make_pipeline</span></a><span class="p">(</span>
    <span class="n">cyclic_spline_transformer</span><span class="p">,</span>
    <a class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV" title="sklearn.linear_model.RidgeCV"><span class="n">RidgeCV</span></a><span class="p">(</span><span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">cyclic_spline_linear_pipeline</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">ts_cv</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Mean Absolute Error:     0.097 +/- 0.011
Root Mean Squared Error: 0.132 +/- 0.013
</pre></div>
</div>
<p>Spline features make it possible for the linear model to successfully
leverage the periodic time-related features and reduce the error from ~14% to
~10% of the maximum demand, which is similar to what we observed with the
one-hot encoded features.</p>
</section>
<section id="qualitative-analysis-of-the-impact-of-features-on-linear-model-predictions">
<h2>Qualitative analysis of the impact of features on linear model predictions<a class="headerlink" href="#qualitative-analysis-of-the-impact-of-features-on-linear-model-predictions" title="Link to this heading">#</a></h2>
<p>Here, we want to visualize the impact of the feature engineering choices on
the time related shape of the predictions.</p>
<p>To do so we consider an arbitrary time-based split to compare the predictions
on a range of held out data points.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">naive_linear_pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_0</span><span class="p">],</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_0</span><span class="p">])</span>
<span class="n">naive_linear_predictions</span> <span class="o">=</span> <span class="n">naive_linear_pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_0</span><span class="p">])</span>

<span class="n">one_hot_linear_pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_0</span><span class="p">],</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_0</span><span class="p">])</span>
<span class="n">one_hot_linear_predictions</span> <span class="o">=</span> <span class="n">one_hot_linear_pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_0</span><span class="p">])</span>

<span class="n">cyclic_cossin_linear_pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_0</span><span class="p">],</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_0</span><span class="p">])</span>
<span class="n">cyclic_cossin_linear_predictions</span> <span class="o">=</span> <span class="n">cyclic_cossin_linear_pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_0</span><span class="p">])</span>

<span class="n">cyclic_spline_linear_pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_0</span><span class="p">],</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_0</span><span class="p">])</span>
<span class="n">cyclic_spline_linear_predictions</span> <span class="o">=</span> <span class="n">cyclic_spline_linear_pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_0</span><span class="p">])</span>
</pre></div>
</div>
<p>We visualize those predictions by zooming on the last 96 hours (4 days) of
the test set to get some qualitative insights:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">last_hours</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="o">-</span><span class="mi">96</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">"Predictions by linear models"</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_0</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">last_hours</span><span class="p">],</span>
    <span class="s2">"x-"</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">"Actual demand"</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">naive_linear_predictions</span><span class="p">[</span><span class="n">last_hours</span><span class="p">],</span> <span class="s2">"x-"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Ordinal time features"</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">cyclic_cossin_linear_predictions</span><span class="p">[</span><span class="n">last_hours</span><span class="p">],</span>
    <span class="s2">"x-"</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">"Trigonometric time features"</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">cyclic_spline_linear_predictions</span><span class="p">[</span><span class="n">last_hours</span><span class="p">],</span>
    <span class="s2">"x-"</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">"Spline-based time features"</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">one_hot_linear_predictions</span><span class="p">[</span><span class="n">last_hours</span><span class="p">],</span>
    <span class="s2">"x-"</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">"One-hot time features"</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img alt="Predictions by linear models" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_cyclical_feature_engineering_006.png" srcset="../../_images/sphx_glr_plot_cyclical_feature_engineering_006.png"/><p>We can draw the following conclusions from the above plot:</p>
<ul class="simple">
<li><p>The <strong>raw ordinal time-related features</strong> are problematic because they do
not capture the natural periodicity: we observe a big jump in the
predictions at the end of each day when the hour features goes from 23 back
to 0. We can expect similar artifacts at the end of each week or each year.</p></li>
<li><p>As expected, the <strong>trigonometric features</strong> (sine and cosine) do not have
these discontinuities at midnight, but the linear regression model fails to
leverage those features to properly model intra-day variations.
Using trigonometric features for higher harmonics or additional
trigonometric features for the natural period with different phases could
potentially fix this problem.</p></li>
<li><p>the <strong>periodic spline-based features</strong> fix those two problems at once: they
give more expressivity to the linear model by making it possible to focus
on specific hours thanks to the use of 12 splines. Furthermore the
<code class="docutils literal notranslate"><span class="pre">extrapolation="periodic"</span></code> option enforces a smooth representation between
<code class="docutils literal notranslate"><span class="pre">hour=23</span></code> and <code class="docutils literal notranslate"><span class="pre">hour=0</span></code>.</p></li>
<li><p>The <strong>one-hot encoded features</strong> behave similarly to the periodic
spline-based features but are more spiky: for instance they can better
model the morning peak during the week days since this peak lasts shorter
than an hour. However, we will see in the following that what can be an
advantage for linear models is not necessarily one for more expressive
models.</p></li>
</ul>
<p>We can also compare the number of features extracted by each feature
engineering pipeline:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">naive_linear_pipeline</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>(17379, 19)
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">one_hot_linear_pipeline</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>(17379, 59)
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">cyclic_cossin_linear_pipeline</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>(17379, 22)
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">cyclic_spline_linear_pipeline</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>(17379, 37)
</pre></div>
</div>
<p>This confirms that the one-hot encoding and the spline encoding strategies
create a lot more features for the time representation than the alternatives,
which in turn gives the downstream linear model more flexibility (degrees of
freedom) to avoid underfitting.</p>
<p>Finally, we observe that none of the linear models can approximate the true
bike rentals demand, especially for the peaks that can be very sharp at rush
hours during the working days but much flatter during the week-ends: the most
accurate linear models based on splines or one-hot encoding tend to forecast
peaks of commuting-related bike rentals even on the week-ends and
under-estimate the commuting-related events during the working days.</p>
<p>These systematic prediction errors reveal a form of under-fitting and can be
explained by the lack of interactions terms between features, e.g.
â€œworkingdayâ€ and features derived from â€œhoursâ€. This issue will be addressed
in the following section.</p>
</section>
<section id="modeling-pairwise-interactions-with-splines-and-polynomial-features">
<h2>Modeling pairwise interactions with splines and polynomial features<a class="headerlink" href="#modeling-pairwise-interactions-with-splines-and-polynomial-features" title="Link to this heading">#</a></h2>
<p>Linear models do not automatically capture interaction effects between input
features. It does not help that some features are marginally non-linear as is
the case with features constructed by <code class="docutils literal notranslate"><span class="pre">SplineTransformer</span></code> (or one-hot
encoding or binning).</p>
<p>However, it is possible to use the <code class="docutils literal notranslate"><span class="pre">PolynomialFeatures</span></code> class on coarse
grained spline encoded hours to model the â€œworkingdayâ€/â€hoursâ€ interaction
explicitly without introducing too many new variables:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <a class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.pipeline.FeatureUnion.html#sklearn.pipeline.FeatureUnion" title="sklearn.pipeline.FeatureUnion"><span class="n">FeatureUnion</span></a>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <a class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.preprocessing.PolynomialFeatures.html#sklearn.preprocessing.PolynomialFeatures" title="sklearn.preprocessing.PolynomialFeatures"><span class="n">PolynomialFeatures</span></a>

<span class="n">hour_workday_interaction</span> <span class="o">=</span> <a class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="sklearn.pipeline.make_pipeline"><span class="n">make_pipeline</span></a><span class="p">(</span>
    <a class="sphx-glr-backref-module-sklearn-compose sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer" title="sklearn.compose.ColumnTransformer"><span class="n">ColumnTransformer</span></a><span class="p">(</span>
        <span class="p">[</span>
            <span class="p">(</span><span class="s2">"cyclic_hour"</span><span class="p">,</span> <span class="n">periodic_spline_transformer</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="n">n_splines</span><span class="o">=</span><span class="mi">8</span><span class="p">),</span> <span class="p">[</span><span class="s2">"hour"</span><span class="p">]),</span>
            <span class="p">(</span><span class="s2">"workingday"</span><span class="p">,</span> <a class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.preprocessing.FunctionTransformer.html#sklearn.preprocessing.FunctionTransformer" title="sklearn.preprocessing.FunctionTransformer"><span class="n">FunctionTransformer</span></a><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">==</span> <span class="s2">"True"</span><span class="p">),</span> <span class="p">[</span><span class="s2">"workingday"</span><span class="p">]),</span>
        <span class="p">]</span>
    <span class="p">),</span>
    <a class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.preprocessing.PolynomialFeatures.html#sklearn.preprocessing.PolynomialFeatures" title="sklearn.preprocessing.PolynomialFeatures"><span class="n">PolynomialFeatures</span></a><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">interaction_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Those features are then combined with the ones already computed in the
previous spline-base pipeline. We can observe a nice performance improvement
by modeling this pairwise interaction explicitly:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">cyclic_spline_interactions_pipeline</span> <span class="o">=</span> <a class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="sklearn.pipeline.make_pipeline"><span class="n">make_pipeline</span></a><span class="p">(</span>
    <a class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.pipeline.FeatureUnion.html#sklearn.pipeline.FeatureUnion" title="sklearn.pipeline.FeatureUnion"><span class="n">FeatureUnion</span></a><span class="p">(</span>
        <span class="p">[</span>
            <span class="p">(</span><span class="s2">"marginal"</span><span class="p">,</span> <span class="n">cyclic_spline_transformer</span><span class="p">),</span>
            <span class="p">(</span><span class="s2">"interactions"</span><span class="p">,</span> <span class="n">hour_workday_interaction</span><span class="p">),</span>
        <span class="p">]</span>
    <span class="p">),</span>
    <a class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV" title="sklearn.linear_model.RidgeCV"><span class="n">RidgeCV</span></a><span class="p">(</span><span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">cyclic_spline_interactions_pipeline</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">ts_cv</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Mean Absolute Error:     0.078 +/- 0.009
Root Mean Squared Error: 0.104 +/- 0.009
</pre></div>
</div>
</section>
<section id="modeling-non-linear-feature-interactions-with-kernels">
<h2>Modeling non-linear feature interactions with kernels<a class="headerlink" href="#modeling-non-linear-feature-interactions-with-kernels" title="Link to this heading">#</a></h2>
<p>The previous analysis highlighted the need to model the interactions between
<code class="docutils literal notranslate"><span class="pre">"workingday"</span></code> and <code class="docutils literal notranslate"><span class="pre">"hours"</span></code>. Another example of a such a non-linear
interaction that we would like to model could be the impact of the rain that
might not be the same during the working days and the week-ends and holidays
for instance.</p>
<p>To model all such interactions, we could either use a polynomial expansion on
all marginal features at once, after their spline-based expansion. However,
this would create a quadratic number of features which can cause overfitting
and computational tractability issues.</p>
<p>Alternatively, we can use the NystrÃ¶m method to compute an approximate
polynomial kernel expansion. Let us try the latter:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.kernel_approximation</span> <span class="kn">import</span> <a class="sphx-glr-backref-module-sklearn-kernel_approximation sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.kernel_approximation.Nystroem.html#sklearn.kernel_approximation.Nystroem" title="sklearn.kernel_approximation.Nystroem"><span class="n">Nystroem</span></a>

<span class="n">cyclic_spline_poly_pipeline</span> <span class="o">=</span> <a class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="sklearn.pipeline.make_pipeline"><span class="n">make_pipeline</span></a><span class="p">(</span>
    <span class="n">cyclic_spline_transformer</span><span class="p">,</span>
    <a class="sphx-glr-backref-module-sklearn-kernel_approximation sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.kernel_approximation.Nystroem.html#sklearn.kernel_approximation.Nystroem" title="sklearn.kernel_approximation.Nystroem"><span class="n">Nystroem</span></a><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">"poly"</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <a class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV" title="sklearn.linear_model.RidgeCV"><span class="n">RidgeCV</span></a><span class="p">(</span><span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">cyclic_spline_poly_pipeline</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">ts_cv</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Mean Absolute Error:     0.053 +/- 0.002
Root Mean Squared Error: 0.076 +/- 0.004
</pre></div>
</div>
<p>We observe that this model can almost rival the performance of the gradient
boosted trees with an average error around 5% of the maximum demand.</p>
<p>Note that while the final step of this pipeline is a linear regression model,
the intermediate steps such as the spline feature extraction and the NystrÃ¶m
kernel approximation are highly non-linear. As a result the compound pipeline
is much more expressive than a simple linear regression model with raw features.</p>
<p>For the sake of completeness, we also evaluate the combination of one-hot
encoding and kernel approximation:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">one_hot_poly_pipeline</span> <span class="o">=</span> <a class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="sklearn.pipeline.make_pipeline"><span class="n">make_pipeline</span></a><span class="p">(</span>
    <a class="sphx-glr-backref-module-sklearn-compose sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer" title="sklearn.compose.ColumnTransformer"><span class="n">ColumnTransformer</span></a><span class="p">(</span>
        <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
            <span class="p">(</span><span class="s2">"categorical"</span><span class="p">,</span> <span class="n">one_hot_encoder</span><span class="p">,</span> <span class="n">categorical_columns</span><span class="p">),</span>
            <span class="p">(</span><span class="s2">"one_hot_time"</span><span class="p">,</span> <span class="n">one_hot_encoder</span><span class="p">,</span> <span class="p">[</span><span class="s2">"hour"</span><span class="p">,</span> <span class="s2">"weekday"</span><span class="p">,</span> <span class="s2">"month"</span><span class="p">]),</span>
        <span class="p">],</span>
        <span class="n">remainder</span><span class="o">=</span><span class="s2">"passthrough"</span><span class="p">,</span>
    <span class="p">),</span>
    <a class="sphx-glr-backref-module-sklearn-kernel_approximation sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.kernel_approximation.Nystroem.html#sklearn.kernel_approximation.Nystroem" title="sklearn.kernel_approximation.Nystroem"><span class="n">Nystroem</span></a><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">"poly"</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <a class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV" title="sklearn.linear_model.RidgeCV"><span class="n">RidgeCV</span></a><span class="p">(</span><span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">one_hot_poly_pipeline</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">ts_cv</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Mean Absolute Error:     0.082 +/- 0.006
Root Mean Squared Error: 0.111 +/- 0.011
</pre></div>
</div>
<p>While one-hot encoded features were competitive with spline-based features
when using linear models, this is no longer the case when using a low-rank
approximation of a non-linear kernel: this can be explained by the fact that
spline features are smoother and allow the kernel approximation to find a
more expressive decision function.</p>
<p>Let us now have a qualitative look at the predictions of the kernel models
and of the gradient boosted trees that should be able to better model
non-linear interactions between features:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">gbrt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_0</span><span class="p">],</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_0</span><span class="p">])</span>
<span class="n">gbrt_predictions</span> <span class="o">=</span> <span class="n">gbrt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_0</span><span class="p">])</span>

<span class="n">one_hot_poly_pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_0</span><span class="p">],</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_0</span><span class="p">])</span>
<span class="n">one_hot_poly_predictions</span> <span class="o">=</span> <span class="n">one_hot_poly_pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_0</span><span class="p">])</span>

<span class="n">cyclic_spline_poly_pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_0</span><span class="p">],</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_0</span><span class="p">])</span>
<span class="n">cyclic_spline_poly_predictions</span> <span class="o">=</span> <span class="n">cyclic_spline_poly_pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_0</span><span class="p">])</span>
</pre></div>
</div>
<p>Again we zoom on the last 4 days of the test set:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">last_hours</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="o">-</span><span class="mi">96</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">"Predictions by non-linear regression models"</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_0</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">last_hours</span><span class="p">],</span>
    <span class="s2">"x-"</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">"Actual demand"</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">gbrt_predictions</span><span class="p">[</span><span class="n">last_hours</span><span class="p">],</span>
    <span class="s2">"x-"</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">"Gradient Boosted Trees"</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">one_hot_poly_predictions</span><span class="p">[</span><span class="n">last_hours</span><span class="p">],</span>
    <span class="s2">"x-"</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">"One-hot + polynomial kernel"</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">cyclic_spline_poly_predictions</span><span class="p">[</span><span class="n">last_hours</span><span class="p">],</span>
    <span class="s2">"x-"</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">"Splines + polynomial kernel"</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img alt="Predictions by non-linear regression models" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_cyclical_feature_engineering_007.png" srcset="../../_images/sphx_glr_plot_cyclical_feature_engineering_007.png"/><p>First, note that trees can naturally model non-linear feature interactions
since, by default, decision trees are allowed to grow beyond a depth of 2
levels.</p>
<p>Here, we can observe that the combinations of spline features and non-linear
kernels works quite well and can almost rival the accuracy of the gradient
boosting regression trees.</p>
<p>On the contrary, one-hot encoded time features do not perform that well with
the low rank kernel model. In particular, they significantly over-estimate
the low demand hours more than the competing models.</p>
<p>We also observe that none of the models can successfully predict some of the
peak rentals at the rush hours during the working days. It is possible that
access to additional features would be required to further improve the
accuracy of the predictions. For instance, it could be useful to have access
to the geographical repartition of the fleet at any point in time or the
fraction of bikes that are immobilized because they need servicing.</p>
<p>Let us finally get a more quantitative look at the prediction errors of those
three models using the true vs predicted demand scatter plots:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">PredictionErrorDisplay</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <a class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="s2">"row"</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">"Non-linear regression models"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">one_hot_poly_predictions</span><span class="p">,</span>
    <span class="n">cyclic_spline_poly_predictions</span><span class="p">,</span>
    <span class="n">gbrt_predictions</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">"One hot +</span><span class="se">\n</span><span class="s2">polynomial kernel"</span><span class="p">,</span>
    <span class="s2">"Splines +</span><span class="se">\n</span><span class="s2">polynomial kernel"</span><span class="p">,</span>
    <span class="s2">"Gradient Boosted</span><span class="se">\n</span><span class="s2">Trees"</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">plot_kinds</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"actual_vs_predicted"</span><span class="p">,</span> <span class="s2">"residual_vs_predicted"</span><span class="p">]</span>
<span class="k">for</span> <span class="n">axis_idx</span><span class="p">,</span> <span class="n">kind</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">plot_kinds</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="n">axis_idx</span><span class="p">],</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="n">disp</span> <span class="o">=</span> <a class="sphx-glr-backref-module-sklearn-metrics-PredictionErrorDisplay sphx-glr-backref-type-py-method" href="../../modules/generated/sklearn.metrics.PredictionErrorDisplay.html#sklearn.metrics.PredictionErrorDisplay.from_predictions" title="sklearn.metrics.PredictionErrorDisplay.from_predictions"><span class="n">PredictionErrorDisplay</span><span class="o">.</span><span class="n">from_predictions</span></a><span class="p">(</span>
            <span class="n">y_true</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_0</span><span class="p">],</span>
            <span class="n">y_pred</span><span class="o">=</span><span class="n">pred</span><span class="p">,</span>
            <span class="n">kind</span><span class="o">=</span><span class="n">kind</span><span class="p">,</span>
            <span class="n">scatter_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">"alpha"</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">},</span>
            <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function" href="https://numpy.org/doc/stable/reference/generated/numpy.linspace.html#numpy.linspace" title="numpy.linspace"><span class="n">np</span><span class="o">.</span><span class="n">linspace</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">5</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">axis_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function" href="https://numpy.org/doc/stable/reference/generated/numpy.linspace.html#numpy.linspace" title="numpy.linspace"><span class="n">np</span><span class="o">.</span><span class="n">linspace</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">5</span><span class="p">))</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span>
                <span class="p">[</span><span class="s2">"Best model"</span><span class="p">,</span> <span class="n">label</span><span class="p">],</span>
                <span class="n">loc</span><span class="o">=</span><span class="s2">"upper center"</span><span class="p">,</span>
                <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">),</span>
                <span class="n">ncol</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s2">"equal"</span><span class="p">,</span> <span class="n">adjustable</span><span class="o">=</span><span class="s2">"box"</span><span class="p">)</span>
<a class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.show.html#matplotlib.pyplot.show" title="matplotlib.pyplot.show"><span class="n">plt</span><span class="o">.</span><span class="n">show</span></a><span class="p">()</span>
</pre></div>
</div>
<img alt="Non-linear regression models" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_cyclical_feature_engineering_008.png" srcset="../../_images/sphx_glr_plot_cyclical_feature_engineering_008.png"/><p>This visualization confirms the conclusions we draw on the previous plot.</p>
<p>All models under-estimate the high demand events (working day rush hours),
but gradient boosting a bit less so. The low demand events are well predicted
on average by gradient boosting while the one-hot polynomial regression
pipeline seems to systematically over-estimate demand in that regime. Overall
the predictions of the gradient boosted trees are closer to the diagonal than
for the kernel models.</p>
</section>
<section id="concluding-remarks">
<h2>Concluding remarks<a class="headerlink" href="#concluding-remarks" title="Link to this heading">#</a></h2>
<p>We note that we could have obtained slightly better results for kernel models
by using more components (higher rank kernel approximation) at the cost of
longer fit and prediction durations. For large values of <code class="docutils literal notranslate"><span class="pre">n_components</span></code>, the
performance of the one-hot encoded features would even match the spline
features.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">Nystroem</span></code> + <code class="docutils literal notranslate"><span class="pre">RidgeCV</span></code> regressor could also have been replaced by
<a class="reference internal" href="../../modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor" title="sklearn.neural_network.MLPRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">MLPRegressor</span></code></a> with one or two hidden layers
and we would have obtained quite similar results.</p>
<p>The dataset we used in this case study is sampled on a hourly basis. However
cyclic spline-based features could model time-within-day or time-within-week
very efficiently with finer-grained time resolutions (for instance with
measurements taken every minute instead of every hours) without introducing
more features. One-hot encoding time representations would not offer this
flexibility.</p>
<p>Finally, in this notebook we used <code class="docutils literal notranslate"><span class="pre">RidgeCV</span></code> because it is very efficient from
a computational point of view. However, it models the target variable as a
Gaussian random variable with constant variance. For positive regression
problems, it is likely that using a Poisson or Gamma distribution would make
more sense. This could be achieved by using
<code class="docutils literal notranslate"><span class="pre">GridSearchCV(TweedieRegressor(power=2),</span> <span class="pre">param_grid({"alpha":</span> <span class="pre">alphas}))</span></code>
instead of <code class="docutils literal notranslate"><span class="pre">RidgeCV</span></code>.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 13.689 seconds)</p>

<p class="rubric">Related examples</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates how Polars-engineered lagged features can be used for time series forecasting with HistGradientBoostingRegressor on the Bike Sharing Demand dataset."><img alt="" src="../../_images/sphx_glr_plot_time_series_lagged_features_thumb.png"/>
<p><a class="reference internal" href="plot_time_series_lagged_features.html#sphx-glr-auto-examples-applications-plot-time-series-lagged-features-py"><span class="std std-ref">Lagged features for time series forecasting</span></a></p>
<div class="sphx-glr-thumbnail-title">Lagged features for time series forecasting</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we will compare the training times and prediction performances of HistGradientBoostingRegressor with different encoding strategies for categorical features. In particular, we will evaluate:"><img alt="" src="../../_images/sphx_glr_plot_gradient_boosting_categorical_thumb.png"/>
<p><a class="reference internal" href="../ensemble/plot_gradient_boosting_categorical.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-categorical-py"><span class="std std-ref">Categorical Feature Support in Gradient Boosting</span></a></p>
<div class="sphx-glr-thumbnail-title">Categorical Feature Support in Gradient Boosting</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates how to approximate a function with polynomials up to degree degree by using ridge regression. We show two different ways given n_samples of 1d points x_i:"><img alt="" src="../../_images/sphx_glr_plot_polynomial_interpolation_thumb.png"/>
<p><a class="reference internal" href="../linear_model/plot_polynomial_interpolation.html#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py"><span class="std std-ref">Polynomial and Spline interpolation</span></a></p>
<div class="sphx-glr-thumbnail-title">Polynomial and Spline interpolation</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Partial dependence plots show the dependence between the target function [2]_ and a set of features of interest, marginalizing over the values of all other features (the complement features). Due to the limits of human perception, the size of the set of features of interest must be small (usually, one or two) thus they are usually chosen among the most important features."><img alt="" src="../../_images/sphx_glr_plot_partial_dependence_thumb.png"/>
<p><a class="reference internal" href="../inspection/plot_partial_dependence.html#sphx-glr-auto-examples-inspection-plot-partial-dependence-py"><span class="std std-ref">Partial Dependence and Individual Conditional Expectation Plots</span></a></p>
<div class="sphx-glr-thumbnail-title">Partial Dependence and Individual Conditional Expectation Plots</div>
</div></div><p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>
</article>
<footer class="bd-footer-article">
<div class="footer-article-items footer-article__inner">
<div class="footer-article-item">
<div class="prev-next-area">
<a class="left-prev" href="plot_species_distribution_modeling.html" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Species distribution modeling</p>
</div>
</a>
<a class="right-next" href="plot_topics_extraction_with_nmf_lda.html" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div></div>
</div>
</footer>
</div>
<div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">
<div class="sidebar-secondary-item">
<div class="page-toc tocsection onthispage" id="pst-page-navigation-heading-2">
<i class="fa-solid fa-list"></i> On this page
  </div>
<nav aria-labelledby="pst-page-navigation-heading-2" class="bd-toc-nav page-toc">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-exploration-on-the-bike-sharing-demand-dataset">Data exploration on the Bike Sharing Demand dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#time-based-cross-validation">Time-based cross-validation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-boosting">Gradient Boosting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-linear-regression">Naive linear regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#time-steps-as-categories">Time-steps as categories</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trigonometric-features">Trigonometric features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#periodic-spline-features">Periodic spline features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#qualitative-analysis-of-the-impact-of-features-on-linear-model-predictions">Qualitative analysis of the impact of features on linear model predictions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modeling-pairwise-interactions-with-splines-and-polynomial-features">Modeling pairwise interactions with splines and polynomial features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modeling-non-linear-feature-interactions-with-kernels">Modeling non-linear feature interactions with kernels</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#concluding-remarks">Concluding remarks</a></li>
</ul>
</nav></div>

<div class="sidebar-secondary-item"><div title="plot_cyclical_feature_engineering.py"><a download="" href="../../_downloads/9fcbbc59ab27a20d07e209a711ac4f50/plot_cyclical_feature_engineering.py"><i class="fa-solid fa-download"></i> Download source code</a></div><div title="plot_cyclical_feature_engineering.ipynb"><a download="" href="../../_downloads/7012baed63b9a27f121bae611b8285c2/plot_cyclical_feature_engineering.ipynb"><i class="fa-solid fa-download"></i> Download Jupyter notebook</a></div></div><div class="sidebar-secondary-item"><div><a href="../../lite/lab/index.html?path=auto_examples/applications/plot_cyclical_feature_engineering.ipynb"><img alt="Launch JupyterLite" height="20" src="../../_images/jupyterlite_badge_logo.svg"/></a></div><div><a href="https://mybinder.org/v2/gh/scikit-learn/scikit-learn/1.5.X?urlpath=lab/tree/notebooks/auto_examples/applications/plot_cyclical_feature_engineering.ipynb"><img alt="Launch binder" height="20" src="../../_images/binder_badge_logo.svg"/></a></div></div></div></div>
</div>
<footer class="bd-footer-content">
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>
<footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
<div class="footer-items__start">
<div class="footer-item">
<p class="copyright">
    
      Â© Copyright 2007 - 2024, scikit-learn developers (BSD License).
      <br/>
</p>
</div>
</div>
</div>
</footer>
</body>
</html>