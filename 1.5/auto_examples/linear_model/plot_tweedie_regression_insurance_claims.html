
<!DOCTYPE html>

<html data-content_root="../../" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="Tweedie regression on insurance claims" property="og:title"/>
<meta content="website" property="og:type"/>
<meta content="https://scikit-learn/stable/auto_examples/linear_model/plot_tweedie_regression_insurance_claims.html" property="og:url"/>
<meta content="scikit-learn" property="og:site_name"/>
<meta content="This example illustrates the use of Poisson, Gamma and Tweedie regression on the French Motor Third-Party Liability Claims dataset, and is inspired by an R tutorial 1. In this dataset, each sample ..." property="og:description"/>
<meta content="https://scikit-learn.org/stable/_static/scikit-learn-logo-small.png" property="og:image"/>
<meta content="scikit-learn" property="og:image:alt"/>
<meta content="This example illustrates the use of Poisson, Gamma and Tweedie regression on the French Motor Third-Party Liability Claims dataset, and is inspired by an R tutorial 1. In this dataset, each sample ..." name="description"/>
<title>Tweedie regression on insurance claims â€” scikit-learn 1.5.2 documentation</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../_static/pygments.css?v=a746c00c" rel="stylesheet" type="text/css"/>
<link href="../../_static/copybutton.css?v=76b2166b" rel="stylesheet" type="text/css"/>
<link href="../../_static/plot_directive.css" rel="stylesheet" type="text/css"/>
<link href="https://fonts.googleapis.com/css?family=Vibur" rel="stylesheet" type="text/css"/>
<link href="../../_static/jupyterlite_sphinx.css?v=ca70e7f1" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery.css?v=d2d258e8" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery-binder.css?v=f4aeca0c" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" rel="stylesheet" type="text/css"/>
<link href="../../_static/sphinx-design.min.css?v=95c83b7e" rel="stylesheet" type="text/css"/>
<link href="../../_static/styles/colors.css?v=cc94ab7d" rel="stylesheet" type="text/css"/>
<link href="../../_static/styles/custom.css?v=e4cb1417" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<link as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/documentation_options.js?v=73275c37"></script>
<script src="../../_static/doctools.js?v=9a2dae69"></script>
<script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
<script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
<script src="../../_static/copybutton.js?v=97f0b27d"></script>
<script src="../../_static/jupyterlite_sphinx.js?v=d6bdf5f8"></script>
<script src="../../_static/design-tabs.js?v=f930bc37"></script>
<script data-domain="scikit-learn.org" defer="defer" src="https://views.scientific-python.org/js/script.js"></script>
<script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'auto_examples/linear_model/plot_tweedie_regression_insurance_claims';</script>
<script>
        DOCUMENTATION_OPTIONS.theme_version = '0.15.4';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://scikit-learn.org/dev/_static/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '1.5.2';
        DOCUMENTATION_OPTIONS.show_version_warning_banner = true;
        </script>
<script src="../../_static/scripts/dropdown.js?v=e2048168"></script>
<script src="../../_static/scripts/version-switcher.js?v=a6dd8357"></script>
<link href="../../_static/favicon.ico" rel="icon"/>
<link href="../../about.html" rel="author" title="About these documents"/>
<link href="../../search.html" rel="search" title="Search"/>
<link href="../inspection/index.html" rel="next" title="Inspection"/>
<link href="plot_theilsen.html" rel="prev" title="Theil-Sen Regression"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
</head>
<body data-bs-root-margin="0px 0px -60%" data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-default-mode="" data-offset="180">
<div class="skip-link d-print-none" id="pst-skip-link"><a href="#main-content">Skip to main content</a></div>
<div id="pst-scroll-pixel-helper"></div>
<button class="btn rounded-pill" id="pst-back-to-top" type="button">
<i class="fa-solid fa-arrow-up"></i>Back to top</button>
<input class="sidebar-toggle" id="pst-primary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
<input class="sidebar-toggle" id="pst-secondary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
</div>
<div class="pst-async-banner-revealer d-none">
<aside aria-label="Version warning" class="d-none d-print-none" id="bd-header-version-warning"></aside>
</div>
<header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
<button aria-label="Site navigation" class="pst-navbar-icon sidebar-toggle primary-toggle">
<span class="fa-solid fa-bars"></span>
</button>
<div class="navbar-header-items__start">
<div class="navbar-item">
<a class="navbar-brand logo" href="../../index.html">
<img alt="scikit-learn homepage" class="logo__image only-light" src="../../_static/scikit-learn-logo-small.png"/>
<script>document.write(`<img src="../../_static/scikit-learn-logo-small.png" class="logo__image only-dark" alt="scikit-learn homepage"/>`);</script>
</a></div>
</div>
<div class="navbar-header-items">
<div class="me-auto navbar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../install.html">
    Install
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../user_guide.html">
    User Guide
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../api/index.html">
    API
  </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../index.html">
    Examples
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-external" href="https://blog.scikit-learn.org/">
    Community
  </a>
</li>
<li class="nav-item dropdown">
<button aria-controls="pst-nav-more-links" aria-expanded="false" class="btn dropdown-toggle nav-item" data-bs-toggle="dropdown" type="button">
                    More
                </button>
<ul class="dropdown-menu" id="pst-nav-more-links">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../getting_started.html">
    Getting Started
  </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../whats_new.html">
    Release History
  </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../glossary.html">
    Glossary
  </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-external" href="https://scikit-learn.org/dev/developers/index.html">
    Development
  </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../faq.html">
    FAQ
  </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../support.html">
    Support
  </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../related_projects.html">
    Related Projects
  </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../roadmap.html">
    Roadmap
  </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../governance.html">
    Governance
  </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../about.html">
    About us
  </a>
</li>
</ul>
</li>
</ul>
</nav></div>
</div>
<div class="navbar-header-items__end">
<div class="navbar-item navbar-persistent--container">
<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
</div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/scikit-learn/scikit-learn" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-square-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
</ul></div>
<div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-2"
      type="button"
      class="version-switcher__button btn btn-sm dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-2"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-2"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-2">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
</div>
</div>
<div class="navbar-persistent--mobile">
<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
</div>
<button aria-label="On this page" class="pst-navbar-icon sidebar-toggle secondary-toggle">
<span class="fa-solid fa-outdent"></span>
</button>
</div>
</header>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../install.html">
    Install
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../user_guide.html">
    User Guide
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../api/index.html">
    API
  </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../index.html">
    Examples
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-external" href="https://blog.scikit-learn.org/">
    Community
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../getting_started.html">
    Getting Started
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../whats_new.html">
    Release History
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../glossary.html">
    Glossary
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-external" href="https://scikit-learn.org/dev/developers/index.html">
    Development
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../faq.html">
    FAQ
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../support.html">
    Support
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../related_projects.html">
    Related Projects
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../roadmap.html">
    Roadmap
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../governance.html">
    Governance
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../about.html">
    About us
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/scikit-learn/scikit-learn" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-square-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
</ul></div>
<div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-3"
      type="button"
      class="version-switcher__button btn btn-sm dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-3"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-3"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-3">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
</div>
</div>
<div class="sidebar-primary-items__start sidebar-primary__section">
<div class="sidebar-primary-item">
<nav aria-label="Section Navigation" class="bd-docs-nav bd-links">
<p aria-level="1" class="bd-links__title" role="heading">Section Navigation</p>
<div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../release_highlights/index.html">Release Highlights</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../release_highlights/plot_release_highlights_1_5_0.html">Release Highlights for scikit-learn 1.5</a></li>
<li class="toctree-l2"><a class="reference internal" href="../release_highlights/plot_release_highlights_1_4_0.html">Release Highlights for scikit-learn 1.4</a></li>
<li class="toctree-l2"><a class="reference internal" href="../release_highlights/plot_release_highlights_1_3_0.html">Release Highlights for scikit-learn 1.3</a></li>
<li class="toctree-l2"><a class="reference internal" href="../release_highlights/plot_release_highlights_1_2_0.html">Release Highlights for scikit-learn 1.2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../release_highlights/plot_release_highlights_1_1_0.html">Release Highlights for scikit-learn 1.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../release_highlights/plot_release_highlights_1_0_0.html">Release Highlights for scikit-learn 1.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../release_highlights/plot_release_highlights_0_24_0.html">Release Highlights for scikit-learn 0.24</a></li>
<li class="toctree-l2"><a class="reference internal" href="../release_highlights/plot_release_highlights_0_23_0.html">Release Highlights for scikit-learn 0.23</a></li>
<li class="toctree-l2"><a class="reference internal" href="../release_highlights/plot_release_highlights_0_22_0.html">Release Highlights for scikit-learn 0.22</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../bicluster/index.html">Biclustering</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../bicluster/plot_spectral_biclustering.html">A demo of the Spectral Biclustering algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bicluster/plot_spectral_coclustering.html">A demo of the Spectral Co-Clustering algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bicluster/plot_bicluster_newsgroups.html">Biclustering documents with the Spectral Co-clustering algorithm</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../calibration/index.html">Calibration</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../calibration/plot_compare_calibration.html">Comparison of Calibration of Classifiers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../calibration/plot_calibration_curve.html">Probability Calibration curves</a></li>
<li class="toctree-l2"><a class="reference internal" href="../calibration/plot_calibration_multiclass.html">Probability Calibration for 3-class classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../calibration/plot_calibration.html">Probability calibration of classifiers</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../classification/index.html">Classification</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../classification/plot_classifier_comparison.html">Classifier comparison</a></li>
<li class="toctree-l2"><a class="reference internal" href="../classification/plot_lda_qda.html">Linear and Quadratic Discriminant Analysis with covariance ellipsoid</a></li>
<li class="toctree-l2"><a class="reference internal" href="../classification/plot_lda.html">Normal, Ledoit-Wolf and OAS Linear Discriminant Analysis for classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../classification/plot_classification_probability.html">Plot classification probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../classification/plot_digits_classification.html">Recognizing hand-written digits</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cluster/index.html">Clustering</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_kmeans_digits.html">A demo of K-Means clustering on the handwritten digits data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_coin_ward_segmentation.html">A demo of structured Ward hierarchical clustering on an image of coins</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_mean_shift.html">A demo of the mean-shift clustering algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_adjusted_for_chance_measures.html">Adjustment for chance in clustering performance evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_agglomerative_clustering.html">Agglomerative clustering with and without structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_agglomerative_clustering_metrics.html">Agglomerative clustering with different metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_kmeans_plusplus.html">An example of K-Means++ initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_bisect_kmeans.html">Bisecting K-Means and Regular K-Means Performance Comparison</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_color_quantization.html">Color Quantization using K-Means</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_birch_vs_minibatchkmeans.html">Compare BIRCH and MiniBatchKMeans</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_cluster_comparison.html">Comparing different clustering algorithms on toy datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_linkage_comparison.html">Comparing different hierarchical linkage methods on toy datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_mini_batch_kmeans.html">Comparison of the K-Means and MiniBatchKMeans clustering algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_dbscan.html">Demo of DBSCAN clustering algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_hdbscan.html">Demo of HDBSCAN clustering algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_optics.html">Demo of OPTICS clustering algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_affinity_propagation.html">Demo of affinity propagation clustering algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_kmeans_assumptions.html">Demonstration of k-means assumptions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_kmeans_stability_low_dim_dense.html">Empirical evaluation of the impact of k-means initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_digits_agglomeration.html">Feature agglomeration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_feature_agglomeration_vs_univariate_selection.html">Feature agglomeration vs. univariate selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_ward_structured_vs_unstructured.html">Hierarchical clustering: structured vs unstructured ward</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_inductive_clustering.html">Inductive Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_cluster_iris.html">K-means Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_dict_face_patches.html">Online learning of a dictionary of parts of faces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_agglomerative_dendrogram.html">Plot Hierarchical Clustering Dendrogram</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_coin_segmentation.html">Segmenting the picture of greek coins in regions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_kmeans_silhouette_analysis.html">Selecting the number of clusters with silhouette analysis on KMeans clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_segmentation_toy.html">Spectral clustering for image segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_digits_linkage.html">Various Agglomerative Clustering on a 2D embedding of digits</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/plot_face_compress.html">Vector Quantization Example</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../covariance/index.html">Covariance estimation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../covariance/plot_lw_vs_oas.html">Ledoit-Wolf vs OAS estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../covariance/plot_mahalanobis_distances.html">Robust covariance estimation and Mahalanobis distances relevance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../covariance/plot_robust_vs_empirical_covariance.html">Robust vs Empirical covariance estimate</a></li>
<li class="toctree-l2"><a class="reference internal" href="../covariance/plot_covariance_estimation.html">Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood</a></li>
<li class="toctree-l2"><a class="reference internal" href="../covariance/plot_sparse_cov.html">Sparse inverse covariance estimation</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cross_decomposition/index.html">Cross decomposition</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../cross_decomposition/plot_compare_cross_decomposition.html">Compare cross decomposition methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cross_decomposition/plot_pcr_vs_pls.html">Principal Component Regression vs Partial Least Squares Regression</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../datasets/index.html">Dataset examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../datasets/plot_random_dataset.html">Plot randomly generated classification dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datasets/plot_random_multilabel_dataset.html">Plot randomly generated multilabel dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datasets/plot_digits_last_image.html">The Digit Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datasets/plot_iris_dataset.html">The Iris Dataset</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tree/index.html">Decision Trees</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../tree/plot_tree_regression.html">Decision Tree Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tree/plot_tree_regression_multioutput.html">Multi-output Decision Tree Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tree/plot_iris_dtc.html">Plot the decision surface of decision trees trained on the iris dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tree/plot_cost_complexity_pruning.html">Post pruning decision trees with cost complexity pruning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tree/plot_unveil_tree_structure.html">Understanding the decision tree structure</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../decomposition/index.html">Decomposition</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../decomposition/plot_ica_blind_source_separation.html">Blind source separation using FastICA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../decomposition/plot_pca_vs_lda.html">Comparison of LDA and PCA 2D projection of Iris dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../decomposition/plot_faces_decomposition.html">Faces dataset decompositions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../decomposition/plot_varimax_fa.html">Factor Analysis (with rotation) to visualize patterns</a></li>
<li class="toctree-l2"><a class="reference internal" href="../decomposition/plot_ica_vs_pca.html">FastICA on 2D point clouds</a></li>
<li class="toctree-l2"><a class="reference internal" href="../decomposition/plot_image_denoising.html">Image denoising using dictionary learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../decomposition/plot_incremental_pca.html">Incremental PCA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../decomposition/plot_kernel_pca.html">Kernel PCA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../decomposition/plot_pca_vs_fa_model_selection.html">Model selection with Probabilistic PCA and Factor Analysis (FA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../decomposition/plot_pca_iris.html">PCA example with Iris Data-set</a></li>
<li class="toctree-l2"><a class="reference internal" href="../decomposition/plot_sparse_coding.html">Sparse coding with a precomputed dictionary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../developing_estimators/index.html">Developing Estimators</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../developing_estimators/sklearn_is_fitted.html"><code class="docutils literal notranslate"><span class="pre">__sklearn_is_fitted__</span></code> as Developer API</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ensemble/index.html">Ensemble methods</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_gradient_boosting_categorical.html">Categorical Feature Support in Gradient Boosting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_stack_predictors.html">Combine predictors using stacking</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_forest_hist_grad_boosting_comparison.html">Comparing Random Forests and Histogram Gradient Boosting models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_random_forest_regression_multioutput.html">Comparing random forests and the multi-output meta estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_adaboost_regression.html">Decision Tree Regression with AdaBoost</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_gradient_boosting_early_stopping.html">Early stopping in Gradient Boosting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_forest_importances.html">Feature importances with a forest of trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_feature_transformation.html">Feature transformations with ensembles of trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_hgbt_regression.html">Features in Histogram Gradient Boosting Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_gradient_boosting_oob.html">Gradient Boosting Out-of-Bag estimates</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_gradient_boosting_regression.html">Gradient Boosting regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_gradient_boosting_regularization.html">Gradient Boosting regularization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_random_forest_embedding.html">Hashing feature transformation using Totally Random Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_isolation_forest.html">IsolationForest example</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_monotonic_constraints.html">Monotonic Constraints</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_adaboost_multiclass.html">Multi-class AdaBoosted Decision Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_ensemble_oob.html">OOB Errors for Random Forests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_forest_importances_faces.html">Pixel importances with a parallel forest of trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_voting_probas.html">Plot class probabilities calculated by the VotingClassifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_voting_regressor.html">Plot individual and voting regression predictions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_voting_decision_regions.html">Plot the decision boundaries of a VotingClassifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_forest_iris.html">Plot the decision surfaces of ensembles of trees on the iris dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_gradient_boosting_quantile.html">Prediction Intervals for Gradient Boosting Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_bias_variance.html">Single estimator versus bagging: bias-variance decomposition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/plot_adaboost_twoclass.html">Two-class AdaBoost</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../applications/index.html">Examples based on real world datasets</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../applications/plot_tomography_l1_reconstruction.html">Compressive sensing: tomography reconstruction with L1 prior (Lasso)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../applications/plot_face_recognition.html">Faces recognition example using eigenfaces and SVMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../applications/plot_digits_denoising.html">Image denoising using kernel PCA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../applications/plot_time_series_lagged_features.html">Lagged features for time series forecasting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../applications/plot_model_complexity_influence.html">Model Complexity Influence</a></li>
<li class="toctree-l2"><a class="reference internal" href="../applications/plot_out_of_core_classification.html">Out-of-core classification of text documents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../applications/plot_outlier_detection_wine.html">Outlier detection on a real data set</a></li>
<li class="toctree-l2"><a class="reference internal" href="../applications/plot_prediction_latency.html">Prediction Latency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../applications/plot_species_distribution_modeling.html">Species distribution modeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../applications/plot_cyclical_feature_engineering.html">Time-related feature engineering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../applications/plot_topics_extraction_with_nmf_lda.html">Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../applications/plot_stock_market.html">Visualizing the stock market structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../applications/wikipedia_principal_eigenvector.html">Wikipedia principal eigenvector</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../feature_selection/index.html">Feature Selection</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../feature_selection/plot_f_test_vs_mi.html">Comparison of F-test and mutual information</a></li>
<li class="toctree-l2"><a class="reference internal" href="../feature_selection/plot_select_from_model_diabetes.html">Model-based and sequential feature selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../feature_selection/plot_feature_selection_pipeline.html">Pipeline ANOVA SVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../feature_selection/plot_rfe_digits.html">Recursive feature elimination</a></li>
<li class="toctree-l2"><a class="reference internal" href="../feature_selection/plot_rfe_with_cross_validation.html">Recursive feature elimination with cross-validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../feature_selection/plot_feature_selection.html">Univariate Feature Selection</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../mixture/index.html">Gaussian Mixture Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../mixture/plot_concentration_prior.html">Concentration Prior Type Analysis of Variation Bayesian Gaussian Mixture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mixture/plot_gmm_pdf.html">Density Estimation for a Gaussian mixture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mixture/plot_gmm_init.html">GMM Initialization Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mixture/plot_gmm_covariances.html">GMM covariances</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mixture/plot_gmm.html">Gaussian Mixture Model Ellipsoids</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mixture/plot_gmm_selection.html">Gaussian Mixture Model Selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mixture/plot_gmm_sin.html">Gaussian Mixture Model Sine Curve</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../gaussian_process/index.html">Gaussian Process for Machine Learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_process/plot_gpr_noisy.html">Ability of Gaussian process regression (GPR) to estimate data noise-level</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_process/plot_compare_gpr_krr.html">Comparison of kernel ridge and Gaussian process regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_process/plot_gpr_co2.html">Forecasting of CO2 level on Mona Loa dataset using Gaussian process regression (GPR)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_process/plot_gpr_noisy_targets.html">Gaussian Processes regression: basic introductory example</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_process/plot_gpc_iris.html">Gaussian process classification (GPC) on iris dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_process/plot_gpr_on_structured_data.html">Gaussian processes on discrete data structures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_process/plot_gpc_xor.html">Illustration of Gaussian process classification (GPC) on the XOR dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_process/plot_gpr_prior_posterior.html">Illustration of prior and posterior Gaussian process for different kernels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_process/plot_gpc_isoprobability.html">Iso-probability lines for Gaussian Processes classification (GPC)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_process/plot_gpc.html">Probabilistic predictions with Gaussian process classification (GPC)</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">Generalized Linear Models</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="plot_ard.html">Comparing Linear Bayesian Regressors</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_sgd_comparison.html">Comparing various online solvers</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_bayesian_ridge_curvefit.html">Curve Fitting with Bayesian Ridge Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_sgd_early_stopping.html">Early stopping of Stochastic Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_elastic_net_precomputed_gram_matrix_with_weighted_samples.html">Fitting an Elastic Net with a precomputed Gram Matrix and Weighted Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_huber_vs_ridge.html">HuberRegressor vs Ridge on dataset with strong outliers</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_multi_task_lasso_support.html">Joint feature selection with multi-task Lasso</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_logistic_l1_l2_sparsity.html">L1 Penalty and Sparsity in Logistic Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_lasso_and_elasticnet.html">L1-based models for Sparse Signals</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_lasso_coordinate_descent_path.html">Lasso and Elastic Net</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_lasso_lars_ic.html">Lasso model selection via information criteria</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_lasso_model_selection.html">Lasso model selection: AIC-BIC / cross-validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_lasso_dense_vs_sparse_data.html">Lasso on dense and sparse data</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_lasso_lars.html">Lasso path using LARS</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_ols.html">Linear Regression Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_iris_logistic.html">Logistic Regression 3-class Classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_logistic.html">Logistic function</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_sparse_logistic_regression_mnist.html">MNIST classification using multinomial logistic + L1</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_sparse_logistic_regression_20newsgroups.html">Multiclass sparse logistic regression on 20newgroups</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_nnls.html">Non-negative least squares</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_sgdocsvm_vs_ocsvm.html">One-Class SVM versus One-Class SVM using Stochastic Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_ols_ridge_variance.html">Ordinary Least Squares and Ridge Regression Variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_omp.html">Orthogonal Matching Pursuit</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_ridge_path.html">Plot Ridge coefficients as a function of the regularization</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_sgd_iris.html">Plot multi-class SGD on the iris dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_logistic_multinomial.html">Plot multinomial and One-vs-Rest Logistic Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_poisson_regression_non_normal_loss.html">Poisson regression and non-normal loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_polynomial_interpolation.html">Polynomial and Spline interpolation</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_quantile_regression.html">Quantile regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_logistic_path.html">Regularization path of L1- Logistic Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_ridge_coeffs.html">Ridge coefficients as a function of the L2 Regularization</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_robust_fit.html">Robust linear estimator fitting</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_ransac.html">Robust linear model estimation using RANSAC</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_sgd_separating_hyperplane.html">SGD: Maximum margin separating hyperplane</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_sgd_penalties.html">SGD: Penalties</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_sgd_weighted_samples.html">SGD: Weighted samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_sgd_loss_functions.html">SGD: convex loss functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_ols_3d.html">Sparsity Example: Fitting only features 1  and 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_theilsen.html">Theil-Sen Regression</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Tweedie regression on insurance claims</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../inspection/index.html">Inspection</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../inspection/plot_linear_model_coefficient_interpretation.html">Common pitfalls in the interpretation of coefficients of linear models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../inspection/plot_causal_interpretation.html">Failure of Machine Learning to infer causal effects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../inspection/plot_partial_dependence.html">Partial Dependence and Individual Conditional Expectation Plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../inspection/plot_permutation_importance.html">Permutation Importance vs Random Forest Feature Importance (MDI)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../inspection/plot_permutation_importance_multicollinear.html">Permutation Importance with Multicollinear or Correlated Features</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../kernel_approximation/index.html">Kernel Approximation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../kernel_approximation/plot_scalable_poly_kernels.html">Scalable learning with polynomial kernel approximation</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../manifold/index.html">Manifold learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../manifold/plot_compare_methods.html">Comparison of Manifold Learning methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../manifold/plot_manifold_sphere.html">Manifold Learning methods on a severed sphere</a></li>
<li class="toctree-l2"><a class="reference internal" href="../manifold/plot_lle_digits.html">Manifold learning on handwritten digits: Locally Linear Embedding, Isomapâ€¦</a></li>
<li class="toctree-l2"><a class="reference internal" href="../manifold/plot_mds.html">Multi-dimensional scaling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../manifold/plot_swissroll.html">Swiss Roll And Swiss-Hole Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../manifold/plot_t_sne_perplexity.html">t-SNE: The effect of various perplexity values on the shape</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../miscellaneous/index.html">Miscellaneous</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_partial_dependence_visualization_api.html">Advanced Plotting With Partial Dependence</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_anomaly_comparison.html">Comparing anomaly detection algorithms for outlier detection on toy datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_kernel_ridge_regression.html">Comparison of kernel ridge regression and SVR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_pipeline_display.html">Displaying Pipelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_estimator_representation.html">Displaying estimators and complex pipelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_outlier_detection_bench.html">Evaluation of outlier detection estimators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_kernel_approximation.html">Explicit feature map approximation for RBF kernels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_multioutput_face_completion.html">Face completion with a multi-output estimators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_set_output.html">Introducing the <code class="docutils literal notranslate"><span class="pre">set_output</span></code> API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_isotonic_regression.html">Isotonic Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_metadata_routing.html">Metadata Routing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_multilabel.html">Multilabel classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_roc_curve_visualization_api.html">ROC Curve with Visualization API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_johnson_lindenstrauss_bound.html">The Johnson-Lindenstrauss bound for embedding with random projections</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous/plot_display_object_visualization.html">Visualizations with Display Objects</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../impute/index.html">Missing Value Imputation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../impute/plot_missing_values.html">Imputing missing values before building an estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../impute/plot_iterative_imputer_variants_comparison.html">Imputing missing values with variants of IterativeImputer</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../model_selection/index.html">Model Selection</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_grid_search_refit_callable.html">Balance model complexity and cross-validated score</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_likelihood_ratios.html">Class Likelihood Ratios to measure classification performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_randomized_search.html">Comparing randomized search and grid search for hyperparameter estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_successive_halving_heatmap.html">Comparison between grid search and successive halving</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_confusion_matrix.html">Confusion matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_grid_search_digits.html">Custom refit strategy of a grid search with cross-validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_multi_metric_evaluation.html">Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_det.html">Detection error tradeoff (DET) curve</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_roc.html">Multiclass Receiver Operating Characteristic (ROC)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_nested_cross_validation_iris.html">Nested versus non-nested cross-validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_cv_predict.html">Plotting Cross-Validated Predictions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_learning_curve.html">Plotting Learning Curves and Checking Modelsâ€™ Scalability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_validation_curve.html">Plotting Validation Curves</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_tuned_decision_threshold.html">Post-hoc tuning the cut-off point of decision function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_cost_sensitive_learning.html">Post-tuning the decision threshold for cost-sensitive learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_precision_recall.html">Precision-Recall</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_roc_crossval.html">Receiver Operating Characteristic (ROC) with cross validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_grid_search_text_feature_extraction.html">Sample pipeline for text feature extraction and evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_grid_search_stats.html">Statistical comparison of models using grid search</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_successive_halving_iterations.html">Successive Halving Iterations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_permutation_tests_for_classification.html">Test with permutations the significance of a classification score</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_train_error_vs_test_error.html">Train error vs Test error</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_underfitting_overfitting.html">Underfitting vs. Overfitting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_selection/plot_cv_indices.html">Visualizing cross-validation behavior in scikit-learn</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../multiclass/index.html">Multiclass methods</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../multiclass/plot_multiclass_overview.html">Overview of multiclass training meta-estimators</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../multioutput/index.html">Multioutput methods</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../multioutput/plot_classifier_chain_yeast.html">Multilabel classification using a classifier chain</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../neighbors/index.html">Nearest Neighbors</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/approximate_nearest_neighbors.html">Approximate nearest neighbors in TSNE</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/plot_caching_nearest_neighbors.html">Caching nearest neighbors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/plot_nca_classification.html">Comparing Nearest Neighbors with and without Neighborhood Components Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/plot_nca_dim_reduction.html">Dimensionality Reduction with Neighborhood Components Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/plot_species_kde.html">Kernel Density Estimate of Species Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/plot_digits_kde_sampling.html">Kernel Density Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/plot_nearest_centroid.html">Nearest Centroid Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/plot_classification.html">Nearest Neighbors Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/plot_regression.html">Nearest Neighbors regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/plot_nca_illustration.html">Neighborhood Components Analysis Illustration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/plot_lof_novelty_detection.html">Novelty detection with Local Outlier Factor (LOF)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/plot_lof_outlier_detection.html">Outlier detection with Local Outlier Factor (LOF)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neighbors/plot_kde_1d.html">Simple 1D Kernel Density Estimation</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../neural_networks/index.html">Neural Networks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../neural_networks/plot_mlp_training_curves.html">Compare Stochastic learning strategies for MLPClassifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neural_networks/plot_rbm_logistic_classification.html">Restricted Boltzmann Machine features for digit classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neural_networks/plot_mlp_alpha.html">Varying regularization in Multi-layer Perceptron</a></li>
<li class="toctree-l2"><a class="reference internal" href="../neural_networks/plot_mnist_filters.html">Visualization of MLP weights on MNIST</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../compose/index.html">Pipelines and composite estimators</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../compose/plot_column_transformer.html">Column Transformer with Heterogeneous Data Sources</a></li>
<li class="toctree-l2"><a class="reference internal" href="../compose/plot_column_transformer_mixed_types.html">Column Transformer with Mixed Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../compose/plot_feature_union.html">Concatenating multiple feature extraction methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../compose/plot_transformed_target.html">Effect of transforming the targets in regression model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../compose/plot_digits_pipe.html">Pipelining: chaining a PCA and a logistic regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../compose/plot_compare_reduction.html">Selecting dimensionality reduction with Pipeline and GridSearchCV</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../preprocessing/index.html">Preprocessing</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../preprocessing/plot_all_scaling.html">Compare the effect of different scalers on data with outliers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preprocessing/plot_target_encoder.html">Comparing Target Encoder with Other Encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preprocessing/plot_discretization_strategies.html">Demonstrating the different strategies of KBinsDiscretizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preprocessing/plot_discretization_classification.html">Feature discretization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preprocessing/plot_scaling_importance.html">Importance of Feature Scaling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preprocessing/plot_map_data_to_normal.html">Map data to a normal distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preprocessing/plot_target_encoder_cross_val.html">Target Encoderâ€™s Internal Cross fitting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preprocessing/plot_discretization.html">Using KBinsDiscretizer to discretize continuous features</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../semi_supervised/index.html">Semi Supervised Classification</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../semi_supervised/plot_semi_supervised_versus_svm_iris.html">Decision boundary of semi-supervised classifiers versus SVM on the Iris dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../semi_supervised/plot_self_training_varying_threshold.html">Effect of varying threshold for self-training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../semi_supervised/plot_label_propagation_digits_active_learning.html">Label Propagation digits active learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../semi_supervised/plot_label_propagation_digits.html">Label Propagation digits: Demonstrating performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../semi_supervised/plot_label_propagation_structure.html">Label Propagation learning a complex structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../semi_supervised/plot_semi_supervised_newsgroups.html">Semi-supervised Classification on a Text Dataset</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../svm/index.html">Support Vector Machines</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_oneclass.html">One-class SVM with non-linear kernel (RBF)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_svm_kernels.html">Plot classification boundaries with different SVM Kernels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_iris_svc.html">Plot different SVM classifiers in the iris dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_linearsvc_support_vectors.html">Plot the support vectors in LinearSVC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_rbf_parameters.html">RBF SVM parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_svm_margin.html">SVM Margins Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_svm_tie_breaking.html">SVM Tie Breaking Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_custom_kernel.html">SVM with custom kernel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_svm_anova.html">SVM-Anova: SVM with univariate feature selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_separating_hyperplane.html">SVM: Maximum margin separating hyperplane</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_separating_hyperplane_unbalanced.html">SVM: Separating hyperplane for unbalanced classes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_weighted_samples.html">SVM: Weighted samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_svm_scale_c.html">Scaling the regularization parameter for SVCs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../svm/plot_svm_regression.html">Support Vector Regression (SVR) using linear and non-linear kernels</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../exercises/index.html">Tutorial exercises</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../exercises/plot_cv_diabetes.html">Cross-validation on diabetes Dataset Exercise</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/plot_digits_classification_exercise.html">Digits Classification Exercise</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/plot_iris_exercise.html">SVM Exercise</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../text/index.html">Working with text documents</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../text/plot_document_classification_20newsgroups.html">Classification of text documents using sparse features</a></li>
<li class="toctree-l2"><a class="reference internal" href="../text/plot_document_clustering.html">Clustering text documents using k-means</a></li>
<li class="toctree-l2"><a class="reference internal" href="../text/plot_hashing_vs_dict_vectorizer.html">FeatureHasher and DictVectorizer Comparison</a></li>
</ul>
</details></li>
</ul>
</div>
</nav></div>
</div>
<div class="sidebar-primary-items__end sidebar-primary__section">
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content" role="main">
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
<div class="header-article-items__start">
<div class="header-article-item">
<nav aria-label="Breadcrumb" class="d-print-none">
<ul class="bd-breadcrumbs">
<li class="breadcrumb-item breadcrumb-home">
<a aria-label="Home" class="nav-link" href="../../index.html">
<i class="fa-solid fa-home"></i>
</a>
</li>
<li class="breadcrumb-item"><a class="nav-link" href="../index.html">Examples</a></li>
<li class="breadcrumb-item"><a class="nav-link" href="index.html">Generalized Linear Models</a></li>
<li aria-current="page" class="breadcrumb-item active">Tweedie...</li>
</ul>
</nav>
</div>
</div>
</div>
</div>
<div id="searchbox"></div>
<article class="bd-article">

<section class="sphx-glr-example-title" id="tweedie-regression-on-insurance-claims">
<span id="sphx-glr-auto-examples-linear-model-plot-tweedie-regression-insurance-claims-py"></span><h1>Tweedie regression on insurance claims<a class="headerlink" href="#tweedie-regression-on-insurance-claims" title="Link to this heading">#</a></h1>
<p>This example illustrates the use of Poisson, Gamma and Tweedie regression on
the <a class="reference external" href="https://www.openml.org/d/41214">French Motor Third-Party Liability Claims dataset</a>, and is inspired by an R tutorial <a class="footnote-reference brackets" href="#id2" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>.</p>
<p>In this dataset, each sample corresponds to an insurance policy, i.e. a
contract within an insurance company and an individual (policyholder).
Available features include driver age, vehicle age, vehicle power, etc.</p>
<p>A few definitions: a <em>claim</em> is the request made by a policyholder to the
insurer to compensate for a loss covered by the insurance. The <em>claim amount</em>
is the amount of money that the insurer must pay. The <em>exposure</em> is the
duration of the insurance coverage of a given policy, in years.</p>
<p>Here our goal is to predict the expected
value, i.e. the mean, of the total claim amount per exposure unit also
referred to as the pure premium.</p>
<p>There are several possibilities to do that, two of which are:</p>
<ol class="arabic simple">
<li><p>Model the number of claims with a Poisson distribution, and the average
claim amount per claim, also known as severity, as a Gamma distribution
and multiply the predictions of both in order to get the total claim
amount.</p></li>
<li><p>Model the total claim amount per exposure directly, typically with a Tweedie
distribution of Tweedie power <span class="math notranslate nohighlight">\(p \in (1, 2)\)</span>.</p></li>
</ol>
<p>In this example we will illustrate both approaches. We start by defining a few
helper functions for loading the data and visualizing results.</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id2" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a href="#id1" role="doc-backlink">1</a><span class="fn-bracket">]</span></span>
<p>A. Noll, R. Salzmann and M.V. Wuthrich, Case Study: French Motor
Third-Party Liability Claims (November 8, 2018). <a class="reference external" href="https://doi.org/10.2139/ssrn.3164764">doi:10.2139/ssrn.3164764</a></p>
</aside>
</aside>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <a class="sphx-glr-backref-module-functools sphx-glr-backref-type-py-function" href="https://docs.python.org/3/library/functools.html#functools.partial" title="functools.partial"><span class="n">partial</span></a>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <a class="sphx-glr-backref-module-sklearn-datasets sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.datasets.fetch_openml.html#sklearn.datasets.fetch_openml" title="sklearn.datasets.fetch_openml"><span class="n">fetch_openml</span></a>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="p">(</span>
    <a class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error" title="sklearn.metrics.mean_absolute_error"><span class="n">mean_absolute_error</span></a><span class="p">,</span>
    <a class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error" title="sklearn.metrics.mean_squared_error"><span class="n">mean_squared_error</span></a><span class="p">,</span>
    <a class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.metrics.mean_tweedie_deviance.html#sklearn.metrics.mean_tweedie_deviance" title="sklearn.metrics.mean_tweedie_deviance"><span class="n">mean_tweedie_deviance</span></a><span class="p">,</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">load_mtpl2</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Fetch the French Motor Third-Party Liability Claims dataset.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_samples: int, default=None</span>
<span class="sd">      number of samples to select (for faster run time). Full dataset has</span>
<span class="sd">      678013 samples.</span>
<span class="sd">    """</span>
    <span class="c1"># freMTPL2freq dataset from https://www.openml.org/d/41214</span>
    <span class="n">df_freq</span> <span class="o">=</span> <a class="sphx-glr-backref-module-sklearn-datasets sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.datasets.fetch_openml.html#sklearn.datasets.fetch_openml" title="sklearn.datasets.fetch_openml"><span class="n">fetch_openml</span></a><span class="p">(</span><span class="n">data_id</span><span class="o">=</span><span class="mi">41214</span><span class="p">,</span> <span class="n">as_frame</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">data</span>
    <span class="n">df_freq</span><span class="p">[</span><span class="s2">"IDpol"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_freq</span><span class="p">[</span><span class="s2">"IDpol"</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">df_freq</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">"IDpol"</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># freMTPL2sev dataset from https://www.openml.org/d/41215</span>
    <span class="n">df_sev</span> <span class="o">=</span> <a class="sphx-glr-backref-module-sklearn-datasets sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.datasets.fetch_openml.html#sklearn.datasets.fetch_openml" title="sklearn.datasets.fetch_openml"><span class="n">fetch_openml</span></a><span class="p">(</span><span class="n">data_id</span><span class="o">=</span><span class="mi">41215</span><span class="p">,</span> <span class="n">as_frame</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">data</span>

    <span class="c1"># sum ClaimAmount over identical IDs</span>
    <span class="n">df_sev</span> <span class="o">=</span> <span class="n">df_sev</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">"IDpol"</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="n">df</span> <span class="o">=</span> <span class="n">df_freq</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df_sev</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s2">"left"</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s2">"ClaimAmount"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">"ClaimAmount"</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># unquote string fields</span>
    <span class="k">for</span> <span class="n">column_name</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[[</span><span class="n">t</span> <span class="ow">is</span> <span class="nb">object</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">values</span><span class="p">]]:</span>
        <span class="n">df</span><span class="p">[</span><span class="n">column_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">column_name</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s2">"'"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">plot_obs_pred</span><span class="p">(</span>
    <span class="n">df</span><span class="p">,</span>
    <span class="n">feature</span><span class="p">,</span>
    <span class="n">weight</span><span class="p">,</span>
    <span class="n">observed</span><span class="p">,</span>
    <span class="n">predicted</span><span class="p">,</span>
    <span class="n">y_label</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">fill_legend</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""Plot observed and predicted - aggregated per feature level.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    df : DataFrame</span>
<span class="sd">        input data</span>
<span class="sd">    feature: str</span>
<span class="sd">        a column name of df for the feature to be plotted</span>
<span class="sd">    weight : str</span>
<span class="sd">        column name of df with the values of weights or exposure</span>
<span class="sd">    observed : str</span>
<span class="sd">        a column name of df with the observed target</span>
<span class="sd">    predicted : DataFrame</span>
<span class="sd">        a dataframe, with the same index as df, with the predicted target</span>
<span class="sd">    fill_legend : bool, default=False</span>
<span class="sd">        whether to show fill_between legend</span>
<span class="sd">    """</span>
    <span class="c1"># aggregate observed and predicted variables by feature level</span>
    <span class="n">df_</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="n">feature</span><span class="p">,</span> <span class="n">weight</span><span class="p">]]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">df_</span><span class="p">[</span><span class="s2">"observed"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">observed</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="n">weight</span><span class="p">]</span>
    <span class="n">df_</span><span class="p">[</span><span class="s2">"predicted"</span><span class="p">]</span> <span class="o">=</span> <span class="n">predicted</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="n">weight</span><span class="p">]</span>
    <span class="n">df_</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">df_</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="n">feature</span><span class="p">])[[</span><span class="n">weight</span><span class="p">,</span> <span class="s2">"observed"</span><span class="p">,</span> <span class="s2">"predicted"</span><span class="p">]]</span>
        <span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">observed</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">"observed"</span><span class="p">]</span> <span class="o">/</span> <span class="n">x</span><span class="p">[</span><span class="n">weight</span><span class="p">])</span>
        <span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">predicted</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">"predicted"</span><span class="p">]</span> <span class="o">/</span> <span class="n">x</span><span class="p">[</span><span class="n">weight</span><span class="p">])</span>
    <span class="p">)</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">df_</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">"observed"</span><span class="p">,</span> <span class="s2">"predicted"</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">"."</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">y_max</span> <span class="o">=</span> <span class="n">df_</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">"observed"</span><span class="p">,</span> <span class="s2">"predicted"</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">*</span> <span class="mf">0.8</span>
    <span class="n">p2</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
        <span class="n">df_</span><span class="o">.</span><span class="n">index</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="n">y_max</span> <span class="o">*</span> <span class="n">df_</span><span class="p">[</span><span class="n">weight</span><span class="p">]</span> <span class="o">/</span> <span class="n">df_</span><span class="p">[</span><span class="n">weight</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span>
        <span class="n">color</span><span class="o">=</span><span class="s2">"g"</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">fill_legend</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="n">p2</span><span class="p">],</span> <span class="p">[</span><span class="s2">"</span><span class="si">{}</span><span class="s2"> distribution"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">feature</span><span class="p">)])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
        <span class="n">ylabel</span><span class="o">=</span><span class="n">y_label</span> <span class="k">if</span> <span class="n">y_label</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="n">title</span> <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">"Train: Observed vs Predicted"</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">score_estimator</span><span class="p">(</span>
    <span class="n">estimator</span><span class="p">,</span>
    <span class="n">X_train</span><span class="p">,</span>
    <span class="n">X_test</span><span class="p">,</span>
    <span class="n">df_train</span><span class="p">,</span>
    <span class="n">df_test</span><span class="p">,</span>
    <span class="n">target</span><span class="p">,</span>
    <span class="n">weights</span><span class="p">,</span>
    <span class="n">tweedie_powers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""Evaluate an estimator on train and test sets with different metrics"""</span>

    <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s2">"DÂ² explained"</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>  <span class="c1"># Use default scorer if it exists</span>
        <span class="p">(</span><span class="s2">"mean abs. error"</span><span class="p">,</span> <a class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error" title="sklearn.metrics.mean_absolute_error"><span class="n">mean_absolute_error</span></a><span class="p">),</span>
        <span class="p">(</span><span class="s2">"mean squared error"</span><span class="p">,</span> <a class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error" title="sklearn.metrics.mean_squared_error"><span class="n">mean_squared_error</span></a><span class="p">),</span>
    <span class="p">]</span>
    <span class="k">if</span> <span class="n">tweedie_powers</span><span class="p">:</span>
        <span class="n">metrics</span> <span class="o">+=</span> <span class="p">[</span>
            <span class="p">(</span>
                <span class="s2">"mean Tweedie dev p=</span><span class="si">{:.4f}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">power</span><span class="p">),</span>
                <a class="sphx-glr-backref-module-functools sphx-glr-backref-type-py-function" href="https://docs.python.org/3/library/functools.html#functools.partial" title="functools.partial"><span class="n">partial</span></a><span class="p">(</span><a class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.metrics.mean_tweedie_deviance.html#sklearn.metrics.mean_tweedie_deviance" title="sklearn.metrics.mean_tweedie_deviance"><span class="n">mean_tweedie_deviance</span></a><span class="p">,</span> <span class="n">power</span><span class="o">=</span><span class="n">power</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">power</span> <span class="ow">in</span> <span class="n">tweedie_powers</span>
        <span class="p">]</span>

    <span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">subset_label</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">df</span> <span class="ow">in</span> <span class="p">[</span>
        <span class="p">(</span><span class="s2">"train"</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">df_train</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">"test"</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">df_test</span><span class="p">),</span>
    <span class="p">]:</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">_weights</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">target</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="n">weights</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">score_label</span><span class="p">,</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">metrics</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">estimator</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="c1"># Score the model consisting of the product of frequency and</span>
                <span class="c1"># severity models.</span>
                <span class="n">est_freq</span><span class="p">,</span> <span class="n">est_sev</span> <span class="o">=</span> <span class="n">estimator</span>
                <span class="n">y_pred</span> <span class="o">=</span> <span class="n">est_freq</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">est_sev</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">y_pred</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">metric</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="s2">"score"</span><span class="p">):</span>
                    <span class="k">continue</span>
                <span class="n">score</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">_weights</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">score</span> <span class="o">=</span> <span class="n">metric</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">_weights</span><span class="p">)</span>

            <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">"subset"</span><span class="p">:</span> <span class="n">subset_label</span><span class="p">,</span> <span class="s2">"metric"</span><span class="p">:</span> <span class="n">score_label</span><span class="p">,</span> <span class="s2">"score"</span><span class="p">:</span> <span class="n">score</span><span class="p">})</span>

    <span class="n">res</span> <span class="o">=</span> <span class="p">(</span>
        <a class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><span class="n">res</span><span class="p">)</span>
        <span class="o">.</span><span class="n">set_index</span><span class="p">([</span><span class="s2">"metric"</span><span class="p">,</span> <span class="s2">"subset"</span><span class="p">])</span>
        <span class="o">.</span><span class="n">score</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
        <span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">"train"</span><span class="p">,</span> <span class="s2">"test"</span><span class="p">]]</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
<section id="loading-datasets-basic-feature-extraction-and-target-definitions">
<h2>Loading datasets, basic feature extraction and target definitions<a class="headerlink" href="#loading-datasets-basic-feature-extraction-and-target-definitions" title="Link to this heading">#</a></h2>
<p>We construct the freMTPL2 dataset by joining the freMTPL2freq table,
containing the number of claims (<code class="docutils literal notranslate"><span class="pre">ClaimNb</span></code>), with the freMTPL2sev table,
containing the claim amount (<code class="docutils literal notranslate"><span class="pre">ClaimAmount</span></code>) for the same policy ids
(<code class="docutils literal notranslate"><span class="pre">IDpol</span></code>).</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <a class="sphx-glr-backref-module-sklearn-compose sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer" title="sklearn.compose.ColumnTransformer"><span class="n">ColumnTransformer</span></a>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <a class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="sklearn.pipeline.make_pipeline"><span class="n">make_pipeline</span></a>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="p">(</span>
    <a class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.preprocessing.FunctionTransformer.html#sklearn.preprocessing.FunctionTransformer" title="sklearn.preprocessing.FunctionTransformer"><span class="n">FunctionTransformer</span></a><span class="p">,</span>
    <a class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.preprocessing.KBinsDiscretizer.html#sklearn.preprocessing.KBinsDiscretizer" title="sklearn.preprocessing.KBinsDiscretizer"><span class="n">KBinsDiscretizer</span></a><span class="p">,</span>
    <a class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder" title="sklearn.preprocessing.OneHotEncoder"><span class="n">OneHotEncoder</span></a><span class="p">,</span>
    <a class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler"><span class="n">StandardScaler</span></a><span class="p">,</span>
<span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">load_mtpl2</span><span class="p">()</span>


<span class="c1"># Correct for unreasonable observations (that might be data error)</span>
<span class="c1"># and a few exceptionally large claim amounts</span>
<span class="n">df</span><span class="p">[</span><span class="s2">"ClaimNb"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">"ClaimNb"</span><span class="p">]</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">upper</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">"Exposure"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">"Exposure"</span><span class="p">]</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">upper</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">"ClaimAmount"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">"ClaimAmount"</span><span class="p">]</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">upper</span><span class="o">=</span><span class="mi">200000</span><span class="p">)</span>
<span class="c1"># If the claim amount is 0, then we do not count it as a claim. The loss function</span>
<span class="c1"># used by the severity model needs strictly positive claim amounts. This way</span>
<span class="c1"># frequency and severity are more consistent with each other.</span>
<span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s2">"ClaimAmount"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"ClaimNb"</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">"ClaimNb"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">log_scale_transformer</span> <span class="o">=</span> <a class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="sklearn.pipeline.make_pipeline"><span class="n">make_pipeline</span></a><span class="p">(</span>
    <a class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.preprocessing.FunctionTransformer.html#sklearn.preprocessing.FunctionTransformer" title="sklearn.preprocessing.FunctionTransformer"><span class="n">FunctionTransformer</span></a><span class="p">(</span><span class="n">func</span><span class="o">=</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-data" href="https://numpy.org/doc/stable/reference/generated/numpy.log.html#numpy.log" title="numpy.log"><span class="n">np</span><span class="o">.</span><span class="n">log</span></a><span class="p">),</span> <a class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler"><span class="n">StandardScaler</span></a><span class="p">()</span>
<span class="p">)</span>

<span class="n">column_trans</span> <span class="o">=</span> <a class="sphx-glr-backref-module-sklearn-compose sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer" title="sklearn.compose.ColumnTransformer"><span class="n">ColumnTransformer</span></a><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">(</span>
            <span class="s2">"binned_numeric"</span><span class="p">,</span>
            <a class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.preprocessing.KBinsDiscretizer.html#sklearn.preprocessing.KBinsDiscretizer" title="sklearn.preprocessing.KBinsDiscretizer"><span class="n">KBinsDiscretizer</span></a><span class="p">(</span><span class="n">n_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
            <span class="p">[</span><span class="s2">"VehAge"</span><span class="p">,</span> <span class="s2">"DrivAge"</span><span class="p">],</span>
        <span class="p">),</span>
        <span class="p">(</span>
            <span class="s2">"onehot_categorical"</span><span class="p">,</span>
            <a class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder" title="sklearn.preprocessing.OneHotEncoder"><span class="n">OneHotEncoder</span></a><span class="p">(),</span>
            <span class="p">[</span><span class="s2">"VehBrand"</span><span class="p">,</span> <span class="s2">"VehPower"</span><span class="p">,</span> <span class="s2">"VehGas"</span><span class="p">,</span> <span class="s2">"Region"</span><span class="p">,</span> <span class="s2">"Area"</span><span class="p">],</span>
        <span class="p">),</span>
        <span class="p">(</span><span class="s2">"passthrough_numeric"</span><span class="p">,</span> <span class="s2">"passthrough"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"BonusMalus"</span><span class="p">]),</span>
        <span class="p">(</span><span class="s2">"log_scaled_numeric"</span><span class="p">,</span> <span class="n">log_scale_transformer</span><span class="p">,</span> <span class="p">[</span><span class="s2">"Density"</span><span class="p">]),</span>
    <span class="p">],</span>
    <span class="n">remainder</span><span class="o">=</span><span class="s2">"drop"</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">column_trans</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1"># Insurances companies are interested in modeling the Pure Premium, that is</span>
<span class="c1"># the expected total claim amount per unit of exposure for each policyholder</span>
<span class="c1"># in their portfolio:</span>
<span class="n">df</span><span class="p">[</span><span class="s2">"PurePremium"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">"ClaimAmount"</span><span class="p">]</span> <span class="o">/</span> <span class="n">df</span><span class="p">[</span><span class="s2">"Exposure"</span><span class="p">]</span>

<span class="c1"># This can be indirectly approximated by a 2-step modeling: the product of the</span>
<span class="c1"># Frequency times the average claim amount per claim:</span>
<span class="n">df</span><span class="p">[</span><span class="s2">"Frequency"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">"ClaimNb"</span><span class="p">]</span> <span class="o">/</span> <span class="n">df</span><span class="p">[</span><span class="s2">"Exposure"</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="s2">"AvgClaimAmount"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">"ClaimAmount"</span><span class="p">]</span> <span class="o">/</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-data" href="https://numpy.org/doc/stable/reference/generated/numpy.fmax.html#numpy.fmax" title="numpy.fmax"><span class="n">np</span><span class="o">.</span><span class="n">fmax</span></a><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"ClaimNb"</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">with</span> <a class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.option_context.html#pandas.option_context" title="pandas.option_context"><span class="n">pd</span><span class="o">.</span><span class="n">option_context</span></a><span class="p">(</span><span class="s2">"display.max_columns"</span><span class="p">,</span> <span class="mi">15</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">ClaimAmount</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       ClaimNb  Exposure Area  VehPower  VehAge  DrivAge  BonusMalus VehBrand  \
IDpol
139          1      0.75    F         7       1       61          50      B12
190          1      0.14    B        12       5       50          60      B12
414          1      0.14    E         4       0       36          85      B12
424          2      0.62    F        10       0       51         100      B12
463          1      0.31    A         5       0       45          50      B12

          VehGas  Density Region  ClaimAmount   PurePremium  Frequency  \
IDpol
139    'Regular'    27000    R11       303.00    404.000000   1.333333
190     'Diesel'       56    R25      1981.84  14156.000000   7.142857
414    'Regular'     4792    R11      1456.55  10403.928571   7.142857
424    'Regular'    27000    R11     10834.00  17474.193548   3.225806
463    'Regular'       12    R73      3986.67  12860.225806   3.225806

       AvgClaimAmount
IDpol
139            303.00
190           1981.84
414           1456.55
424           5417.00
463           3986.67
</pre></div>
</div>
</section>
<section id="frequency-model-poisson-distribution">
<h2>Frequency model â€“ Poisson distribution<a class="headerlink" href="#frequency-model-poisson-distribution" title="Link to this heading">#</a></h2>
<p>The number of claims (<code class="docutils literal notranslate"><span class="pre">ClaimNb</span></code>) is a positive integer (0 included).
Thus, this target can be modelled by a Poisson distribution.
It is then assumed to be the number of discrete events occurring with a
constant rate in a given time interval (<code class="docutils literal notranslate"><span class="pre">Exposure</span></code>, in units of years).
Here we model the frequency <code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">ClaimNb</span> <span class="pre">/</span> <span class="pre">Exposure</span></code>, which is still a
(scaled) Poisson distribution, and use <code class="docutils literal notranslate"><span class="pre">Exposure</span></code> as <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <a class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.linear_model.PoissonRegressor.html#sklearn.linear_model.PoissonRegressor" title="sklearn.linear_model.PoissonRegressor"><span class="n">PoissonRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <a class="sphx-glr-backref-module-sklearn-model_selection sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split" title="sklearn.model_selection.train_test_split"><span class="n">train_test_split</span></a>

<span class="n">df_train</span><span class="p">,</span> <span class="n">df_test</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <a class="sphx-glr-backref-module-sklearn-model_selection sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split" title="sklearn.model_selection.train_test_split"><span class="n">train_test_split</span></a><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>Let us keep in mind that despite the seemingly large number of data points in
this dataset, the number of evaluation points where the claim amount is
non-zero is quite small:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">df_test</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>169504
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">df_test</span><span class="p">[</span><span class="n">df_test</span><span class="p">[</span><span class="s2">"ClaimAmount"</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>6237
</pre></div>
</div>
<p>As a consequence, we expect a significant variability in our
evaluation upon random resampling of the train test split.</p>
<p>The parameters of the model are estimated by minimizing the Poisson deviance
on the training set via a Newton solver. Some of the features are collinear
(e.g. because we did not drop any categorical level in the <code class="docutils literal notranslate"><span class="pre">OneHotEncoder</span></code>),
we use a weak L2 penalization to avoid numerical issues.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">glm_freq</span> <span class="o">=</span> <a class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.linear_model.PoissonRegressor.html#sklearn.linear_model.PoissonRegressor" title="sklearn.linear_model.PoissonRegressor"><span class="n">PoissonRegressor</span></a><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">"newton-cholesky"</span><span class="p">)</span>
<span class="n">glm_freq</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">"Frequency"</span><span class="p">],</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">df_train</span><span class="p">[</span><span class="s2">"Exposure"</span><span class="p">])</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">score_estimator</span><span class="p">(</span>
    <span class="n">glm_freq</span><span class="p">,</span>
    <span class="n">X_train</span><span class="p">,</span>
    <span class="n">X_test</span><span class="p">,</span>
    <span class="n">df_train</span><span class="p">,</span>
    <span class="n">df_test</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">"Frequency"</span><span class="p">,</span>
    <span class="n">weights</span><span class="o">=</span><span class="s2">"Exposure"</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Evaluation of PoissonRegressor on target Frequency"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Evaluation of PoissonRegressor on target Frequency
subset               train    test
metric
DÂ² explained        0.0448  0.0427
mean abs. error     0.1379  0.1378
mean squared error  0.2441  0.2246
</pre></div>
</div>
<p>Note that the score measured on the test set is surprisingly better than on
the training set. This might be specific to this random train-test split.
Proper cross-validation could help us to assess the sampling variability of
these results.</p>
<p>We can visually compare observed and predicted values, aggregated by the
drivers age (<code class="docutils literal notranslate"><span class="pre">DrivAge</span></code>), vehicle age (<code class="docutils literal notranslate"><span class="pre">VehAge</span></code>) and the insurance
bonus/malus (<code class="docutils literal notranslate"><span class="pre">BonusMalus</span></code>).</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">plot_obs_pred</span><span class="p">(</span>
    <span class="n">df</span><span class="o">=</span><span class="n">df_train</span><span class="p">,</span>
    <span class="n">feature</span><span class="o">=</span><span class="s2">"DrivAge"</span><span class="p">,</span>
    <span class="n">weight</span><span class="o">=</span><span class="s2">"Exposure"</span><span class="p">,</span>
    <span class="n">observed</span><span class="o">=</span><span class="s2">"Frequency"</span><span class="p">,</span>
    <span class="n">predicted</span><span class="o">=</span><span class="n">glm_freq</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span>
    <span class="n">y_label</span><span class="o">=</span><span class="s2">"Claim Frequency"</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"train data"</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">plot_obs_pred</span><span class="p">(</span>
    <span class="n">df</span><span class="o">=</span><span class="n">df_test</span><span class="p">,</span>
    <span class="n">feature</span><span class="o">=</span><span class="s2">"DrivAge"</span><span class="p">,</span>
    <span class="n">weight</span><span class="o">=</span><span class="s2">"Exposure"</span><span class="p">,</span>
    <span class="n">observed</span><span class="o">=</span><span class="s2">"Frequency"</span><span class="p">,</span>
    <span class="n">predicted</span><span class="o">=</span><span class="n">glm_freq</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span>
    <span class="n">y_label</span><span class="o">=</span><span class="s2">"Claim Frequency"</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"test data"</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">fill_legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">plot_obs_pred</span><span class="p">(</span>
    <span class="n">df</span><span class="o">=</span><span class="n">df_test</span><span class="p">,</span>
    <span class="n">feature</span><span class="o">=</span><span class="s2">"VehAge"</span><span class="p">,</span>
    <span class="n">weight</span><span class="o">=</span><span class="s2">"Exposure"</span><span class="p">,</span>
    <span class="n">observed</span><span class="o">=</span><span class="s2">"Frequency"</span><span class="p">,</span>
    <span class="n">predicted</span><span class="o">=</span><span class="n">glm_freq</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span>
    <span class="n">y_label</span><span class="o">=</span><span class="s2">"Claim Frequency"</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"test data"</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="n">fill_legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">plot_obs_pred</span><span class="p">(</span>
    <span class="n">df</span><span class="o">=</span><span class="n">df_test</span><span class="p">,</span>
    <span class="n">feature</span><span class="o">=</span><span class="s2">"BonusMalus"</span><span class="p">,</span>
    <span class="n">weight</span><span class="o">=</span><span class="s2">"Exposure"</span><span class="p">,</span>
    <span class="n">observed</span><span class="o">=</span><span class="s2">"Frequency"</span><span class="p">,</span>
    <span class="n">predicted</span><span class="o">=</span><span class="n">glm_freq</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span>
    <span class="n">y_label</span><span class="o">=</span><span class="s2">"Claim Frequency"</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"test data"</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">fill_legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<img alt="train data, test data, test data, test data" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_tweedie_regression_insurance_claims_001.png" srcset="../../_images/sphx_glr_plot_tweedie_regression_insurance_claims_001.png"/><p>According to the observed data, the frequency of accidents is higher for
drivers younger than 30 years old, and is positively correlated with the
<code class="docutils literal notranslate"><span class="pre">BonusMalus</span></code> variable. Our model is able to mostly correctly model this
behaviour.</p>
</section>
<section id="severity-model-gamma-distribution">
<h2>Severity Model -  Gamma distribution<a class="headerlink" href="#severity-model-gamma-distribution" title="Link to this heading">#</a></h2>
<p>The mean claim amount or severity (<code class="docutils literal notranslate"><span class="pre">AvgClaimAmount</span></code>) can be empirically
shown to follow approximately a Gamma distribution. We fit a GLM model for
the severity with the same features as the frequency model.</p>
<p>Note:</p>
<ul class="simple">
<li><p>We filter out <code class="docutils literal notranslate"><span class="pre">ClaimAmount</span> <span class="pre">==</span> <span class="pre">0</span></code> as the Gamma distribution has support
on <span class="math notranslate nohighlight">\((0, \infty)\)</span>, not <span class="math notranslate nohighlight">\([0, \infty)\)</span>.</p></li>
<li><p>We use <code class="docutils literal notranslate"><span class="pre">ClaimNb</span></code> as <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> to account for policies that contain
more than one claim.</p></li>
</ul>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <a class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.linear_model.GammaRegressor.html#sklearn.linear_model.GammaRegressor" title="sklearn.linear_model.GammaRegressor"><span class="n">GammaRegressor</span></a>

<span class="n">mask_train</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">"ClaimAmount"</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span>
<span class="n">mask_test</span> <span class="o">=</span> <span class="n">df_test</span><span class="p">[</span><span class="s2">"ClaimAmount"</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span>

<span class="n">glm_sev</span> <span class="o">=</span> <a class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.linear_model.GammaRegressor.html#sklearn.linear_model.GammaRegressor" title="sklearn.linear_model.GammaRegressor"><span class="n">GammaRegressor</span></a><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">"newton-cholesky"</span><span class="p">)</span>

<span class="n">glm_sev</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train</span><span class="p">[</span><span class="n">mask_train</span><span class="o">.</span><span class="n">values</span><span class="p">],</span>
    <span class="n">df_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask_train</span><span class="p">,</span> <span class="s2">"AvgClaimAmount"</span><span class="p">],</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="n">df_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask_train</span><span class="p">,</span> <span class="s2">"ClaimNb"</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">score_estimator</span><span class="p">(</span>
    <span class="n">glm_sev</span><span class="p">,</span>
    <span class="n">X_train</span><span class="p">[</span><span class="n">mask_train</span><span class="o">.</span><span class="n">values</span><span class="p">],</span>
    <span class="n">X_test</span><span class="p">[</span><span class="n">mask_test</span><span class="o">.</span><span class="n">values</span><span class="p">],</span>
    <span class="n">df_train</span><span class="p">[</span><span class="n">mask_train</span><span class="p">],</span>
    <span class="n">df_test</span><span class="p">[</span><span class="n">mask_test</span><span class="p">],</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">"AvgClaimAmount"</span><span class="p">,</span>
    <span class="n">weights</span><span class="o">=</span><span class="s2">"ClaimNb"</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Evaluation of GammaRegressor on target AvgClaimAmount"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Evaluation of GammaRegressor on target AvgClaimAmount
subset                     train          test
metric
DÂ² explained        3.900000e-03  4.400000e-03
mean abs. error     1.756746e+03  1.744042e+03
mean squared error  5.801770e+07  5.030677e+07
</pre></div>
</div>
<p>Those values of the metrics are not necessarily easy to interpret. It can be
insightful to compare them with a model that does not use any input
features and always predicts a constant value, i.e. the average claim
amount, in the same setting:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <a class="sphx-glr-backref-module-sklearn-dummy sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.dummy.DummyRegressor.html#sklearn.dummy.DummyRegressor" title="sklearn.dummy.DummyRegressor"><span class="n">DummyRegressor</span></a>

<span class="n">dummy_sev</span> <span class="o">=</span> <a class="sphx-glr-backref-module-sklearn-dummy sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.dummy.DummyRegressor.html#sklearn.dummy.DummyRegressor" title="sklearn.dummy.DummyRegressor"><span class="n">DummyRegressor</span></a><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">"mean"</span><span class="p">)</span>
<span class="n">dummy_sev</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train</span><span class="p">[</span><span class="n">mask_train</span><span class="o">.</span><span class="n">values</span><span class="p">],</span>
    <span class="n">df_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask_train</span><span class="p">,</span> <span class="s2">"AvgClaimAmount"</span><span class="p">],</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="n">df_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask_train</span><span class="p">,</span> <span class="s2">"ClaimNb"</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">score_estimator</span><span class="p">(</span>
    <span class="n">dummy_sev</span><span class="p">,</span>
    <span class="n">X_train</span><span class="p">[</span><span class="n">mask_train</span><span class="o">.</span><span class="n">values</span><span class="p">],</span>
    <span class="n">X_test</span><span class="p">[</span><span class="n">mask_test</span><span class="o">.</span><span class="n">values</span><span class="p">],</span>
    <span class="n">df_train</span><span class="p">[</span><span class="n">mask_train</span><span class="p">],</span>
    <span class="n">df_test</span><span class="p">[</span><span class="n">mask_test</span><span class="p">],</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">"AvgClaimAmount"</span><span class="p">,</span>
    <span class="n">weights</span><span class="o">=</span><span class="s2">"ClaimNb"</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Evaluation of a mean predictor on target AvgClaimAmount"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Evaluation of a mean predictor on target AvgClaimAmount
subset                     train          test
metric
DÂ² explained        0.000000e+00 -0.000000e+00
mean abs. error     1.756687e+03  1.744497e+03
mean squared error  5.803882e+07  5.033764e+07
</pre></div>
</div>
<p>We conclude that the claim amount is very challenging to predict. Still, the
<a class="reference internal" href="../../modules/generated/sklearn.linear_model.GammaRegressor.html#sklearn.linear_model.GammaRegressor" title="sklearn.linear_model.GammaRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">GammaRegressor</span></code></a> is able to leverage some
information from the input features to slightly improve upon the mean
baseline in terms of DÂ².</p>
<p>Note that the resulting model is the average claim amount per claim. As such,
it is conditional on having at least one claim, and cannot be used to predict
the average claim amount per policy. For this, it needs to be combined with
a claims frequency model.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="s2">"Mean AvgClaim Amount per policy:              </span><span class="si">%.2f</span><span class="s2"> "</span>
    <span class="o">%</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">"AvgClaimAmount"</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">"Mean AvgClaim Amount | NbClaim &gt; 0:           </span><span class="si">%.2f</span><span class="s2">"</span>
    <span class="o">%</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">"AvgClaimAmount"</span><span class="p">][</span><span class="n">df_train</span><span class="p">[</span><span class="s2">"AvgClaimAmount"</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">"Predicted Mean AvgClaim Amount | NbClaim &gt; 0: </span><span class="si">%.2f</span><span class="s2">"</span>
    <span class="o">%</span> <span class="n">glm_sev</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">"Predicted Mean AvgClaim Amount (dummy) | NbClaim &gt; 0: </span><span class="si">%.2f</span><span class="s2">"</span>
    <span class="o">%</span> <span class="n">dummy_sev</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Mean AvgClaim Amount per policy:              71.78
Mean AvgClaim Amount | NbClaim &gt; 0:           1951.21
Predicted Mean AvgClaim Amount | NbClaim &gt; 0: 1940.95
Predicted Mean AvgClaim Amount (dummy) | NbClaim &gt; 0: 1978.59
</pre></div>
</div>
<p>We can visually compare observed and predicted values, aggregated for
the drivers age (<code class="docutils literal notranslate"><span class="pre">DrivAge</span></code>).</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">plot_obs_pred</span><span class="p">(</span>
    <span class="n">df</span><span class="o">=</span><span class="n">df_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask_train</span><span class="p">],</span>
    <span class="n">feature</span><span class="o">=</span><span class="s2">"DrivAge"</span><span class="p">,</span>
    <span class="n">weight</span><span class="o">=</span><span class="s2">"Exposure"</span><span class="p">,</span>
    <span class="n">observed</span><span class="o">=</span><span class="s2">"AvgClaimAmount"</span><span class="p">,</span>
    <span class="n">predicted</span><span class="o">=</span><span class="n">glm_sev</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">mask_train</span><span class="o">.</span><span class="n">values</span><span class="p">]),</span>
    <span class="n">y_label</span><span class="o">=</span><span class="s2">"Average Claim Severity"</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"train data"</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">plot_obs_pred</span><span class="p">(</span>
    <span class="n">df</span><span class="o">=</span><span class="n">df_test</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask_test</span><span class="p">],</span>
    <span class="n">feature</span><span class="o">=</span><span class="s2">"DrivAge"</span><span class="p">,</span>
    <span class="n">weight</span><span class="o">=</span><span class="s2">"Exposure"</span><span class="p">,</span>
    <span class="n">observed</span><span class="o">=</span><span class="s2">"AvgClaimAmount"</span><span class="p">,</span>
    <span class="n">predicted</span><span class="o">=</span><span class="n">glm_sev</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">mask_test</span><span class="o">.</span><span class="n">values</span><span class="p">]),</span>
    <span class="n">y_label</span><span class="o">=</span><span class="s2">"Average Claim Severity"</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"test data"</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">fill_legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<a class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.tight_layout.html#matplotlib.pyplot.tight_layout" title="matplotlib.pyplot.tight_layout"><span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span></a><span class="p">()</span>
</pre></div>
</div>
<img alt="train data, test data" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_tweedie_regression_insurance_claims_002.png" srcset="../../_images/sphx_glr_plot_tweedie_regression_insurance_claims_002.png"/><p>Overall, the drivers age (<code class="docutils literal notranslate"><span class="pre">DrivAge</span></code>) has a weak impact on the claim
severity, both in observed and predicted data.</p>
</section>
<section id="pure-premium-modeling-via-a-product-model-vs-single-tweedieregressor">
<h2>Pure Premium Modeling via a Product Model vs single TweedieRegressor<a class="headerlink" href="#pure-premium-modeling-via-a-product-model-vs-single-tweedieregressor" title="Link to this heading">#</a></h2>
<p>As mentioned in the introduction, the total claim amount per unit of
exposure can be modeled as the product of the prediction of the
frequency model by the prediction of the severity model.</p>
<p>Alternatively, one can directly model the total loss with a unique
Compound Poisson Gamma generalized linear model (with a log link function).
This model is a special case of the Tweedie GLM with a â€œpowerâ€ parameter
<span class="math notranslate nohighlight">\(p \in (1, 2)\)</span>. Here, we fix apriori the <code class="docutils literal notranslate"><span class="pre">power</span></code> parameter of the
Tweedie model to some arbitrary value (1.9) in the valid range. Ideally one
would select this value via grid-search by minimizing the negative
log-likelihood of the Tweedie model, but unfortunately the current
implementation does not allow for this (yet).</p>
<p>We will compare the performance of both approaches.
To quantify the performance of both models, one can compute
the mean deviance of the train and test data assuming a Compound
Poisson-Gamma distribution of the total claim amount. This is equivalent to
a Tweedie distribution with a <code class="docutils literal notranslate"><span class="pre">power</span></code> parameter between 1 and 2.</p>
<p>The <a class="reference internal" href="../../modules/generated/sklearn.metrics.mean_tweedie_deviance.html#sklearn.metrics.mean_tweedie_deviance" title="sklearn.metrics.mean_tweedie_deviance"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.mean_tweedie_deviance</span></code></a> depends on a <code class="docutils literal notranslate"><span class="pre">power</span></code>
parameter. As we do not know the true value of the <code class="docutils literal notranslate"><span class="pre">power</span></code> parameter, we here
compute the mean deviances for a grid of possible values, and compare the
models side by side, i.e. we compare them at identical values of <code class="docutils literal notranslate"><span class="pre">power</span></code>.
Ideally, we hope that one model will be consistently better than the other,
regardless of <code class="docutils literal notranslate"><span class="pre">power</span></code>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <a class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.linear_model.TweedieRegressor.html#sklearn.linear_model.TweedieRegressor" title="sklearn.linear_model.TweedieRegressor"><span class="n">TweedieRegressor</span></a>

<span class="n">glm_pure_premium</span> <span class="o">=</span> <a class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="../../modules/generated/sklearn.linear_model.TweedieRegressor.html#sklearn.linear_model.TweedieRegressor" title="sklearn.linear_model.TweedieRegressor"><span class="n">TweedieRegressor</span></a><span class="p">(</span><span class="n">power</span><span class="o">=</span><span class="mf">1.9</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">"newton-cholesky"</span><span class="p">)</span>
<span class="n">glm_pure_premium</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">"PurePremium"</span><span class="p">],</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">df_train</span><span class="p">[</span><span class="s2">"Exposure"</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">tweedie_powers</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">1.7</span><span class="p">,</span> <span class="mf">1.8</span><span class="p">,</span> <span class="mf">1.9</span><span class="p">,</span> <span class="mf">1.99</span><span class="p">,</span> <span class="mf">1.999</span><span class="p">,</span> <span class="mf">1.9999</span><span class="p">]</span>

<span class="n">scores_product_model</span> <span class="o">=</span> <span class="n">score_estimator</span><span class="p">(</span>
    <span class="p">(</span><span class="n">glm_freq</span><span class="p">,</span> <span class="n">glm_sev</span><span class="p">),</span>
    <span class="n">X_train</span><span class="p">,</span>
    <span class="n">X_test</span><span class="p">,</span>
    <span class="n">df_train</span><span class="p">,</span>
    <span class="n">df_test</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">"PurePremium"</span><span class="p">,</span>
    <span class="n">weights</span><span class="o">=</span><span class="s2">"Exposure"</span><span class="p">,</span>
    <span class="n">tweedie_powers</span><span class="o">=</span><span class="n">tweedie_powers</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">scores_glm_pure_premium</span> <span class="o">=</span> <span class="n">score_estimator</span><span class="p">(</span>
    <span class="n">glm_pure_premium</span><span class="p">,</span>
    <span class="n">X_train</span><span class="p">,</span>
    <span class="n">X_test</span><span class="p">,</span>
    <span class="n">df_train</span><span class="p">,</span>
    <span class="n">df_test</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">"PurePremium"</span><span class="p">,</span>
    <span class="n">weights</span><span class="o">=</span><span class="s2">"Exposure"</span><span class="p">,</span>
    <span class="n">tweedie_powers</span><span class="o">=</span><span class="n">tweedie_powers</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <a class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-function" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html#pandas.concat" title="pandas.concat"><span class="n">pd</span><span class="o">.</span><span class="n">concat</span></a><span class="p">(</span>
    <span class="p">[</span><span class="n">scores_product_model</span><span class="p">,</span> <span class="n">scores_glm_pure_premium</span><span class="p">],</span>
    <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">sort</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">keys</span><span class="o">=</span><span class="p">(</span><span class="s2">"Product Model"</span><span class="p">,</span> <span class="s2">"TweedieRegressor"</span><span class="p">),</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Evaluation of the Product Model and the Tweedie Regressor on target PurePremium"</span><span class="p">)</span>
<span class="k">with</span> <a class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.option_context.html#pandas.option_context" title="pandas.option_context"><span class="n">pd</span><span class="o">.</span><span class="n">option_context</span></a><span class="p">(</span><span class="s2">"display.expand_frame_repr"</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Evaluation of the Product Model and the Tweedie Regressor on target PurePremium
                          Product Model               TweedieRegressor
subset                            train          test            train          test
metric
DÂ² explained                        NaN           NaN     1.640000e-02  1.370000e-02
mean Tweedie dev p=1.5000  7.669930e+01  7.617050e+01     7.640770e+01  7.640880e+01
mean Tweedie dev p=1.7000  3.695740e+01  3.683980e+01     3.682880e+01  3.692270e+01
mean Tweedie dev p=1.8000  3.046010e+01  3.040530e+01     3.037600e+01  3.045390e+01
mean Tweedie dev p=1.9000  3.387580e+01  3.385000e+01     3.382120e+01  3.387830e+01
mean Tweedie dev p=1.9900  2.015716e+02  2.015414e+02     2.015347e+02  2.015587e+02
mean Tweedie dev p=1.9990  1.914573e+03  1.914370e+03     1.914538e+03  1.914387e+03
mean Tweedie dev p=1.9999  1.904751e+04  1.904556e+04     1.904747e+04  1.904558e+04
mean abs. error            2.730119e+02  2.722128e+02     2.739865e+02  2.731249e+02
mean squared error         3.295040e+07  3.212197e+07     3.295505e+07  3.213056e+07
</pre></div>
</div>
<p>In this example, both modeling approaches yield comparable performance
metrics. For implementation reasons, the percentage of explained variance
<span class="math notranslate nohighlight">\(D^2\)</span> is not available for the product model.</p>
<p>We can additionally validate these models by comparing observed and
predicted total claim amount over the test and train subsets. We see that,
on average, both model tend to underestimate the total claim (but this
behavior depends on the amount of regularization).</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">subset_label</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">df</span> <span class="ow">in</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">"train"</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">df_train</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"test"</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">df_test</span><span class="p">),</span>
<span class="p">]:</span>
    <span class="n">exposure</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">"Exposure"</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">"subset"</span><span class="p">:</span> <span class="n">subset_label</span><span class="p">,</span>
            <span class="s2">"observed"</span><span class="p">:</span> <span class="n">df</span><span class="p">[</span><span class="s2">"ClaimAmount"</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>
            <span class="s2">"predicted, frequency*severity model"</span><span class="p">:</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function" href="https://numpy.org/doc/stable/reference/generated/numpy.sum.html#numpy.sum" title="numpy.sum"><span class="n">np</span><span class="o">.</span><span class="n">sum</span></a><span class="p">(</span>
                <span class="n">exposure</span> <span class="o">*</span> <span class="n">glm_freq</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">glm_sev</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="p">),</span>
            <span class="s2">"predicted, tweedie, power=</span><span class="si">%.2f</span><span class="s2">"</span>
            <span class="o">%</span> <span class="n">glm_pure_premium</span><span class="o">.</span><span class="n">power</span><span class="p">:</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function" href="https://numpy.org/doc/stable/reference/generated/numpy.sum.html#numpy.sum" title="numpy.sum"><span class="n">np</span><span class="o">.</span><span class="n">sum</span></a><span class="p">(</span><span class="n">exposure</span> <span class="o">*</span> <span class="n">glm_pure_premium</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)),</span>
        <span class="p">}</span>
    <span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><a class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><span class="n">res</span><span class="p">)</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">"subset"</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>subset                                      train          test
observed                             3.917618e+07  1.299546e+07
predicted, frequency*severity model  3.916555e+07  1.313276e+07
predicted, tweedie, power=1.90       3.951751e+07  1.325198e+07
</pre></div>
</div>
<p>Finally, we can compare the two models using a plot of cumulated claims: for
each model, the policyholders are ranked from safest to riskiest based on the
model predictions and the fraction of observed total cumulated claims is
plotted on the y axis. This plot is often called the ordered Lorenz curve of
the model.</p>
<p>The Gini coefficient (based on the area between the curve and the diagonal)
can be used as a model selection metric to quantify the ability of the model
to rank policyholders. Note that this metric does not reflect the ability of
the models to make accurate predictions in terms of absolute value of total
claim amounts but only in terms of relative amounts as a ranking metric. The
Gini coefficient is upper bounded by 1.0 but even an oracle model that ranks
the policyholders by the observed claim amounts cannot reach a score of 1.0.</p>
<p>We observe that both models are able to rank policyholders by risky-ness
significantly better than chance although they are also both far from the
oracle model due to the natural difficulty of the prediction problem from a
few features: most accidents are not predictable and can be caused by
environmental circumstances that are not described at all by the input
features of the models.</p>
<p>Note that the Gini index only characterizes the ranking performance of the
model but not its calibration: any monotonic transformation of the predictions
leaves the Gini index of the model unchanged.</p>
<p>Finally one should highlight that the Compound Poisson Gamma model that is
directly fit on the pure premium is operationally simpler to develop and
maintain as it consists of a single scikit-learn estimator instead of a pair
of models, each with its own set of hyperparameters.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <a class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.metrics.auc.html#sklearn.metrics.auc" title="sklearn.metrics.auc"><span class="n">auc</span></a>


<span class="k">def</span> <span class="nf">lorenz_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">exposure</span><span class="p">):</span>
    <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function" href="https://numpy.org/doc/stable/reference/generated/numpy.asarray.html#numpy.asarray" title="numpy.asarray"><span class="n">np</span><span class="o">.</span><span class="n">asarray</span></a><span class="p">(</span><span class="n">y_true</span><span class="p">),</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function" href="https://numpy.org/doc/stable/reference/generated/numpy.asarray.html#numpy.asarray" title="numpy.asarray"><span class="n">np</span><span class="o">.</span><span class="n">asarray</span></a><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">exposure</span> <span class="o">=</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function" href="https://numpy.org/doc/stable/reference/generated/numpy.asarray.html#numpy.asarray" title="numpy.asarray"><span class="n">np</span><span class="o">.</span><span class="n">asarray</span></a><span class="p">(</span><span class="n">exposure</span><span class="p">)</span>

    <span class="c1"># order samples by increasing predicted risk:</span>
    <span class="n">ranking</span> <span class="o">=</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function" href="https://numpy.org/doc/stable/reference/generated/numpy.argsort.html#numpy.argsort" title="numpy.argsort"><span class="n">np</span><span class="o">.</span><span class="n">argsort</span></a><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">ranked_exposure</span> <span class="o">=</span> <span class="n">exposure</span><span class="p">[</span><span class="n">ranking</span><span class="p">]</span>
    <span class="n">ranked_pure_premium</span> <span class="o">=</span> <span class="n">y_true</span><span class="p">[</span><span class="n">ranking</span><span class="p">]</span>
    <span class="n">cumulated_claim_amount</span> <span class="o">=</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function" href="https://numpy.org/doc/stable/reference/generated/numpy.cumsum.html#numpy.cumsum" title="numpy.cumsum"><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span></a><span class="p">(</span><span class="n">ranked_pure_premium</span> <span class="o">*</span> <span class="n">ranked_exposure</span><span class="p">)</span>
    <span class="n">cumulated_claim_amount</span> <span class="o">/=</span> <span class="n">cumulated_claim_amount</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">cumulated_samples</span> <span class="o">=</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function" href="https://numpy.org/doc/stable/reference/generated/numpy.linspace.html#numpy.linspace" title="numpy.linspace"><span class="n">np</span><span class="o">.</span><span class="n">linspace</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">cumulated_claim_amount</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">cumulated_samples</span><span class="p">,</span> <span class="n">cumulated_claim_amount</span>


<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="n">y_pred_product</span> <span class="o">=</span> <span class="n">glm_freq</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="o">*</span> <span class="n">glm_sev</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_pred_total</span> <span class="o">=</span> <span class="n">glm_pure_premium</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">y_pred</span> <span class="ow">in</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">"Frequency * Severity model"</span><span class="p">,</span> <span class="n">y_pred_product</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"Compound Poisson Gamma"</span><span class="p">,</span> <span class="n">y_pred_total</span><span class="p">),</span>
<span class="p">]:</span>
    <span class="n">ordered_samples</span><span class="p">,</span> <span class="n">cum_claims</span> <span class="o">=</span> <span class="n">lorenz_curve</span><span class="p">(</span>
        <span class="n">df_test</span><span class="p">[</span><span class="s2">"PurePremium"</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">df_test</span><span class="p">[</span><span class="s2">"Exposure"</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">gini</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <a class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.metrics.auc.html#sklearn.metrics.auc" title="sklearn.metrics.auc"><span class="n">auc</span></a><span class="p">(</span><span class="n">ordered_samples</span><span class="p">,</span> <span class="n">cum_claims</span><span class="p">)</span>
    <span class="n">label</span> <span class="o">+=</span> <span class="s2">" (Gini index: </span><span class="si">{:.3f}</span><span class="s2">)"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gini</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ordered_samples</span><span class="p">,</span> <span class="n">cum_claims</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">"-"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>

<span class="c1"># Oracle model: y_pred == y_test</span>
<span class="n">ordered_samples</span><span class="p">,</span> <span class="n">cum_claims</span> <span class="o">=</span> <span class="n">lorenz_curve</span><span class="p">(</span>
    <span class="n">df_test</span><span class="p">[</span><span class="s2">"PurePremium"</span><span class="p">],</span> <span class="n">df_test</span><span class="p">[</span><span class="s2">"PurePremium"</span><span class="p">],</span> <span class="n">df_test</span><span class="p">[</span><span class="s2">"Exposure"</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">gini</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <a class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function" href="../../modules/generated/sklearn.metrics.auc.html#sklearn.metrics.auc" title="sklearn.metrics.auc"><span class="n">auc</span></a><span class="p">(</span><span class="n">ordered_samples</span><span class="p">,</span> <span class="n">cum_claims</span><span class="p">)</span>
<span class="n">label</span> <span class="o">=</span> <span class="s2">"Oracle (Gini index: </span><span class="si">{:.3f}</span><span class="s2">)"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gini</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ordered_samples</span><span class="p">,</span> <span class="n">cum_claims</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">"-."</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>

<span class="c1"># Random baseline</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">"--"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">"black"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Random baseline"</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Lorenz Curves"</span><span class="p">,</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">"Fraction of policyholders</span><span class="se">\n</span><span class="s2">(ordered by model from safest to riskiest)"</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">"Fraction of total claim amount"</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">"upper left"</span><span class="p">)</span>
<a class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html#matplotlib.pyplot.plot" title="matplotlib.pyplot.plot"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span></a><span class="p">()</span>
</pre></div>
</div>
<img alt="Lorenz Curves" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_tweedie_regression_insurance_claims_003.png" srcset="../../_images/sphx_glr_plot_tweedie_regression_insurance_claims_003.png"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[]
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 11.224 seconds)</p>

<p class="rubric">Related examples</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This example illustrates the use of log-linear Poisson regression on the French Motor Third-Party Liability Claims dataset from [1]_ and compares it with a linear model fitted with the usual least squared error and a non-linear GBRT model fitted with the Poisson loss (and a log-link)."><img alt="" src="../../_images/sphx_glr_plot_poisson_regression_non_normal_loss_thumb.png"/>
<p><a class="reference internal" href="plot_poisson_regression_non_normal_loss.html#sphx-glr-auto-examples-linear-model-plot-poisson-regression-non-normal-loss-py"><span class="std std-ref">Poisson regression and non-normal loss</span></a></p>
<div class="sphx-glr-thumbnail-title">Poisson regression and non-normal loss</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Well calibrated classifiers are probabilistic classifiers for which the output of predict_proba can be directly interpreted as a confidence level. For instance, a well calibrated (binary) classifier should classify the samples such that for the samples to which it gave a predict_proba value close to 0.8, approximately 80% actually belong to the positive class."><img alt="" src="../../_images/sphx_glr_plot_compare_calibration_thumb.png"/>
<p><a class="reference internal" href="../calibration/plot_compare_calibration.html#sphx-glr-auto-examples-calibration-plot-compare-calibration-py"><span class="std std-ref">Comparison of Calibration of Classifiers</span></a></p>
<div class="sphx-glr-thumbnail-title">Comparison of Calibration of Classifiers</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates how Polars-engineered lagged features can be used for time series forecasting with HistGradientBoostingRegressor on the Bike Sharing Demand dataset."><img alt="" src="../../_images/sphx_glr_plot_time_series_lagged_features_thumb.png"/>
<p><a class="reference internal" href="../applications/plot_time_series_lagged_features.html#sphx-glr-auto-examples-applications-plot-time-series-lagged-features-py"><span class="std std-ref">Lagged features for time series forecasting</span></a></p>
<div class="sphx-glr-thumbnail-title">Lagged features for time series forecasting</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the use of the Box-Cox and Yeo-Johnson transforms through PowerTransformer to map data from various distributions to a normal distribution."><img alt="" src="../../_images/sphx_glr_plot_map_data_to_normal_thumb.png"/>
<p><a class="reference internal" href="../preprocessing/plot_map_data_to_normal.html#sphx-glr-auto-examples-preprocessing-plot-map-data-to-normal-py"><span class="std std-ref">Map data to a normal distribution</span></a></p>
<div class="sphx-glr-thumbnail-title">Map data to a normal distribution</div>
</div></div><p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>
</article>
<footer class="bd-footer-article">
<div class="footer-article-items footer-article__inner">
<div class="footer-article-item">
<div class="prev-next-area">
<a class="left-prev" href="plot_theilsen.html" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Theil-Sen Regression</p>
</div>
</a>
<a class="right-next" href="../inspection/index.html" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Inspection</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div></div>
</div>
</footer>
</div>
<div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">
<div class="sidebar-secondary-item">
<div class="page-toc tocsection onthispage" id="pst-page-navigation-heading-2">
<i class="fa-solid fa-list"></i> On this page
  </div>
<nav aria-labelledby="pst-page-navigation-heading-2" class="bd-toc-nav page-toc">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-datasets-basic-feature-extraction-and-target-definitions">Loading datasets, basic feature extraction and target definitions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#frequency-model-poisson-distribution">Frequency model â€“ Poisson distribution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#severity-model-gamma-distribution">Severity Model -  Gamma distribution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pure-premium-modeling-via-a-product-model-vs-single-tweedieregressor">Pure Premium Modeling via a Product Model vs single TweedieRegressor</a></li>
</ul>
</nav></div>

<div class="sidebar-secondary-item"><div title="plot_tweedie_regression_insurance_claims.py"><a download="" href="../../_downloads/86c888008757148890daaf43d664fa71/plot_tweedie_regression_insurance_claims.py"><i class="fa-solid fa-download"></i> Download source code</a></div><div title="plot_tweedie_regression_insurance_claims.ipynb"><a download="" href="../../_downloads/a97bf662e52d471b04e1ab480c0ad7f2/plot_tweedie_regression_insurance_claims.ipynb"><i class="fa-solid fa-download"></i> Download Jupyter notebook</a></div></div><div class="sidebar-secondary-item"><div><a href="../../lite/lab/index.html?path=auto_examples/linear_model/plot_tweedie_regression_insurance_claims.ipynb"><img alt="Launch JupyterLite" height="20" src="../../_images/jupyterlite_badge_logo18.svg"/></a></div><div><a href="https://mybinder.org/v2/gh/scikit-learn/scikit-learn/1.5.X?urlpath=lab/tree/notebooks/auto_examples/linear_model/plot_tweedie_regression_insurance_claims.ipynb"><img alt="Launch binder" height="20" src="../../_images/binder_badge_logo18.svg"/></a></div></div></div></div>
</div>
<footer class="bd-footer-content">
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>
<footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
<div class="footer-items__start">
<div class="footer-item">
<p class="copyright">
    
      Â© Copyright 2007 - 2024, scikit-learn developers (BSD License).
      <br/>
</p>
</div>
</div>
</div>
</footer>
</body>
</html>